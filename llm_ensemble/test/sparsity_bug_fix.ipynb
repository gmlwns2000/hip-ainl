{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4, 11,  7,  9,  7],\n",
      "          [ 7,  9,  1,  3,  7],\n",
      "          [ 5, 10, 10,  3,  2]],\n",
      "\n",
      "         [[ 9,  5,  3,  9,  8],\n",
      "          [ 2,  1, 10,  3,  5],\n",
      "          [ 4,  2,  8,  8,  9]],\n",
      "\n",
      "         [[10,  3,  5,  4, 10],\n",
      "          [10,  1, 10,  2,  7],\n",
      "          [ 2,  7, 11,  7,  6]]],\n",
      "\n",
      "\n",
      "        [[[ 9,  6,  7,  8,  9],\n",
      "          [ 2,  8,  9,  4,  6],\n",
      "          [11,  5, 10,  9,  6]],\n",
      "\n",
      "         [[ 7, 11, 11,  7,  1],\n",
      "          [ 8,  9,  5,  6,  7],\n",
      "          [10,  6,  3,  1,  5]],\n",
      "\n",
      "         [[ 1,  4,  9,  8, 10],\n",
      "          [ 8, 10,  4, 11,  7],\n",
      "          [ 8,  3,  6,  4,  5]]]])\n"
     ]
    }
   ],
   "source": [
    "# ensemble_attn_mask_per_layer [40, 128, 256, 5] to [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "\n",
    "# from ...hip.utils import seed\n",
    "def seed(seed=50):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "ensemble_method_final_inter_thresh = 4\n",
    "ensemble_method_final_bdd_mask_k = 0\n",
    "ensemble_model_n = 5\n",
    "seed()\n",
    "\n",
    "ensemble_attn_mask_per_layer = torch.randint(1, 12, (2,3,3,5))\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "_N_H, TDST_BQ, MASK_K_BK, MODEL_N = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "origin_sparsity = (torch.sum(ensemble_attn_mask_per_layer < 32000)//ensemble_model_n).item()\n",
    "\n",
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H * TDST_BQ, MASK_K_BK * MODEL_N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4, 11,  7,  9,  7,  7,  9,  1,  3,  7,  5, 10, 10,  3,  2],\n",
      "        [ 9,  5,  3,  9,  8,  2,  1, 10,  3,  5,  4,  2,  8,  8,  9],\n",
      "        [10,  3,  5,  4, 10, 10,  1, 10,  2,  7,  2,  7, 11,  7,  6],\n",
      "        [ 9,  6,  7,  8,  9,  2,  8,  9,  4,  6, 11,  5, 10,  9,  6],\n",
      "        [ 7, 11, 11,  7,  1,  8,  9,  5,  6,  7, 10,  6,  3,  1,  5],\n",
      "        [ 1,  4,  9,  8, 10,  8, 10,  4, 11,  7,  8,  3,  6,  4,  5]])\n",
      "torch.Size([6, 15])\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_attn_mask_per_layer)\n",
    "print(ensemble_attn_mask_per_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       " tensor([ 6,  6,  7,  7,  8,  7, 12,  9, 11, 11,  6]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ensemble_method_final_bdd_mask_k == 1:\n",
    "    pass\n",
    "    # ensemble_indices_k_size = mask_k//block_size_k\n",
    "else:\n",
    "    # TODO set to max possible memory : change it more efficiently\n",
    "    ensemble_indices_k_size = MASK_K_BK * MODEL_N \n",
    "\n",
    "# TODO: Is it better to start plain and concatenate?\n",
    "# ensembled_indices = torch.full((_N_H*TDST_BQ, ensemble_indices_k_size), 32000) # change to (N_H, TDST_BQ, ensemble_indices_k_size)\n",
    "\n",
    "# k_size_max = 0\n",
    "\n",
    "# NOTE per_query_token_cnt_diclist is just for analysis\n",
    "if os.environ.get('ENSEMBLE_AGREE_DICLIST', '0') == '1':\n",
    "    per_query_token_cnt_diclist = []\n",
    "\n",
    "# ensemble_attn_mask_per_layer : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, sorted=False, return_inverse=True, return_counts=True)\n",
    "# indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unique_x, unique_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "tensor([ 6,  6,  7,  7,  8,  7, 12,  9, 11, 11,  6])\n",
      "tensor([[    1,     2,     3,     4,     5, 32000,     7, 32000,     9,    10,\n",
      "            11, 32000, 32000, 32000, 32000],\n",
      "        [    1,     2,     3,     4,     5, 32000, 32000,     8,     9,    10,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    1,     2,     3,     4,     5,     6,     7, 32000, 32000,    10,\n",
      "            11, 32000, 32000, 32000, 32000],\n",
      "        [32000,     2, 32000,     4,     5,     6,     7,     8,     9,    10,\n",
      "            11, 32000, 32000, 32000, 32000],\n",
      "        [    1, 32000,     3, 32000,     5,     6,     7,     8,     9,    10,\n",
      "            11, 32000, 32000, 32000, 32000],\n",
      "        [    1, 32000,     3,     4,     5,     6,     7,     8,     9,    10,\n",
      "            11, 32000, 32000, 32000, 32000]])\n",
      "tensor([[       1,        1,        2,        1,        1, -9999999,        4,\n",
      "         -9999999,        2,        2,        1, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       1,        2,        2,        1,        2, -9999999, -9999999,\n",
      "                3,        3,        1, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       1,        2,        1,        1,        1,        1,        3,\n",
      "         -9999999, -9999999,        4,        1, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [-9999999,        1, -9999999,        1,        1,        3,        1,\n",
      "                2,        4,        1,        1, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       2, -9999999,        1, -9999999,        2,        2,        3,\n",
      "                1,        1,        1,        2, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       1, -9999999,        1,        3,        1,        1,        1,\n",
      "                3,        1,        2,        1, -9999999, -9999999, -9999999,\n",
      "         -9999999]])\n"
     ]
    }
   ],
   "source": [
    "# cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "N, K = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "cnt_xs = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    cnt_xs.append(\n",
    "        (unique_x[None, None, :] == ensemble_attn_mask_per_layer[icn*chunk_n:icn*chunk_n+chunk_n, :, None]).long().sum(1)\n",
    "    )\n",
    "cnt_x = torch.cat(cnt_xs, dim=0)\n",
    "\n",
    "\n",
    "result = torch.full_like(ensemble_attn_mask_per_layer, 32000)\n",
    "result = result.scatter_(1, indices.clamp(0, K-1), ensemble_attn_mask_per_layer)\n",
    "\n",
    "\n",
    "# t = result[:, :, None] == unique_x[None, None, :]\n",
    "# t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "# t = t.sum(-1)\n",
    "N, K = result.shape\n",
    "ts = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    t = result[icn*chunk_n:icn*chunk_n+chunk_n, :, None] == unique_x[None, None, :]\n",
    "    t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "    t = t.sum(-1)\n",
    "    ts.append(t)\n",
    "t = torch.cat(ts, dim=0)\n",
    "\n",
    "# torch.Size([4096, 1280]) torch.Size([64, 1280]) torch.Size([4096, 2094])\n",
    "# print(result.shape, t.shape, cnt_x.shape)\n",
    "result_cnt = torch.where(result < 32000, cnt_x.gather(-1, t), -9999999)\n",
    "\n",
    "print(unique_x)\n",
    "print(unique_cnt)\n",
    "print(result)\n",
    "print(result_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "tensor([[    7,     3,     9,    10,     1,     2,     4,     5,    11, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    8,     9,     2,     3,     5,     1,     4,    10, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [   10,     7,     2,     1,     3,     4,     5,     6,    11, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    9,     6,     8,     2,     4,     5,     7,    10,    11, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    7,     1,     5,     6,    11,     3,     8,     9,    10, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    4,     8,    10,     1,     3,     5,     6,     7,     9,    11,\n",
      "         32000, 32000, 32000, 32000, 32000]])\n",
      "tensor([[       4,        2,        2,        2,        1,        1,        1,\n",
      "                1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       3,        3,        2,        2,        2,        1,        1,\n",
      "                1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       4,        3,        2,        1,        1,        1,        1,\n",
      "                1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       4,        3,        2,        1,        1,        1,        1,\n",
      "                1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       3,        2,        2,        2,        2,        1,        1,\n",
      "                1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       3,        3,        2,        1,        1,        1,        1,\n",
      "                1,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999]])\n",
      "tensor([[    7, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [   10, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    9, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000]])\n",
      "tensor([[    4, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    4, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [    4, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000],\n",
      "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000, 32000]])\n"
     ]
    }
   ],
   "source": [
    "# ensemble_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "# ensemble_cnt_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)\n",
    "mask = ensemble_cnt_sorted >= ensemble_method_final_inter_thresh\n",
    "\n",
    "ensemble_filtered = torch.where(mask, ensemble_sorted, torch.tensor(32000, device=mask.device))\n",
    "ensemble_cnt_filtered = torch.where(mask, ensemble_cnt_sorted, torch.tensor(32000, device=mask.device))\n",
    "\n",
    "print(ensemble_method_final_inter_thresh)\n",
    "print(ensemble_sorted)\n",
    "print(ensemble_cnt_sorted)\n",
    "# print(mask)\n",
    "print(ensemble_filtered)\n",
    "print(ensemble_cnt_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 15])\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True]])\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True])\n",
      "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),)\n",
      "torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "## mask_i : where to discard leftovers \n",
    "filtered_mask = ensemble_filtered == 32000\n",
    "# Determine which columns have all rows as -1\n",
    "columns_with_all_negative_one = torch.all(filtered_mask, dim=0)\n",
    "\n",
    "# Get the first index where all rows have -1\n",
    "nonzero_indices = torch.nonzero(columns_with_all_negative_one, as_tuple=True)\n",
    "\n",
    "# If there are any such columns, find the first one\n",
    "if len(nonzero_indices[0]) > 0:\n",
    "    mask_k_i = nonzero_indices[0][0].item()\n",
    "    k_final = min(mask_k_i, ensemble_indices_k_size)\n",
    "else:\n",
    "    mask_k_i = -1  # If no such index is found\n",
    "    k_final = ensemble_indices_k_size\n",
    "\n",
    "print(filtered_mask.shape)\n",
    "print(filtered_mask)\n",
    "print(columns_with_all_negative_one)\n",
    "print(nonzero_indices)\n",
    "print(nonzero_indices[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_k_i, ensemble_indices_k_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[    7],\n",
       "          [32000],\n",
       "          [   10]],\n",
       " \n",
       "         [[    9],\n",
       "          [32000],\n",
       "          [32000]]]),\n",
       " tensor([[    4],\n",
       "         [32000],\n",
       "         [    4],\n",
       "         [    4],\n",
       "         [32000],\n",
       "         [32000]]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_final = min(mask_k_i, ensemble_indices_k_size)\n",
    "ensemble_filtered = ensemble_filtered[:, :k_final]\n",
    "ensemble_cnt_filtered = ensemble_cnt_filtered[:, :k_final]\n",
    "ensemble_filtered = ensemble_filtered.view(_N_H, TDST_BQ, -1)\n",
    "\n",
    "ensemble_filtered, ensemble_cnt_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4, 11,  7,  9,  7,  7,  9,  1,  3,  7,  5, 10, 10,  3,  2],\n",
      "        [ 9,  5,  3,  9,  8,  2,  1, 10,  3,  5,  4,  2,  8,  8,  9],\n",
      "        [10,  3,  5,  4, 10, 10,  1, 10,  2,  7,  2,  7, 11,  7,  6],\n",
      "        [ 9,  6,  7,  8,  9,  2,  8,  9,  4,  6, 11,  5, 10,  9,  6],\n",
      "        [ 7, 11, 11,  7,  1,  8,  9,  5,  6,  7, 10,  6,  3,  1,  5],\n",
      "        [ 1,  4,  9,  8, 10,  8, 10,  4, 11,  7,  8,  3,  6,  4,  5]])\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_attn_mask_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 1]),\n",
       " tensor([[[    7],\n",
       "          [32000],\n",
       "          [   10]],\n",
       " \n",
       "         [[    9],\n",
       "          [32000],\n",
       "          [32000]]]),\n",
       " tensor([[[ True],\n",
       "          [False],\n",
       "          [ True]],\n",
       " \n",
       "         [[ True],\n",
       "          [False],\n",
       "          [False]]]),\n",
       " tensor([[1, 0, 1],\n",
       "         [1, 0, 0]]),\n",
       " 18,\n",
       " 3,\n",
       " 0.16666666666666666)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_mask = ensemble_filtered < 32000\n",
    "ks = k_mask.sum(dim=-1).view(_N_H, TDST_BQ)\n",
    "sparsity_per_layer = torch.sum(ensemble_filtered<32000).item()\n",
    "sparsity_ratio = (sparsity_per_layer/origin_sparsity)\n",
    "\n",
    "\n",
    "ensemble_filtered.shape, ensemble_filtered, k_mask, ks, origin_sparsity, sparsity_per_layer, sparsity_ratio, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 5])\n",
      "tensor([[[[ 4, 11,  7,  9,  7],\n",
      "          [ 7,  9,  1,  3,  7],\n",
      "          [ 5, 10, 10,  3,  2]],\n",
      "\n",
      "         [[ 9,  5,  3,  9,  8],\n",
      "          [ 2,  1, 10,  3,  5],\n",
      "          [ 4,  2,  8,  8,  9]],\n",
      "\n",
      "         [[10,  3,  5,  4, 10],\n",
      "          [10,  1, 10,  2,  7],\n",
      "          [ 2,  7, 11,  7,  6]]],\n",
      "\n",
      "\n",
      "        [[[ 9,  6,  7,  8,  9],\n",
      "          [ 2,  8,  9,  4,  6],\n",
      "          [11,  5, 10,  9,  6]],\n",
      "\n",
      "         [[ 7, 11, 11,  7,  1],\n",
      "          [ 8,  9,  5,  6,  7],\n",
      "          [10,  6,  3,  1,  5]],\n",
      "\n",
      "         [[ 1,  4,  9,  8, 10],\n",
      "          [ 8, 10,  4, 11,  7],\n",
      "          [ 8,  3,  6,  4,  5]]]])\n",
      "torch.Size([6, 15])\n",
      "tensor([[ 4, 11,  7,  9,  7,  7,  9,  1,  3,  7,  5, 10, 10,  3,  2],\n",
      "        [ 9,  5,  3,  9,  8,  2,  1, 10,  3,  5,  4,  2,  8,  8,  9],\n",
      "        [10,  3,  5,  4, 10, 10,  1, 10,  2,  7,  2,  7, 11,  7,  6],\n",
      "        [ 9,  6,  7,  8,  9,  2,  8,  9,  4,  6, 11,  5, 10,  9,  6],\n",
      "        [ 7, 11, 11,  7,  1,  8,  9,  5,  6,  7, 10,  6,  3,  1,  5],\n",
      "        [ 1,  4,  9,  8, 10,  8, 10,  4, 11,  7,  8,  3,  6,  4,  5]])\n",
      "tensor([[[    7,     3,     9,    10, 32000],\n",
      "         [    8,     9,     2,     3,     5],\n",
      "         [   10,     7,     2, 32000, 32000]],\n",
      "\n",
      "        [[    9,     6,     8, 32000, 32000],\n",
      "         [    7,     1,     5,     6,    11],\n",
      "         [    4,     8,    10, 32000, 32000]]])\n",
      "tensor([[    4,     2,     2,     2, 32000],\n",
      "        [    3,     3,     2,     2,     2],\n",
      "        [    4,     3,     2, 32000, 32000],\n",
      "        [    4,     3,     2, 32000, 32000],\n",
      "        [    3,     2,     2,     2,     2],\n",
      "        [    3,     3,     2, 32000, 32000]])\n",
      "tensor([[4, 5, 3],\n",
      "        [3, 5, 3]])\n",
      "1.2777777777777777\n"
     ]
    }
   ],
   "source": [
    "# ensemble_attn_mask_per_layer [40, 128, 256, 5] to [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "\n",
    "# from ...hip.utils import seed\n",
    "def seed(seed=50):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "ensemble_method_final_inter_thresh = 2\n",
    "ensemble_method_final_bdd_mask_k = 0\n",
    "ensemble_model_n = 5\n",
    "seed()\n",
    "\n",
    "ensemble_attn_mask_per_layer = torch.randint(1, 12, (2,3,3,5))\n",
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "_N_H, TDST_BQ, MASK_K_BK, MODEL_N = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "origin_sparsity = (torch.sum(ensemble_attn_mask_per_layer < 32000)//ensemble_model_n).item()\n",
    "\n",
    "if ensemble_method_final_bdd_mask_k == 1:\n",
    "    pass\n",
    "    # ensemble_indices_k_size = mask_k//block_size_k\n",
    "else:\n",
    "    # TODO set to max possible memory : change it more efficiently\n",
    "    ensemble_indices_k_size = MASK_K_BK * MODEL_N \n",
    "\n",
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H * TDST_BQ, MASK_K_BK * MODEL_N)\n",
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "# TODO: Is it better to start plain and concatenate?\n",
    "# ensembled_indices = torch.full((_N_H*TDST_BQ, ensemble_indices_k_size), 32000) # change to (N_H, TDST_BQ, ensemble_indices_k_size)\n",
    "\n",
    "# k_size_max = 0\n",
    "\n",
    "# NOTE per_query_token_cnt_diclist is just for analysis\n",
    "if os.environ.get('ENSEMBLE_AGREE_DICLIST', '0') == '1':\n",
    "    per_query_token_cnt_diclist = []\n",
    "\n",
    "# ensemble_attn_mask_per_layer [40, 128, 256, 5] to [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "# ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H * TDST_BQ, MASK_K_BK * MODEL_N)\n",
    "# ensemble_attn_mask_per_layer : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, return_inverse=True, sorted=False, return_counts=True)\n",
    "# indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "\n",
    "# cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "N, K = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "cnt_xs = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    cnt_xs.append(\n",
    "        (unique_x[None, None, :] == ensemble_attn_mask_per_layer[icn*chunk_n:icn*chunk_n+chunk_n, :, None]).long().sum(1)\n",
    "    )\n",
    "cnt_x = torch.cat(cnt_xs, dim=0)\n",
    "\n",
    "\n",
    "result = torch.full_like(ensemble_attn_mask_per_layer, 32000)\n",
    "result = result.scatter_(1, indices.clamp(0, K-1), ensemble_attn_mask_per_layer)\n",
    "\n",
    "\n",
    "# t = result[:, :, None] == unique_x[None, None, :]\n",
    "# t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "# t = t.sum(-1)\n",
    "N, K = result.shape\n",
    "ts = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    t = result[icn*chunk_n:icn*chunk_n+chunk_n, :, None] == unique_x[None, None, :]\n",
    "    t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "    t = t.sum(-1)\n",
    "    ts.append(t)\n",
    "t = torch.cat(ts, dim=0)\n",
    "\n",
    "# torch.Size([4096, 1280]) torch.Size([64, 1280]) torch.Size([4096, 2094])\n",
    "# print(result.shape, t.shape, cnt_x.shape)\n",
    "result_cnt = torch.where(result < 32000, cnt_x.gather(-1, t), -9999999)\n",
    "\n",
    "'''\n",
    "ensemble_attn_mask_per_layer\n",
    "tensor([[1, 1, 3, 3, 3, 5],\\\n",
    "        [3, 3, 4, 4, 4, 4]])\n",
    "ensemble_cnt_sorted\n",
    "tensor([[       6,        4,        3,        3,        2,        1,        1,\n",
    "    -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
    "    -9999999, -9999999, -9999999, -9999999, -9999999, -9999999],\\\n",
    "    [       6,        4,        3,        3,        2,        2, -9999999,\n",
    "    -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
    "    -9999999, -9999999, -9999999, -9999999, -9999999, -9999999]])\n",
    "ensemble_sorted\n",
    "    tensor([[   10,     6,     3,     8,     1,     5,    11, 32000, 32000, 32000,\n",
    "    32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000],\\\n",
    "    [    5,     4,     7,     9,     6,     3, 32000, 32000, 32000, 32000,\n",
    "    32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000]]))\n",
    "'''\n",
    "# ensemble_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "# ensemble_cnt_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)\n",
    "mask = ensemble_cnt_sorted >= ensemble_method_final_inter_thresh\n",
    "\n",
    "ensemble_filtered = torch.where(mask, ensemble_sorted, torch.tensor(32000, device=mask.device))\n",
    "ensemble_cnt_filtered = torch.where(mask, ensemble_cnt_sorted, torch.tensor(32000, device=mask.device))\n",
    "\n",
    "## mask_i : where to discard leftovers \n",
    "filtered_mask = ensemble_filtered == 32000\n",
    "# Determine which columns have all rows as -1\n",
    "columns_with_all_negative_one = torch.all(filtered_mask, dim=0)\n",
    "\n",
    "# Get the first index where all rows have -1\n",
    "nonzero_indices = torch.nonzero(columns_with_all_negative_one, as_tuple=True)\n",
    "\n",
    "# If there are any such columns, find the first one\n",
    "if len(nonzero_indices[0]) > 0:\n",
    "    mask_k_i = nonzero_indices[0][0].item()\n",
    "    k_final = min(mask_k_i, ensemble_indices_k_size)\n",
    "else:\n",
    "    mask_k_i = -1  # If no such index is found\n",
    "    k_final = ensemble_indices_k_size\n",
    "\n",
    "ensemble_filtered = ensemble_filtered[:, :k_final] # TODO is this meaningful??\n",
    "ensemble_cnt_filtered = ensemble_cnt_filtered[:, :k_final]\n",
    "ensemble_filtered = ensemble_filtered.view(_N_H, TDST_BQ, -1)\n",
    "\n",
    "k_mask = ensemble_filtered < 32000\n",
    "ks = k_mask.sum(dim=-1).view(_N_H, TDST_BQ)\n",
    "sparsity_per_layer = torch.sum(ensemble_filtered<32000).item()\n",
    "sparsity_ratio = (sparsity_per_layer/origin_sparsity)\n",
    "\n",
    "print(ensemble_filtered)\n",
    "print(ensemble_cnt_filtered)\n",
    "print(ks)\n",
    "print(sparsity_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
