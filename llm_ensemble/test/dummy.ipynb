{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming these variables are defined: N_H, TDST_BQ, MASK_K_BK\n",
    "# Example values for demonstration (You should replace them with your actual values)\n",
    "N_H = 40  # Example: Number of heads\n",
    "TDST_BQ = 128  # Example: TDST divided by block size for query\n",
    "MASK_K_BK = 256  # Example: MASK_K divided by block size for keys\n",
    "\n",
    "# Initialize the tensors with example shapes\n",
    "# Replace these with your actual tensors\n",
    "indices = torch.zeros(N_H, TDST_BQ, MASK_K_BK, dtype=torch.long)\n",
    "ks = torch.randint(low=0, high=MASK_K_BK, size=(N_H, TDST_BQ), dtype=torch.long)  # Random values as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_tensor = torch.arange(MASK_K_BK, device=indices.device).expand_as(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         ...,\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255]],\n",
      "\n",
      "        [[  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         ...,\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255]],\n",
      "\n",
      "        [[  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         ...,\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         ...,\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255]],\n",
      "\n",
      "        [[  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         ...,\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255]],\n",
      "\n",
      "        [[  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         ...,\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255],\n",
      "         [  0,   1,   2,  ..., 253, 254, 255]]])\n"
     ]
    }
   ],
   "source": [
    "print(range_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 128, 256])\n",
      "tensor([[ 80, 236, 111,  ..., 242, 252, 193],\n",
      "        [239, 201, 216,  ..., 190, 178,  77],\n",
      "        [155, 173,  67,  ..., 161, 137,  26],\n",
      "        ...,\n",
      "        [  3, 248,  10,  ..., 107,  73, 180],\n",
      "        [ 64,   3, 223,  ..., 181,  30, 131],\n",
      "        [  2,  79,  38,  ...,  87, 118,  95]])\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)\n",
    "print(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 128, 1])\n",
      "tensor([[[ 80],\n",
      "         [236],\n",
      "         [111],\n",
      "         ...,\n",
      "         [242],\n",
      "         [252],\n",
      "         [193]],\n",
      "\n",
      "        [[239],\n",
      "         [201],\n",
      "         [216],\n",
      "         ...,\n",
      "         [190],\n",
      "         [178],\n",
      "         [ 77]],\n",
      "\n",
      "        [[155],\n",
      "         [173],\n",
      "         [ 67],\n",
      "         ...,\n",
      "         [161],\n",
      "         [137],\n",
      "         [ 26]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  3],\n",
      "         [248],\n",
      "         [ 10],\n",
      "         ...,\n",
      "         [107],\n",
      "         [ 73],\n",
      "         [180]],\n",
      "\n",
      "        [[ 64],\n",
      "         [  3],\n",
      "         [223],\n",
      "         ...,\n",
      "         [181],\n",
      "         [ 30],\n",
      "         [131]],\n",
      "\n",
      "        [[  2],\n",
      "         [ 79],\n",
      "         [ 38],\n",
      "         ...,\n",
      "         [ 87],\n",
      "         [118],\n",
      "         [ 95]]])\n",
      "tensor([[[False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[False, False,  True,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [False, False, False,  ...,  True,  True,  True]]])\n",
      "torch.Size([40, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "mask = range_tensor >= ks.unsqueeze(-1)\n",
    "print(ks.unsqueeze(-1).shape)\n",
    "print(ks.unsqueeze(-1))\n",
    "\n",
    "print(mask)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000]],\n",
      "\n",
      "        [[    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000]],\n",
      "\n",
      "        [[    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000]],\n",
      "\n",
      "        [[    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000]],\n",
      "\n",
      "        [[    0,     0, 32000,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000],\n",
      "         [    0,     0,     0,  ..., 32000, 32000, 32000]]])\n"
     ]
    }
   ],
   "source": [
    "indices[mask] = 32000\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15,  2,  5,  1, 18],\n",
      "        [ 5, 17,  3, 15, 10]])\n",
      "The maximum value in ks is: 18\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming ks is your tensor with shape (N_H, TDST_BQ)\n",
    "# Example tensor for demonstration purposes (replace with your tensor)\n",
    "N_H = 2\n",
    "TDST_BQ = 5\n",
    "ks = torch.randint(low=0, high=20, size=(N_H, TDST_BQ))\n",
    "print(ks)\n",
    "# To find the maximum value across the entire tensor\n",
    "max_value = ks.max().item()\n",
    "\n",
    "print(f\"The maximum value in ks is: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5, 0])\n",
      "tensor([], size=(3, 4, 5, 0))\n",
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 5, 1])\n",
      "torch.Size([3, 4, 5, 1])\n",
      "tensor([[[[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ensemble_attn_mask_per_layer = torch.empty(3,4, 5, 0)\n",
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "\n",
    "indices = torch.ones(3,4,5)\n",
    "print(indices.shape)\n",
    "print(indices.unsqueeze(-1).shape)\n",
    "ensemble_attn_mask_per_layer = torch.cat((ensemble_attn_mask_per_layer, indices.unsqueeze(-1)), dim=-1)\n",
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSRC = 5\n",
    "origin_sparsity = (torch.sum(ensemble_attn_mask_per_layer < TSRC)//5).item()\n",
    "\n",
    "origin_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ensemble_attn_mask_per_layer < TSRC).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ensemble_attn_mask_per_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_attn_mask_per_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "ensemble_attn_mask_per_layer = torch.cat(ensemble_attn_mask_per_layer, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([4, 16, 2, 3])\n",
      "Reshaped shape: torch.Size([64, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define an example tensor with the initial shape\n",
    "N_H = 4\n",
    "TDST = 1024\n",
    "BLOCK_SIZE_Q = 64\n",
    "MASK_K_BK = 2\n",
    "ensemble_model_n = 3\n",
    "\n",
    "# Create a tensor with the specified initial shape\n",
    "tensor = torch.rand((N_H, TDST // BLOCK_SIZE_Q, MASK_K_BK, ensemble_model_n))\n",
    "\n",
    "# Calculate new shape\n",
    "new_first_dimension = N_H * (TDST // BLOCK_SIZE_Q)\n",
    "new_last_dimension = MASK_K_BK * ensemble_model_n\n",
    "\n",
    "# Reshape the tensor\n",
    "reshaped_tensor = tensor.view(new_first_dimension, new_last_dimension)\n",
    "\n",
    "print(\"Original shape:\", tensor.shape)  # Output: (4, 16, 2, 3)\n",
    "print(\"Reshaped shape:\", reshaped_tensor.shape)  # Output: (64, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0543, 0.1904, 0.1274, 0.3107, 0.0958, 0.2595],\n",
      "        [0.9638, 0.9202, 0.9052, 0.8515, 0.7359, 0.6152],\n",
      "        [0.2663, 0.6266, 0.4071, 0.0938, 0.9798, 0.4514],\n",
      "        [0.7393, 0.1167, 0.9352, 0.2723, 0.1543, 0.0890],\n",
      "        [0.8946, 0.4289, 0.9273, 0.8273, 0.9801, 0.3374],\n",
      "        [0.9915, 0.9311, 0.9238, 0.2278, 0.5803, 0.4495],\n",
      "        [0.4288, 0.0264, 0.8844, 0.0894, 0.1071, 0.3184],\n",
      "        [0.1842, 0.9013, 0.9048, 0.2102, 0.5804, 0.6663],\n",
      "        [0.0732, 0.4532, 0.6602, 0.6666, 0.4118, 0.5718],\n",
      "        [0.5520, 0.8793, 0.8612, 0.6264, 0.4713, 0.8292],\n",
      "        [0.0932, 0.3912, 0.9973, 0.4357, 0.9339, 0.3855],\n",
      "        [0.0038, 0.6807, 0.6606, 0.1933, 0.2436, 0.8034],\n",
      "        [0.4190, 0.4909, 0.8589, 0.0355, 0.7662, 0.0952],\n",
      "        [0.9935, 0.0621, 0.4886, 0.6496, 0.9542, 0.8495],\n",
      "        [0.4079, 0.1637, 0.0294, 0.7211, 0.7922, 0.2984],\n",
      "        [0.1756, 0.4312, 0.1844, 0.3051, 0.3343, 0.8732],\n",
      "        [0.9312, 0.0740, 0.8891, 0.6068, 0.2214, 0.7877],\n",
      "        [0.8816, 0.8976, 0.2024, 0.0600, 0.8195, 0.8499],\n",
      "        [0.3955, 0.8720, 0.2571, 0.7190, 0.6108, 0.2239],\n",
      "        [0.6414, 0.1273, 0.0444, 0.5058, 0.1828, 0.0079],\n",
      "        [0.5594, 0.7614, 0.4930, 0.3936, 0.3154, 0.8444],\n",
      "        [0.9178, 0.4158, 0.0181, 0.1706, 0.0054, 0.5375],\n",
      "        [0.7161, 0.3817, 0.4470, 0.5911, 0.6589, 0.9465],\n",
      "        [0.1509, 0.9264, 0.9773, 0.7390, 0.1058, 0.6914],\n",
      "        [0.0986, 0.3460, 0.0871, 0.4960, 0.0580, 0.9192],\n",
      "        [0.2281, 0.5089, 0.6671, 0.4153, 0.4195, 0.7898],\n",
      "        [0.5043, 0.6956, 0.2464, 0.5485, 0.2556, 0.3447],\n",
      "        [0.7743, 0.2369, 0.5688, 0.6962, 0.2043, 0.2445],\n",
      "        [0.3928, 0.6338, 0.8521, 0.0302, 0.1138, 0.9714],\n",
      "        [0.4835, 0.6004, 0.6427, 0.2855, 0.9791, 0.6127],\n",
      "        [0.1422, 0.2246, 0.2505, 0.8105, 0.8323, 0.6619],\n",
      "        [0.4086, 0.9405, 0.9955, 0.7691, 0.4982, 0.2913],\n",
      "        [0.7299, 0.4818, 0.6405, 0.0360, 0.6759, 0.0662],\n",
      "        [0.6373, 0.5561, 0.4094, 0.8825, 0.9101, 0.4290],\n",
      "        [0.4351, 0.3945, 0.0772, 0.3932, 0.1905, 0.9306],\n",
      "        [0.6147, 0.1623, 0.1949, 0.2019, 0.6063, 0.0756],\n",
      "        [0.5799, 0.6363, 0.7866, 0.0032, 0.0138, 0.4022],\n",
      "        [0.8293, 0.4705, 0.2276, 0.1605, 0.1983, 0.9595],\n",
      "        [0.7891, 0.6954, 0.6877, 0.8480, 0.1929, 0.8989],\n",
      "        [0.5807, 0.2282, 0.9678, 0.1310, 0.3172, 0.9889],\n",
      "        [0.7265, 0.0551, 0.9806, 0.5830, 0.2540, 0.5790],\n",
      "        [0.0551, 0.4862, 0.2106, 0.8774, 0.4983, 0.3727],\n",
      "        [0.6208, 0.9130, 0.5013, 0.4364, 0.8326, 0.0474],\n",
      "        [0.4175, 0.2255, 0.2896, 0.3655, 0.9292, 0.8060],\n",
      "        [0.3494, 0.7797, 0.2639, 0.1809, 0.2536, 0.1315],\n",
      "        [0.4063, 0.4604, 0.4942, 0.5999, 0.2717, 0.7708],\n",
      "        [0.1091, 0.5700, 0.4239, 0.8511, 0.4185, 0.7984],\n",
      "        [0.4848, 0.8049, 0.4165, 0.9898, 0.8284, 0.9645],\n",
      "        [0.6121, 0.3809, 0.4965, 0.6660, 0.1289, 0.3384],\n",
      "        [0.8024, 0.0749, 0.8606, 0.5105, 0.8985, 0.8824],\n",
      "        [0.5247, 0.6504, 0.7012, 0.2984, 0.8808, 0.0732],\n",
      "        [0.9615, 0.9877, 0.4968, 0.0198, 0.2128, 0.5721],\n",
      "        [0.3961, 0.2300, 0.1038, 0.9799, 0.4105, 0.0872],\n",
      "        [0.8408, 0.3793, 0.9957, 0.8710, 0.8001, 0.0409],\n",
      "        [0.0701, 0.2570, 0.6866, 0.9534, 0.4556, 0.2609],\n",
      "        [0.4742, 0.3439, 0.6940, 0.5685, 0.3670, 0.7604],\n",
      "        [0.3275, 0.6429, 0.4057, 0.3620, 0.9384, 0.1432],\n",
      "        [0.7634, 0.7583, 0.5274, 0.7946, 0.3834, 0.9362],\n",
      "        [0.3931, 0.7206, 0.0809, 0.2352, 0.5610, 0.9784],\n",
      "        [0.0181, 0.7804, 0.0656, 0.6478, 0.3640, 0.9750],\n",
      "        [0.0835, 0.2337, 0.6254, 0.0769, 0.5943, 0.0092],\n",
      "        [0.5885, 0.4190, 0.3227, 0.7317, 0.7986, 0.6125],\n",
      "        [0.6781, 0.0983, 0.6660, 0.0414, 0.5215, 0.9467],\n",
      "        [0.2473, 0.2434, 0.1462, 0.2759, 0.1911, 0.8462]])\n"
     ]
    }
   ],
   "source": [
    "print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0543, 0.0958, 0.1274, 0.1904, 0.2595, 0.3107])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.6152, 0.7359, 0.8515, 0.9052, 0.9202, 0.9638])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0938, 0.2663, 0.4071, 0.4514, 0.6266, 0.9798])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0890, 0.1167, 0.1543, 0.2723, 0.7393, 0.9352])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.3374, 0.4289, 0.8273, 0.8946, 0.9273, 0.9801])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2278, 0.4495, 0.5803, 0.9238, 0.9311, 0.9915])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0264, 0.0894, 0.1071, 0.3184, 0.4288, 0.8844])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1842, 0.2102, 0.5804, 0.6663, 0.9013, 0.9048])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0732, 0.4118, 0.4532, 0.5718, 0.6602, 0.6666])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.4713, 0.5520, 0.6264, 0.8292, 0.8612, 0.8793])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0932, 0.3855, 0.3912, 0.4357, 0.9339, 0.9973])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0038, 0.1933, 0.2436, 0.6606, 0.6807, 0.8034])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0355, 0.0952, 0.4190, 0.4909, 0.7662, 0.8589])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0621, 0.4886, 0.6496, 0.8495, 0.9542, 0.9935])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0294, 0.1637, 0.2984, 0.4079, 0.7211, 0.7922])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1756, 0.1844, 0.3051, 0.3343, 0.4312, 0.8732])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0740, 0.2214, 0.6068, 0.7877, 0.8891, 0.9312])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0600, 0.2024, 0.8195, 0.8499, 0.8816, 0.8976])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2239, 0.2571, 0.3955, 0.6108, 0.7190, 0.8720])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0079, 0.0444, 0.1273, 0.1828, 0.5058, 0.6414])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.3154, 0.3936, 0.4930, 0.5594, 0.7614, 0.8444])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0054, 0.0181, 0.1706, 0.4158, 0.5375, 0.9178])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.3817, 0.4470, 0.5911, 0.6589, 0.7161, 0.9465])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1058, 0.1509, 0.6914, 0.7390, 0.9264, 0.9773])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0580, 0.0871, 0.0986, 0.3460, 0.4960, 0.9192])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2281, 0.4153, 0.4195, 0.5089, 0.6671, 0.7898])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2464, 0.2556, 0.3447, 0.5043, 0.5485, 0.6956])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2043, 0.2369, 0.2445, 0.5688, 0.6962, 0.7743])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0302, 0.1138, 0.3928, 0.6338, 0.8521, 0.9714])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2855, 0.4835, 0.6004, 0.6127, 0.6427, 0.9791])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1422, 0.2246, 0.2505, 0.6619, 0.8105, 0.8323])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2913, 0.4086, 0.4982, 0.7691, 0.9405, 0.9955])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0360, 0.0662, 0.4818, 0.6405, 0.6759, 0.7299])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.4094, 0.4290, 0.5561, 0.6373, 0.8825, 0.9101])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0772, 0.1905, 0.3932, 0.3945, 0.4351, 0.9306])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0756, 0.1623, 0.1949, 0.2019, 0.6063, 0.6147])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0032, 0.0138, 0.4022, 0.5799, 0.6363, 0.7866])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1605, 0.1983, 0.2276, 0.4705, 0.8293, 0.9595])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1929, 0.6877, 0.6954, 0.7891, 0.8480, 0.8989])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1310, 0.2282, 0.3172, 0.5807, 0.9678, 0.9889])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0551, 0.2540, 0.5790, 0.5830, 0.7265, 0.9806])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0551, 0.2106, 0.3727, 0.4862, 0.4983, 0.8774])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0474, 0.4364, 0.5013, 0.6208, 0.8326, 0.9130])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2255, 0.2896, 0.3655, 0.4175, 0.8060, 0.9292])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1315, 0.1809, 0.2536, 0.2639, 0.3494, 0.7797])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.2717, 0.4063, 0.4604, 0.4942, 0.5999, 0.7708])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1091, 0.4185, 0.4239, 0.5700, 0.7984, 0.8511])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.4165, 0.4848, 0.8049, 0.8284, 0.9645, 0.9898])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1289, 0.3384, 0.3809, 0.4965, 0.6121, 0.6660])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0749, 0.5105, 0.8024, 0.8606, 0.8824, 0.8985])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0732, 0.2984, 0.5247, 0.6504, 0.7012, 0.8808])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0198, 0.2128, 0.4968, 0.5721, 0.9615, 0.9877])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0872, 0.1038, 0.2300, 0.3961, 0.4105, 0.9799])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0409, 0.3793, 0.8001, 0.8408, 0.8710, 0.9957])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0701, 0.2570, 0.2609, 0.4556, 0.6866, 0.9534])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.3439, 0.3670, 0.4742, 0.5685, 0.6940, 0.7604])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1432, 0.3275, 0.3620, 0.4057, 0.6429, 0.9384])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.3834, 0.5274, 0.7583, 0.7634, 0.7946, 0.9362])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0809, 0.2352, 0.3931, 0.5610, 0.7206, 0.9784])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0181, 0.0656, 0.3640, 0.6478, 0.7804, 0.9750])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0092, 0.0769, 0.0835, 0.2337, 0.5943, 0.6254])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.3227, 0.4190, 0.5885, 0.6125, 0.7317, 0.7986])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.0414, 0.0983, 0.5215, 0.6660, 0.6781, 0.9467])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n",
      "tensor([0.1462, 0.1911, 0.2434, 0.2473, 0.2759, 0.8462])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "for r in reshaped_tensor:\n",
    "    unique_ensemble, counts = torch.unique(r, sorted=True, return_counts=True)\n",
    "    print(unique_ensemble)\n",
    "    print(counts)\n",
    "    print(\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "tensor([3, 3, 4, 7, 4, 3])\n",
      "tensor([3, 2, 4, 0, 1, 5])\n",
      "tensor([3, 2, 4, 0, 1, 5])\n",
      "tensor([7, 4, 4, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,3,4,3,2,2,3,1,0,0,0,5], [3,3,2,4,5,4,3,2,1,3,4,5]])\n",
    "\n",
    "e, s = torch.unique(t, sorted=True, return_counts=True)\n",
    "print(e)\n",
    "print(s)\n",
    "\n",
    "sorted_indices = torch.argsort(s, descending=True)\n",
    "sorted_unique_values = e[sorted_indices]\n",
    "sorted_counts = s[sorted_indices]\n",
    "print(sorted_indices)\n",
    "print(sorted_unique_values)\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [3, 4, 3, 5],\n",
      "        [6, 6, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example 2D tensor\n",
    "tensor = torch.tensor([\n",
    "    [1, 2, 2, 3],\n",
    "    [4, 5, 4, 6],\n",
    "    [7, 7, 8, 8]\n",
    "])\n",
    "\n",
    "# Reshape to flatten and retrieve unique values with indices\n",
    "unique_elements, unique_indices = torch.unique(tensor, return_inverse=True)\n",
    "print(unique_elements)\n",
    "print(unique_indices)\n",
    "# split_indices = torch.cumsum(torch.bincount(unique_indices[:-1]), dim=0)\n",
    "\n",
    "# # Unique values per row\n",
    "# unique_values_per_row = torch.split(unique_elements, split_indices.tolist())\n",
    "\n",
    "# print(\"Unique values for each row:\", unique_values_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Ensemble (2D):\n",
      "tensor([[10, 20, 30, 40],\n",
      "        [15, 25, 35, 45]])\n",
      "Ensemble Counts (2D):\n",
      "tensor([[ 5, 15, 10,  8],\n",
      "        [10, 20, 30, 40]])\n",
      "tensor([[False,  True, False, False],\n",
      "        [False,  True,  True,  True]])\n",
      "Filtered unique ensemble: tensor([20, 25, 35, 45])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example 1: Two-dimensional tensors with unique elements and counts\n",
    "# This could represent unique values and their counts from multiple runs or batches\n",
    "\n",
    "# Two-dimensional tensor for unique elements\n",
    "unique_ensemble = torch.tensor([\n",
    "    [10, 20, 30, 40],  # First set of unique elements\n",
    "    [15, 25, 35, 45]   # Second set of unique elements\n",
    "])\n",
    "\n",
    "# Two-dimensional tensor for corresponding counts\n",
    "ensemble_cnt = torch.tensor([\n",
    "    [5, 15, 10, 8],  # Corresponding counts for the first set\n",
    "    [10, 20, 30, 40]  # Corresponding counts for the second set\n",
    "])\n",
    "\n",
    "print(\"Unique Ensemble (2D):\")\n",
    "print(unique_ensemble)\n",
    "\n",
    "print(\"Ensemble Counts (2D):\")\n",
    "print(ensemble_cnt)\n",
    "\n",
    "ensemble_method_final_inter_thresh = 15\n",
    "\n",
    "# Create a boolean mask to filter elements based on the threshold\n",
    "mask = ensemble_cnt >= ensemble_method_final_inter_thresh\n",
    "\n",
    "# Apply the mask to `unique_ensemble` to get the filtered elements\n",
    "filtered_unique_ensemble = unique_ensemble[mask]\n",
    "print(mask)\n",
    "print(\"Filtered unique ensemble:\", filtered_unique_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1835e-41, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1,3,4,3,2,2,3,1,0,0,0,5])\n",
    "\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original tensor\n",
    "tensor = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "# Tensor to be added\n",
    "new_elements = torch.tensor([\n",
    "    [5, 6]\n",
    "])\n",
    "\n",
    "# Concatenate along rows (dim=0)\n",
    "result = torch.cat((tensor, new_elements), dim=0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 2] at entry 0 and [1, 2] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m new_elements \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m     10\u001b[0m ])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Stack along a new axis\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_elements\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 2] at entry 0 and [1, 2] at entry 1"
     ]
    }
   ],
   "source": [
    "# Original tensor\n",
    "tensor = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "# Tensor to be added\n",
    "new_elements = torch.tensor([\n",
    "    [5, 6]\n",
    "])\n",
    "\n",
    "# Stack along a new axis\n",
    "result = torch.stack((tensor, new_elements), dim=0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n"
     ]
    }
   ],
   "source": [
    "# Two tensors with the same shape\n",
    "tensor1 = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "\n",
    "tensor2 = torch.tensor([\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "# Stacking along a new dimension\n",
    "result = torch.stack((tensor1, tensor2), dim=0)  # Works because shapes are identical\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.tensor(\n",
    "    [1, 2, 3],)\n",
    "\n",
    "tensor1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.tensor([32000, 32000, 32000])\n",
    "\n",
    "torch.all(test_tensor == 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.load('../../cache/timber/qkv.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4096, 128])\n",
      "torch.Size([32, 4096, 128])\n",
      "torch.Size([32, 4096, 128])\n",
      "512\n",
      "32\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(t['q'].shape)\n",
    "print(t['k'].shape)\n",
    "print(t['v'].shape)\n",
    "print(t['mask_k'])\n",
    "print(t['block_size_q'])\n",
    "print(t['block_size_k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m unique_x, indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique_consecutive(x, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m indices \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mmin(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "x = tensor([[3, 3, 5, 5, 5],\n",
    "        [3, 3, 2, 2, 3]])\n",
    "unique_x, indices = torch.unique_consecutive(x, return_inverse=True)\n",
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "result = -torch.ones_like(x)\n",
    "result = result.scatter_(1, indices, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[3, 3, 5, 5, 5],\n",
    "            [3, 3, 2, 2, 3]])\n",
    "unique_x, indices, cnt = torch.unique_consecutive(x, return_inverse=True, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 3, 2, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1],\n",
       "        [2, 2, 3, 3, 4]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 2, 2, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "result = -torch.ones_like(x)\n",
    "result = result.scatter_(1, indices, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 5, 5, 5],\n",
       "        [3, 3, 2, 2, 3]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 3, 2, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 2]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  5, -1, -1, -1],\n",
       "        [ 3,  2,  3, -1, -1]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 1, 5, 5, 5, 2],\n",
    "            [3, 3, 2, 2, 2, 2]])\n",
    "unique_x, indices, unique_cnt = torch.unique(x, return_inverse=True, sorted=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 2, 3])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 5])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 3, 3, 3, 1],\n",
       "        [2, 2, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 3, 3, 3, 1],\n",
      "        [1, 1, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 0, 3],\n",
       "        [0, 4, 2, 0]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_x = (unique_x[None, None, :] == x[:, :, None]).long().sum(1)\n",
    "cnt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 3, 3, 3, 1],\n",
       "        [1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 5, 5, 5, 2],\n",
       "        [3, 3, 2, 2, 2, 2]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     2, 32000,     5, 32000, 32000],\n",
       "        [    2,     3, 32000, 32000, 32000, 32000]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = -torch.ones_like(x)\n",
    "result = torch.full_like(x, 32000)\n",
    "result = result.scatter_(1, indices, x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9999999,        1, -9999999,        3, -9999999, -9999999],\n",
       "        [       4,        2, -9999999, -9999999, -9999999, -9999999]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = result[:, :, None] == unique_x[None, None, :]\n",
    "t = t * torch.arange(len(unique_x))[None, None, :]\n",
    "t = t.sum(-1)\n",
    "result_cnt = torch.where(result > 0, cnt_x.gather(-1, t), -9999999)\n",
    "result_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[       3,        1, -9999999, -9999999, -9999999, -9999999],\n",
       "         [       4,        2, -9999999, -9999999, -9999999, -9999999]]),\n",
       " tensor([[ 5,  2,  0, -1, -1, -1],\n",
       "         [ 2,  3, -1, -1, -1, -1]]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "result_sorted = result.gather(-1, indices)\n",
    "result_cnt_sorted, result_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = -torch.ones(x)\n",
    "cnt = cnt.scatter_(1, indices, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 5])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 2, 2, 2, 0],\n",
       "        [1, 1, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3,  5, -1, -1, -1],\n",
       "        [ 2,  3, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 3])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cnt\n",
    "# cnt: [2, 3, 1], [2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 3, 5]),\n",
       " tensor([[0, 0, 3, 3, 3, 1],\n",
       "         [2, 2, 1, 1, 0, 1]]),\n",
       " tensor([3, 4, 2, 3]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0, 0, 5, 5, 5, 2],\n",
    "            [3, 3, 2, 2, 0, 2]])\n",
    "\n",
    "unique_x, indices, unique_cnt = torch.unique(x, return_inverse=True, sorted=False, return_counts=True)\n",
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "unique_x, indices, unique_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 2, 3, 5]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_x[None, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [0],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [2]],\n",
       "\n",
       "        [[3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [0],\n",
       "         [2]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 0, 3],\n",
       "        [1, 3, 2, 0]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_x = (unique_x[None, None, :] == x[:, :, None]).long().sum(1)\n",
    "cnt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2, -1,  5, -1, -1],\n",
       "        [ 0,  2,  3, -1, -1, -1]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = -torch.ones_like(x)\n",
    "result = result.scatter_(1, indices, x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 3, 0, 0],\n",
      "        [0, 1, 2, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "t = result[:, :, None] == unique_x[None, None, :]\n",
    "t = t * torch.arange(len(unique_x))[None, None, :]\n",
    "t = t.sum(-1)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cnt = torch.where(result > 0, cnt_x.gather(-1, t), -9999999)\n",
    "result_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "result_sorted = result.gather(-1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9999999,        1, -9999999,        3, -9999999, -9999999],\n",
       "        [-9999999,        3,        2, -9999999, -9999999, -9999999]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  2,  0, -1, -1, -1],\n",
       "        [ 2,  3,  0, -1, -1, -1]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[       3,        1, -9999999, -9999999, -9999999, -9999999],\n",
       "         [       3,        2, -9999999, -9999999, -9999999, -9999999]]),\n",
       " tensor([[ 5,  2,  0, -1, -1, -1],\n",
       "         [ 2,  3,  0, -1, -1, -1]]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cnt_sorted, result_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  5, -1, -1, -1],\n",
       "        [ 3,  2,  3, -1, -1]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0, 0, 5, 5, 5],\n",
    "            [3, 3, 4, 4, 6]])\n",
    "unique_x, indices = torch.unique_consecutive(x, return_inverse=True)\n",
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "result = -torch.ones_like(x)\n",
    "result = result.scatter_(1, indices, x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_attn_mask_per_layer = torch.tensor([[1, 1, 3, 3, 3, 5],\n",
    "            [3, 3, 4, 4, 4, 4]])\n",
    "\n",
    "unique_x, indices, unique_cnt = torch.unique_consecutive(ensemble_attn_mask_per_layer, return_inverse=True, return_counts=True)\n",
    "indices -= indices.min(dim=1, keepdims=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1, 2],\n",
       "        [0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_attn_mask_per_layer = torch.tensor([[1, 1, 3, 3, 3, 5,6,6,6,6,8,8,8,10,10,10,10,10,10, 11],\n",
    "            [3, 3, 4, 4, 4, 4,5,5,5,5,5,5,6,6,7,7,7,9,9,9]])\n",
    "\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, return_inverse=True, return_counts=True)\n",
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "result = -torch.ones_like(ensemble_attn_mask_per_layer)\n",
    "# result = torch.full_like(ensemble_attn_mask_per_layer, 32000)\n",
    "result = result.scatter_(1, indices, ensemble_attn_mask_per_layer)\n",
    "t = result[:, :, None] == unique_x[None, None, :]\n",
    "t = t * torch.arange(len(unique_x))[None, None, :]\n",
    "t = t.sum(-1)\n",
    "result_cnt = torch.where(result > 0, cnt_x.gather(-1, t), -9999999)\n",
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[       6,        4,        3,        3,        2,        1,        1,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "         [       6,        4,        3,        3,        2,        2, -9999999,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999]]),\n",
       " tensor([[10,  6,  3,  8,  1,  5, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1],\n",
       "         [ 5,  4,  7,  9,  6,  3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1]]))"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cnt_sorted, ensemble_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_attn_mask_per_layer = torch.tensor([[1, 1, 3, 3, 3, 5,6,6,6,6,8,8,8,10,10,10,10,10,10, 11],\n",
    "            [3, 3, 4, 4, 4, 4,5,5,5,5,5,5,6,6,7,7,7,9,9,9]])\n",
    "\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, return_inverse=True, return_counts=True)\n",
    "indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "# result = -torch.ones_like(ensemble_attn_mask_per_layer)\n",
    "result = torch.full_like(ensemble_attn_mask_per_layer, 32000)\n",
    "result = result.scatter_(1, indices, ensemble_attn_mask_per_layer)\n",
    "t = result[:, :, None] == unique_x[None, None, :]\n",
    "t = t * torch.arange(len(unique_x))[None, None, :]\n",
    "t = t.sum(-1)\n",
    "result_cnt = torch.where(result < 32000, cnt_x.gather(-1, t), -9999999)\n",
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[       6,        4,        3,        3,        2,        1,        1,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "         [       6,        4,        3,        3,        2,        2, -9999999,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "          -9999999, -9999999, -9999999, -9999999, -9999999, -9999999]]),\n",
       " tensor([[   10,     6,     3,     8,     1,     5,    11, 32000, 32000, 32000,\n",
       "          32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000],\n",
       "         [    5,     4,     7,     9,     6,     3, 32000, 32000, 32000, 32000,\n",
       "          32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000]]))"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ensemble_cnt_sorted, ensemble_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_method_final_inter_thresh = 2\n",
    "mask =  ensemble_cnt_sorted>= ensemble_method_final_inter_thresh\n",
    "print(mask)\n",
    "mask.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6,  3,  8,  1,  5, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1],\n",
       "        [ 5,  4,  7,  9,  6,  3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6,  3,  8,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1],\n",
       "        [ 5,  4,  7,  9,  6,  3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.where(mask, ensemble_sorted, torch.tensor(-1))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  4,  3,  3,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1],\n",
       "        [ 6,  4,  3,  3,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cnt_filtered = torch.where(mask, ensemble_cnt_sorted, torch.tensor(-1))\n",
    "ensemble_cnt_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "view() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (torch.dtype dtype)\n      didn't match because some of the arguments have invalid types: (!Tensor!)\n * (tuple of ints size)\n      didn't match because some of the arguments have invalid types: (!Tensor!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[325], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mensemble_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (torch.dtype dtype)\n      didn't match because some of the arguments have invalid types: (!Tensor!)\n * (tuple of ints size)\n      didn't match because some of the arguments have invalid types: (!Tensor!)\n"
     ]
    }
   ],
   "source": [
    "ensemble_sorted[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4, 3, 3, 2, 6, 4, 3, 3, 2, 2])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cnt_sorted[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First index where all rows have -1: 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Given tensor\n",
    "tensor = torch.tensor([\n",
    "    [6, 4, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [6, 4, 3, 3, 2, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "])\n",
    "\n",
    "# Create a mask for positions with -1\n",
    "is_negative_one = tensor == -1\n",
    "\n",
    "# Get the first index where all rows contain -1\n",
    "# Calculate the indices of the first -1 for each row\n",
    "first_negative_one_indices = is_negative_one.int().argmax(dim=1)\n",
    "\n",
    "# Find the minimum index across all rows where -1 starts\n",
    "first_all_negative_one_index = first_negative_one_indices.min()\n",
    "\n",
    "print(\"First index where all rows have -1:\", first_all_negative_one_index.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(4, 32, 32, 0))\n",
      "Updated shape: torch.Size([4, 32, 32, 1])\n",
      "tensor([[[[0.0000e+00],\n",
      "          [1.0000e+00],\n",
      "          [2.0000e+00],\n",
      "          ...,\n",
      "          [2.9000e+01],\n",
      "          [3.0000e+01],\n",
      "          [3.1000e+01]],\n",
      "\n",
      "         [[3.2000e+01],\n",
      "          [3.3000e+01],\n",
      "          [3.4000e+01],\n",
      "          ...,\n",
      "          [6.1000e+01],\n",
      "          [6.2000e+01],\n",
      "          [6.3000e+01]],\n",
      "\n",
      "         [[6.4000e+01],\n",
      "          [6.5000e+01],\n",
      "          [6.6000e+01],\n",
      "          ...,\n",
      "          [9.3000e+01],\n",
      "          [9.4000e+01],\n",
      "          [9.5000e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[9.2800e+02],\n",
      "          [9.2900e+02],\n",
      "          [9.3000e+02],\n",
      "          ...,\n",
      "          [9.5700e+02],\n",
      "          [9.5800e+02],\n",
      "          [9.5900e+02]],\n",
      "\n",
      "         [[9.6000e+02],\n",
      "          [9.6100e+02],\n",
      "          [9.6200e+02],\n",
      "          ...,\n",
      "          [9.8900e+02],\n",
      "          [9.9000e+02],\n",
      "          [9.9100e+02]],\n",
      "\n",
      "         [[9.9200e+02],\n",
      "          [9.9300e+02],\n",
      "          [9.9400e+02],\n",
      "          ...,\n",
      "          [1.0210e+03],\n",
      "          [1.0220e+03],\n",
      "          [1.0230e+03]]],\n",
      "\n",
      "\n",
      "        [[[1.0240e+03],\n",
      "          [1.0250e+03],\n",
      "          [1.0260e+03],\n",
      "          ...,\n",
      "          [1.0530e+03],\n",
      "          [1.0540e+03],\n",
      "          [1.0550e+03]],\n",
      "\n",
      "         [[1.0560e+03],\n",
      "          [1.0570e+03],\n",
      "          [1.0580e+03],\n",
      "          ...,\n",
      "          [1.0850e+03],\n",
      "          [1.0860e+03],\n",
      "          [1.0870e+03]],\n",
      "\n",
      "         [[1.0880e+03],\n",
      "          [1.0890e+03],\n",
      "          [1.0900e+03],\n",
      "          ...,\n",
      "          [1.1170e+03],\n",
      "          [1.1180e+03],\n",
      "          [1.1190e+03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.9520e+03],\n",
      "          [1.9530e+03],\n",
      "          [1.9540e+03],\n",
      "          ...,\n",
      "          [1.9810e+03],\n",
      "          [1.9820e+03],\n",
      "          [1.9830e+03]],\n",
      "\n",
      "         [[1.9840e+03],\n",
      "          [1.9850e+03],\n",
      "          [1.9860e+03],\n",
      "          ...,\n",
      "          [2.0130e+03],\n",
      "          [2.0140e+03],\n",
      "          [2.0150e+03]],\n",
      "\n",
      "         [[2.0160e+03],\n",
      "          [2.0170e+03],\n",
      "          [2.0180e+03],\n",
      "          ...,\n",
      "          [2.0450e+03],\n",
      "          [2.0460e+03],\n",
      "          [2.0470e+03]]],\n",
      "\n",
      "\n",
      "        [[[2.0480e+03],\n",
      "          [2.0490e+03],\n",
      "          [2.0500e+03],\n",
      "          ...,\n",
      "          [2.0770e+03],\n",
      "          [2.0780e+03],\n",
      "          [2.0790e+03]],\n",
      "\n",
      "         [[2.0800e+03],\n",
      "          [2.0810e+03],\n",
      "          [2.0820e+03],\n",
      "          ...,\n",
      "          [2.1090e+03],\n",
      "          [2.1100e+03],\n",
      "          [2.1110e+03]],\n",
      "\n",
      "         [[2.1120e+03],\n",
      "          [2.1130e+03],\n",
      "          [2.1140e+03],\n",
      "          ...,\n",
      "          [2.1410e+03],\n",
      "          [2.1420e+03],\n",
      "          [2.1430e+03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.9760e+03],\n",
      "          [2.9770e+03],\n",
      "          [2.9780e+03],\n",
      "          ...,\n",
      "          [3.0050e+03],\n",
      "          [3.0060e+03],\n",
      "          [3.0070e+03]],\n",
      "\n",
      "         [[3.0080e+03],\n",
      "          [3.0090e+03],\n",
      "          [3.0100e+03],\n",
      "          ...,\n",
      "          [3.0370e+03],\n",
      "          [3.0380e+03],\n",
      "          [3.0390e+03]],\n",
      "\n",
      "         [[3.0400e+03],\n",
      "          [3.0410e+03],\n",
      "          [3.0420e+03],\n",
      "          ...,\n",
      "          [3.0690e+03],\n",
      "          [3.0700e+03],\n",
      "          [3.0710e+03]]],\n",
      "\n",
      "\n",
      "        [[[3.0720e+03],\n",
      "          [3.0730e+03],\n",
      "          [3.0740e+03],\n",
      "          ...,\n",
      "          [3.1010e+03],\n",
      "          [3.1020e+03],\n",
      "          [3.1030e+03]],\n",
      "\n",
      "         [[3.1040e+03],\n",
      "          [3.1050e+03],\n",
      "          [3.1060e+03],\n",
      "          ...,\n",
      "          [3.1330e+03],\n",
      "          [3.1340e+03],\n",
      "          [3.1350e+03]],\n",
      "\n",
      "         [[3.1360e+03],\n",
      "          [3.1370e+03],\n",
      "          [3.1380e+03],\n",
      "          ...,\n",
      "          [3.1650e+03],\n",
      "          [3.1660e+03],\n",
      "          [3.1670e+03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.0000e+03],\n",
      "          [4.0010e+03],\n",
      "          [4.0020e+03],\n",
      "          ...,\n",
      "          [4.0290e+03],\n",
      "          [4.0300e+03],\n",
      "          [4.0310e+03]],\n",
      "\n",
      "         [[4.0320e+03],\n",
      "          [4.0330e+03],\n",
      "          [4.0340e+03],\n",
      "          ...,\n",
      "          [4.0610e+03],\n",
      "          [4.0620e+03],\n",
      "          [4.0630e+03]],\n",
      "\n",
      "         [[4.0640e+03],\n",
      "          [4.0650e+03],\n",
      "          [4.0660e+03],\n",
      "          ...,\n",
      "          [4.0930e+03],\n",
      "          [4.0940e+03],\n",
      "          [4.0950e+03]]]])\n",
      "tensor([[[   0,    1,    2,  ...,   29,   30,   31],\n",
      "         [  32,   33,   34,  ...,   61,   62,   63],\n",
      "         [  64,   65,   66,  ...,   93,   94,   95],\n",
      "         ...,\n",
      "         [ 928,  929,  930,  ...,  957,  958,  959],\n",
      "         [ 960,  961,  962,  ...,  989,  990,  991],\n",
      "         [ 992,  993,  994,  ..., 1021, 1022, 1023]],\n",
      "\n",
      "        [[1024, 1025, 1026,  ..., 1053, 1054, 1055],\n",
      "         [1056, 1057, 1058,  ..., 1085, 1086, 1087],\n",
      "         [1088, 1089, 1090,  ..., 1117, 1118, 1119],\n",
      "         ...,\n",
      "         [1952, 1953, 1954,  ..., 1981, 1982, 1983],\n",
      "         [1984, 1985, 1986,  ..., 2013, 2014, 2015],\n",
      "         [2016, 2017, 2018,  ..., 2045, 2046, 2047]],\n",
      "\n",
      "        [[2048, 2049, 2050,  ..., 2077, 2078, 2079],\n",
      "         [2080, 2081, 2082,  ..., 2109, 2110, 2111],\n",
      "         [2112, 2113, 2114,  ..., 2141, 2142, 2143],\n",
      "         ...,\n",
      "         [2976, 2977, 2978,  ..., 3005, 3006, 3007],\n",
      "         [3008, 3009, 3010,  ..., 3037, 3038, 3039],\n",
      "         [3040, 3041, 3042,  ..., 3069, 3070, 3071]],\n",
      "\n",
      "        [[3072, 3073, 3074,  ..., 3101, 3102, 3103],\n",
      "         [3104, 3105, 3106,  ..., 3133, 3134, 3135],\n",
      "         [3136, 3137, 3138,  ..., 3165, 3166, 3167],\n",
      "         ...,\n",
      "         [4000, 4001, 4002,  ..., 4029, 4030, 4031],\n",
      "         [4032, 4033, 4034,  ..., 4061, 4062, 4063],\n",
      "         [4064, 4065, 4066,  ..., 4093, 4094, 4095]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Shape parameters\n",
    "N = 4  # Batch size\n",
    "T_DST = 128\n",
    "mask_k = 256\n",
    "block_size_q = 4\n",
    "block_size_k = 8\n",
    "\n",
    "# Create a sample tensor for indices with the given shape\n",
    "indices = torch.arange(N * (T_DST // block_size_q) * (mask_k // block_size_k)).view(N, T_DST // block_size_q, mask_k // block_size_k)\n",
    "\n",
    "# Create the ensemble_attn_mask_per_layer tensor with an initial shape (last dimension is 0)\n",
    "ensemble_attn_mask_per_layer = torch.empty((N, T_DST // block_size_q, mask_k // block_size_k, 0))\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "# Concatenate the indices tensor along the last dimension of ensemble_attn_mask_per_layer\n",
    "ensemble_attn_mask_per_layer = torch.cat((ensemble_attn_mask_per_layer, indices.unsqueeze(-1)), dim=-1)\n",
    "\n",
    "# Now the shape should be (N, T_DST // block_size_q, mask_k // block_size_k, 1)\n",
    "print(\"Updated shape:\", ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "print(indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
