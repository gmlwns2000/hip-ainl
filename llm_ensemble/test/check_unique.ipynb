{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# from timber.trainer.timber_trainer import load_model\n",
    "import torch\n",
    "import os\n",
    "\n",
    "_N_H = 3\n",
    "TDST_BQ = 5\n",
    "MASK_K_BK = 4\n",
    "MODEL_N = 3\n",
    "ensemble_final_timedim = 3\n",
    "\n",
    "ensemble_attn_mask_per_layer = torch.randint(1, 11, (_N_H, TDST_BQ, MASK_K_BK, MODEL_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 4, 3])\n",
      "tensor([[[[ 2,  1,  2],\n",
      "          [10,  8,  1],\n",
      "          [10,  5,  4],\n",
      "          [ 1,  3,  5]],\n",
      "\n",
      "         [[ 1,  9,  8],\n",
      "          [ 4,  7,  9],\n",
      "          [ 1,  6,  5],\n",
      "          [ 1,  2,  9]],\n",
      "\n",
      "         [[ 2,  4,  2],\n",
      "          [ 6,  1,  1],\n",
      "          [10,  7,  9],\n",
      "          [ 7,  9,  6]],\n",
      "\n",
      "         [[ 9,  8,  8],\n",
      "          [ 7,  6,  5],\n",
      "          [ 6,  3,  4],\n",
      "          [ 1,  2,  9]],\n",
      "\n",
      "         [[ 5, 10,  3],\n",
      "          [10,  3,  5],\n",
      "          [ 7,  6,  8],\n",
      "          [ 8,  3,  1]]],\n",
      "\n",
      "\n",
      "        [[[ 3,  1,  7],\n",
      "          [ 5,  1,  1],\n",
      "          [ 4,  7,  5],\n",
      "          [ 4,  5,  9]],\n",
      "\n",
      "         [[ 5, 10,  3],\n",
      "          [ 2,  9,  5],\n",
      "          [ 7,  7,  4],\n",
      "          [ 3,  6,  5]],\n",
      "\n",
      "         [[ 6,  7,  4],\n",
      "          [10,  5,  6],\n",
      "          [10, 10,  7],\n",
      "          [ 7,  8,  3]],\n",
      "\n",
      "         [[ 1,  3,  8],\n",
      "          [10,  4,  6],\n",
      "          [ 4,  7, 10],\n",
      "          [ 7,  4,  1]],\n",
      "\n",
      "         [[ 3,  2,  5],\n",
      "          [ 3,  8,  2],\n",
      "          [ 3,  7,  9],\n",
      "          [ 4,  7,  7]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  1,  3],\n",
      "          [10,  7,  8],\n",
      "          [ 1,  2,  1],\n",
      "          [ 8,  1,  5]],\n",
      "\n",
      "         [[ 9, 10,  5],\n",
      "          [ 3, 10,  4],\n",
      "          [ 7,  8,  4],\n",
      "          [ 8,  4,  2]],\n",
      "\n",
      "         [[ 3,  3,  2],\n",
      "          [ 6,  6, 10],\n",
      "          [ 2,  5,  2],\n",
      "          [ 6,  6,  9]],\n",
      "\n",
      "         [[10,  2,  5],\n",
      "          [ 7,  5,  8],\n",
      "          [ 9,  9,  7],\n",
      "          [ 5,  8,  9]],\n",
      "\n",
      "         [[ 7,  5,  3],\n",
      "          [ 7,  1,  5],\n",
      "          [ 9,  6,  9],\n",
      "          [ 1,  4,  2]]]])\n",
      "torch.Size([6, 36])\n",
      "tensor([[      2,       1,       2,      10,       8,       1,      10,       5,\n",
      "               4,       1,       3,       5,       1,       9,       8,       4,\n",
      "               7,       9,       1,       6,       5,       1,       2,       9,\n",
      "               2,       4,       2,       6,       1,       1,      10,       7,\n",
      "               9,       7,       9,       6],\n",
      "        [      9,       8,       8,       7,       6,       5,       6,       3,\n",
      "               4,       1,       2,       9,       5,      10,       3,      10,\n",
      "               3,       5,       7,       6,       8,       8,       3,       1,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [      3,       1,       7,       5,       1,       1,       4,       7,\n",
      "               5,       4,       5,       9,       5,      10,       3,       2,\n",
      "               9,       5,       7,       7,       4,       3,       6,       5,\n",
      "               6,       7,       4,      10,       5,       6,      10,      10,\n",
      "               7,       7,       8,       3],\n",
      "        [      1,       3,       8,      10,       4,       6,       4,       7,\n",
      "              10,       7,       4,       1,       3,       2,       5,       3,\n",
      "               8,       2,       3,       7,       9,       4,       7,       7,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [      6,       1,       3,      10,       7,       8,       1,       2,\n",
      "               1,       8,       1,       5,       9,      10,       5,       3,\n",
      "              10,       4,       7,       8,       4,       8,       4,       2,\n",
      "               3,       3,       2,       6,       6,      10,       2,       5,\n",
      "               2,       6,       6,       9],\n",
      "        [     10,       2,       5,       7,       5,       8,       9,       9,\n",
      "               7,       5,       8,       9,       7,       5,       3,       7,\n",
      "               1,       5,       9,       6,       9,       1,       4,       2,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999]])\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "\n",
    "TDST_BQ_TIMEDIM = TDST_BQ // ensemble_final_timedim\n",
    "timedim_leftover = TDST_BQ % ensemble_final_timedim\n",
    "\n",
    "if timedim_leftover > 0:\n",
    "    TDST_BQ_TIMEDIM += 1\n",
    "    padding_tensor = torch.full((_N_H, ensemble_final_timedim - timedim_leftover, MASK_K_BK, MODEL_N), 9999999)\n",
    "    TDST_BQ += ensemble_final_timedim - timedim_leftover\n",
    "    ensemble_attn_mask_per_layer = torch.cat((ensemble_attn_mask_per_layer, padding_tensor), dim=1)\n",
    "\n",
    "assert ensemble_attn_mask_per_layer.shape == (_N_H, TDST_BQ, MASK_K_BK, MODEL_N)\n",
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H, TDST_BQ, MASK_K_BK, MODEL_N)\n",
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H * TDST_BQ, MASK_K_BK * MODEL_N)\n",
    "assert TDST_BQ % ensemble_final_timedim == 0\n",
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view((_N_H * TDST_BQ)//ensemble_final_timedim, MASK_K_BK * MODEL_N * ensemble_final_timedim)\n",
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "\n",
    "\n",
    "# ensemble_attn_mask_per_layer : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, return_inverse=True, sorted=False, return_counts=True)\n",
    "# indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "\n",
    "# cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "N, K = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "cnt_xs = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    cnt_xs.append(\n",
    "        (unique_x[None, None, :] == ensemble_attn_mask_per_layer[icn*chunk_n:icn*chunk_n+chunk_n, :, None]).long().sum(1)\n",
    "    )\n",
    "cnt_x = torch.cat(cnt_xs, dim=0)\n",
    "\n",
    "\n",
    "result = torch.full_like(ensemble_attn_mask_per_layer, 9999999)\n",
    "result = result.scatter_(1, indices.clamp(0, K-1), ensemble_attn_mask_per_layer)\n",
    "\n",
    "\n",
    "# t = result[:, :, None] == unique_x[None, None, :]\n",
    "# t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "# t = t.sum(-1)\n",
    "N, K = result.shape\n",
    "ts = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    t = result[icn*chunk_n:icn*chunk_n+chunk_n, :, None] == unique_x[None, None, :]\n",
    "    t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "    t = t.sum(-1)\n",
    "    ts.append(t)\n",
    "t = torch.cat(ts, dim=0)\n",
    "\n",
    "# torch.Size([4096, 1280]) torch.Size([64, 1280]) torch.Size([4096, 2094])\n",
    "# print(result.shape, t.shape, cnt_x.shape)\n",
    "result_cnt = torch.where(result < 9999999, cnt_x.gather(-1, t), -9999999)\n",
    "\n",
    "'''\n",
    "ensemble_attn_mask_per_layer\n",
    "tensor([[1, 1, 3, 3, 3, 5],\\\n",
    "        [3, 3, 4, 4, 4, 4]])\n",
    "ensemble_cnt_sorted\n",
    "tensor([[       6,        4,        3,        3,        2,        1,        1,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999],\\\n",
    "[       6,        4,        3,        3,        2,        2, -9999999,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999]])\n",
    "ensemble_sorted\n",
    "tensor([[   10,     6,     3,     8,     1,     5,    11, 32000, 32000, 32000,\n",
    "32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000],\\\n",
    "[    5,     4,     7,     9,     6,     3, 32000, 32000, 32000, 32000,\n",
    "32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000]]))\n",
    "'''\n",
    "# ensemble_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "# ensemble_cnt_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[      6,       2,       9,       3,       7,       8,       5,      10,\n",
      "               1,       4, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [      2,      10,       5,       1,       9,       3,       7,       8,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [      3,       7,      10,       6,       8,       4,       1,       5,\n",
      "               2,       9, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [     10,       7,       3,       4,       9,       6,       2,       5,\n",
      "               1, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [      3,       4,      10,       8,       7,       1,       5,       2,\n",
      "               9,       6, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999],\n",
      "        [      7,       3,       9,       2,       8,       5,       4,       6,\n",
      "              10,       1, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999, 9999999,\n",
      "         9999999, 9999999, 9999999, 9999999]])\n",
      "tensor([[       6,        5,        5,        4,        4,        4,        3,\n",
      "                2,        2,        1, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       5,        5,        4,        3,        3,        2,        1,\n",
      "                1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       8,        6,        5,        4,        4,        3,        2,\n",
      "                2,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       6,        4,        3,        3,        3,        2,        1,\n",
      "                1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       6,        5,        5,        5,        4,        3,        3,\n",
      "                2,        2,        1, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999],\n",
      "        [       6,        4,        3,        2,        2,        2,        2,\n",
      "                1,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
      "         -9999999]])\n",
      "torch.Size([6, 36])\n",
      "torch.Size([6, 36])\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_sorted)\n",
    "print(ensemble_cnt_sorted)\n",
    "print(ensemble_sorted.shape)\n",
    "print(ensemble_cnt_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0807, -0.4962,  0.7057, -2.9348, -1.8689],\n",
      "        [ 0.2331,  0.7846, -0.8708, -1.1181, -2.6611]])\n",
      "tensor([[-0.0807, -0.4962,  0.7057, -2.9348, -1.8689],\n",
      "        [ 0.2331,  0.7846, -0.8708, -1.1181, -2.6611]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(2,5)\n",
    "\n",
    "print(t)\n",
    "print(t[:, :9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ensemble_cnt_sorted >= ensemble_method_final_inter_thresh\n",
    "\n",
    "ensemble_filtered = torch.where(mask, ensemble_sorted, torch.tensor(9999999, device=mask.device))\n",
    "ensemble_cnt_filtered = torch.where(mask, ensemble_cnt_sorted, torch.tensor(9999999, device=mask.device))\n",
    "\n",
    "## mask_i : where to discard leftovers \n",
    "filtered_mask = ensemble_filtered == 9999999\n",
    "# Determine which columns have all rows as -1\n",
    "columns_with_all_negative_one = torch.all(filtered_mask, dim=0)\n",
    "\n",
    "# Get the first index where all rows have -1\n",
    "nonzero_indices = torch.nonzero(columns_with_all_negative_one, as_tuple=True)\n",
    "\n",
    "# If there are any such columns, find the first one\n",
    "if len(nonzero_indices[0]) > 0:\n",
    "    mask_k_i = nonzero_indices[0][0].item()\n",
    "    k_final = min(mask_k_i, ensemble_indices_k_size)\n",
    "else:\n",
    "    mask_k_i = -1  # If no such index is found\n",
    "    k_final = ensemble_indices_k_size\n",
    "\n",
    "ensemble_filtered = ensemble_filtered[:, :k_final] # TODO is this meaningful??\n",
    "ensemble_cnt_filtered = ensemble_cnt_filtered[:, :k_final]\n",
    "ensemble_filtered = ensemble_filtered.view(_N_H, TDST_BQ, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 7, 8, 7],\n",
      "        [1, 3, 5, 6],\n",
      "        [9, 2, 9, 5],\n",
      "        [1, 6, 7, 7],\n",
      "        [3, 1, 5, 4],\n",
      "        [7, 5, 8, 6]])\n",
      "tensor([[2, 7, 8, 7, 1, 3, 5, 6, 9, 2, 9, 5],\n",
      "        [1, 6, 7, 7, 3, 1, 5, 4, 7, 5, 8, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "e = torch.randint(1, 10, (6, 4))\n",
    "print(e)\n",
    "e = e.view(6//3, 3*4)\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H * TDST_BQ, MASK_K_BK * MODEL_N)\n",
    "# ensemble_attn_mask_per_layer : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, return_inverse=True, sorted=False, return_counts=True)\n",
    "# indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "\n",
    "# cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "N, K = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "cnt_xs = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    cnt_xs.append(\n",
    "        (unique_x[None, None, :] == ensemble_attn_mask_per_layer[icn*chunk_n:icn*chunk_n+chunk_n, :, None]).long().sum(1)\n",
    "    )\n",
    "cnt_x = torch.cat(cnt_xs, dim=0)\n",
    "\n",
    "\n",
    "result = torch.full_like(ensemble_attn_mask_per_layer, 9999999)\n",
    "result = result.scatter_(1, indices.clamp(0, K-1), ensemble_attn_mask_per_layer)\n",
    "\n",
    "\n",
    "# t = result[:, :, None] == unique_x[None, None, :]\n",
    "# t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "# t = t.sum(-1)\n",
    "N, K = result.shape\n",
    "ts = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    t = result[icn*chunk_n:icn*chunk_n+chunk_n, :, None] == unique_x[None, None, :]\n",
    "    t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "    t = t.sum(-1)\n",
    "    ts.append(t)\n",
    "t = torch.cat(ts, dim=0)\n",
    "\n",
    "# torch.Size([4096, 1280]) torch.Size([64, 1280]) torch.Size([4096, 2094])\n",
    "# print(result.shape, t.shape, cnt_x.shape)\n",
    "result_cnt = torch.where(result < 9999999, cnt_x.gather(-1, t), -9999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 2, 5])\n",
      "tensor([[[[ 3,  3,  7,  2, 10],\n",
      "          [ 6,  1,  9,  8,  3]],\n",
      "\n",
      "         [[ 1,  5,  9,  1,  9],\n",
      "          [ 7,  4,  2,  9,  4]],\n",
      "\n",
      "         [[ 7,  9,  5,  9,  2],\n",
      "          [ 3,  6,  3,  9, 10]],\n",
      "\n",
      "         [[ 5,  6, 10,  2,  9],\n",
      "          [ 1, 10,  2,  2,  7]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  2,  9,  2,  2],\n",
      "          [ 8,  7,  9, 10, 10]],\n",
      "\n",
      "         [[10,  6,  3,  2,  2],\n",
      "          [ 4,  3,  5,  8,  6]],\n",
      "\n",
      "         [[ 4,  1,  6,  1,  5],\n",
      "          [ 9,  3, 10,  4,  1]],\n",
      "\n",
      "         [[ 8,  3,  6,  9,  2],\n",
      "          [ 8,  7,  8,  9,  6]]],\n",
      "\n",
      "\n",
      "        [[[ 4,  3,  5,  8, 10],\n",
      "          [ 2,  3,  8,  1,  2]],\n",
      "\n",
      "         [[ 6,  3, 10,  9,  2],\n",
      "          [ 3, 10,  8,  9,  8]],\n",
      "\n",
      "         [[ 8,  1,  4,  8,  9],\n",
      "          [ 9,  9,  6,  8,  2]],\n",
      "\n",
      "         [[ 2,  2,  1,  2,  2],\n",
      "          [ 1,  9,  4, 10,  7]]]])\n",
      "torch.Size([3, 3, 2, 5])\n",
      "tensor([[[[      3,       3,       7,       2,      10],\n",
      "          [      6,       1,       9,       8,       3]],\n",
      "\n",
      "         [[      1,       5,       9,       1,       9],\n",
      "          [      7,       4,       2,       9,       4]],\n",
      "\n",
      "         [[      7,       9,       5,       9,       2],\n",
      "          [      3,       6,       3,       9,      10]],\n",
      "\n",
      "         [[      5,       6,      10,       2,       9],\n",
      "          [      1,      10,       2,       2,       7]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]]],\n",
      "\n",
      "\n",
      "        [[[      6,       2,       9,       2,       2],\n",
      "          [      8,       7,       9,      10,      10]],\n",
      "\n",
      "         [[     10,       6,       3,       2,       2],\n",
      "          [      4,       3,       5,       8,       6]],\n",
      "\n",
      "         [[      4,       1,       6,       1,       5],\n",
      "          [      9,       3,      10,       4,       1]],\n",
      "\n",
      "         [[      8,       3,       6,       9,       2],\n",
      "          [      8,       7,       8,       9,       6]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]]],\n",
      "\n",
      "\n",
      "        [[[      4,       3,       5,       8,      10],\n",
      "          [      2,       3,       8,       1,       2]],\n",
      "\n",
      "         [[      6,       3,      10,       9,       2],\n",
      "          [      3,      10,       8,       9,       8]],\n",
      "\n",
      "         [[      8,       1,       4,       8,       9],\n",
      "          [      9,       9,       6,       8,       2]],\n",
      "\n",
      "         [[      2,       2,       1,       2,       2],\n",
      "          [      1,       9,       4,      10,       7]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]],\n",
      "\n",
      "         [[9999999, 9999999, 9999999, 9999999, 9999999],\n",
      "          [9999999, 9999999, 9999999, 9999999, 9999999]]]])\n",
      "New tensor shape: torch.Size([3, 7, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the existing tensor with dimensions (_N_H, TDST_BQ, MASK_K_BK, MODEL_N)\n",
    "_N_H = 3\n",
    "TDST_BQ = 4\n",
    "MASK_K_BK = 2\n",
    "MODEL_N = 5\n",
    "\n",
    "# Existing tensor\n",
    "ensemble_attn_mask_per_layer = torch.randint(1, 11, (_N_H, TDST_BQ, MASK_K_BK, MODEL_N))\n",
    "\n",
    "# Define the new tensor with size (N_H, timedim_leftover, MASK_K_BK, MODEL_N)\n",
    "timedim_leftover = 3  # Example size\n",
    "new_tensor = torch.full((_N_H, timedim_leftover, MASK_K_BK, MODEL_N), 9999999)\n",
    "\n",
    "# Concatenate along the TDST_BQ dimension\n",
    "# Dimension index for TDST_BQ is 1\n",
    "result = torch.cat((ensemble_attn_mask_per_layer, new_tensor), dim=1)\n",
    "\n",
    "print(ensemble_attn_mask_per_layer.shape)\n",
    "print(ensemble_attn_mask_per_layer)\n",
    "print(new_tensor.shape)\n",
    "print(result)\n",
    "# Check the new shape of the resulting tensor\n",
    "print(\"New tensor shape:\", result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  3,  4,  8,  8,  9,  4,  9,  9,  4,  7,  2],\n",
       "        [ 6, 10,  8,  4,  1,  9,  7, 10, 10,  4,  2,  4],\n",
       "        [ 9,  8,  3,  7,  9,  5,  2, 10,  2,  4,  1,  8],\n",
       "        [ 1,  6,  8,  4, 10,  9,  4,  1,  4,  2, 10,  9],\n",
       "        [ 3,  6,  5,  7,  7,  2,  8,  2,  8,  7, 10,  8],\n",
       "        [ 9,  4,  2,  8,  1,  7,  4,  7,  8,  5,  2, 10],\n",
       "        [10,  7,  2,  1,  2,  9,  4,  3, 10,  4,  1,  9],\n",
       "        [ 1,  6,  6,  6,  6,  4,  2,  7, 10,  9,  2,  9],\n",
       "        [ 3,  5,  2,  9,  6,  5,  3,  2,  5,  6,  6,  9],\n",
       "        [10,  4,  4,  2,  2,  8,  9,  8,  9,  3,  4,  9],\n",
       "        [ 6,  8,  8,  4,  9,  8,  9,  1,  9, 10,  6,  3],\n",
       "        [ 8,  8,  6,  8,  4,  9,  4,  1, 10,  4,  5,  3],\n",
       "        [ 4, 10,  8,  8,  9,  8,  4,  2,  8,  3,  7, 10],\n",
       "        [10,  3,  5,  4,  6,  6,  6, 10,  5, 10,  6,  9],\n",
       "        [ 9,  8,  7,  9,  7,  3,  6,  1, 10,  1,  1,  8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_attn_mask_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9999999,       2,       3,       4, 9999999, 9999999,       7,       8,\n",
       "               9, 9999999, 9999999, 9999999],\n",
       "        [      1,       2, 9999999,       4, 9999999,       6,       7,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1,       2,       3,       4,       5, 9999999,       7,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1,       2, 9999999,       4, 9999999,       6, 9999999,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [9999999,       2,       3, 9999999,       5,       6,       7,       8,\n",
       "         9999999,      10, 9999999, 9999999],\n",
       "        [      1,       2, 9999999,       4,       5, 9999999,       7,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1,       2,       3,       4, 9999999, 9999999,       7, 9999999,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1,       2, 9999999,       4, 9999999,       6,       7, 9999999,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [9999999,       2,       3, 9999999,       5,       6, 9999999, 9999999,\n",
       "               9, 9999999, 9999999, 9999999],\n",
       "        [9999999,       2,       3,       4, 9999999, 9999999, 9999999,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1, 9999999,       3,       4, 9999999,       6, 9999999,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1, 9999999,       3,       4,       5,       6, 9999999,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [9999999,       2,       3,       4, 9999999, 9999999,       7,       8,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [9999999, 9999999,       3,       4,       5,       6, 9999999, 9999999,\n",
       "               9,      10, 9999999, 9999999],\n",
       "        [      1, 9999999,       3, 9999999, 9999999,       6,       7,       8,\n",
       "               9,      10, 9999999, 9999999]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9999999,        1,        2,        3, -9999999, -9999999,        1,\n",
       "                2,        3, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999,        3, -9999999,        1,        1,\n",
       "                1,        1,        3, -9999999, -9999999],\n",
       "        [       1,        2,        1,        1,        1, -9999999,        1,\n",
       "                2,        2,        1, -9999999, -9999999],\n",
       "        [       2,        1, -9999999,        3, -9999999,        1, -9999999,\n",
       "                1,        2,        2, -9999999, -9999999],\n",
       "        [-9999999,        2,        1, -9999999,        1,        1,        3,\n",
       "                3, -9999999,        1, -9999999, -9999999],\n",
       "        [       1,        2, -9999999,        2,        1, -9999999,        2,\n",
       "                2,        1,        1, -9999999, -9999999],\n",
       "        [       2,        2,        1,        2, -9999999, -9999999,        1,\n",
       "         -9999999,        2,        2, -9999999, -9999999],\n",
       "        [       1,        2, -9999999,        1, -9999999,        4,        1,\n",
       "         -9999999,        2,        1, -9999999, -9999999],\n",
       "        [-9999999,        2,        2, -9999999,        3,        3, -9999999,\n",
       "         -9999999,        2, -9999999, -9999999, -9999999],\n",
       "        [-9999999,        2,        1,        3, -9999999, -9999999, -9999999,\n",
       "                2,        3,        1, -9999999, -9999999],\n",
       "        [       1, -9999999,        1,        1, -9999999,        2, -9999999,\n",
       "                3,        3,        1, -9999999, -9999999],\n",
       "        [       1, -9999999,        1,        3,        1,        1, -9999999,\n",
       "                3,        1,        1, -9999999, -9999999],\n",
       "        [-9999999,        1,        1,        2, -9999999, -9999999,        1,\n",
       "                4,        1,        2, -9999999, -9999999],\n",
       "        [-9999999, -9999999,        1,        1,        2,        4, -9999999,\n",
       "         -9999999,        1,        3, -9999999, -9999999],\n",
       "        [       3, -9999999,        1, -9999999, -9999999,        1,        2,\n",
       "                2,        2,        1, -9999999, -9999999]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)\n",
    "# mask = ensemble_cnt_sorted >= ensemble_method_final_inter_thresh\n",
    "\n",
    "# ensemble_filtered = torch.where(mask, ensemble_sorted, torch.tensor(9999999, device=mask.device))\n",
    "# ensemble_cnt_filtered = torch.where(mask, ensemble_cnt_sorted, torch.tensor(9999999, device=mask.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      4,       9,       3,       8,       2,       7, 9999999, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      4,      10,       1,       2,       6,       7,       8,       9,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      2,       8,       9,       1,       3,       4,       5,       7,\n",
       "              10, 9999999, 9999999, 9999999],\n",
       "        [      4,       1,       9,      10,       2,       6,       8, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      7,       8,       2,       3,       5,       6,      10, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      2,       4,       7,       8,       1,       5,       9,      10,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      1,       2,       4,       9,      10,       3,       7, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      6,       2,       9,       1,       4,       7,      10, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      5,       6,       2,       3,       9, 9999999, 9999999, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      4,       9,       2,       8,       3,      10, 9999999, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      8,       9,       6,       1,       3,       4,      10, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      4,       8,       1,       3,       5,       6,       9,      10,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      8,       4,      10,       2,       3,       7,       9, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      6,      10,       5,       3,       4,       9, 9999999, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999],\n",
       "        [      1,       7,       8,       9,       3,       6,      10, 9999999,\n",
       "         9999999, 9999999, 9999999, 9999999]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       3,        3,        2,        2,        1,        1, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        3,        1,        1,        1,        1,        1,\n",
       "                1, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       2,        2,        2,        1,        1,        1,        1,\n",
       "                1,        1, -9999999, -9999999, -9999999],\n",
       "        [       3,        2,        2,        2,        1,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        3,        2,        1,        1,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       2,        2,        2,        2,        1,        1,        1,\n",
       "                1, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       2,        2,        2,        2,        2,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       4,        2,        2,        1,        1,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        3,        2,        2,        2, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        3,        2,        2,        1,        1, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        3,        2,        1,        1,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        3,        1,        1,        1,        1,        1,\n",
       "                1, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       4,        2,        2,        1,        1,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       4,        3,        2,        1,        1,        1, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       3,        2,        2,        2,        1,        1,        1,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cnt_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "_N_H = 2\n",
    "TDST_BQ = 5\n",
    "MASK_K_BK = 4\n",
    "MODEL_N = 3\n",
    "\n",
    "ensemble_attn_mask_per_layer = torch.randn(_N_H, TDST_BQ, MASK_K_BK, MODEL_N)\n",
    "\n",
    "ensemble_attn_mask_per_layer = ensemble_attn_mask_per_layer.view(_N_H * TDST_BQ, MASK_K_BK * MODEL_N)\n",
    "# ensemble_attn_mask_per_layer : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "unique_x, indices, unique_cnt = torch.unique(ensemble_attn_mask_per_layer, return_inverse=True, sorted=False, return_counts=True)\n",
    "# indices -= indices.min(dim=1, keepdims=True)[0]\n",
    "\n",
    "# cnt_x = (unique_x[None, None, :] == ensemble_attn_mask_per_layer[:, :, None]).long().sum(1)\n",
    "N, K = ensemble_attn_mask_per_layer.shape\n",
    "\n",
    "cnt_xs = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    cnt_xs.append(\n",
    "        (unique_x[None, None, :] == ensemble_attn_mask_per_layer[icn*chunk_n:icn*chunk_n+chunk_n, :, None]).long().sum(1)\n",
    "    )\n",
    "cnt_x = torch.cat(cnt_xs, dim=0)\n",
    "\n",
    "\n",
    "result = torch.full_like(ensemble_attn_mask_per_layer, 9999999)\n",
    "result = result.scatter_(1, indices.clamp(0, K-1), ensemble_attn_mask_per_layer)\n",
    "\n",
    "\n",
    "# t = result[:, :, None] == unique_x[None, None, :]\n",
    "# t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "# t = t.sum(-1)\n",
    "N, K = result.shape\n",
    "ts = []\n",
    "chunk_n = 64\n",
    "for icn in range(int(math.ceil(N / chunk_n))):\n",
    "    t = result[icn*chunk_n:icn*chunk_n+chunk_n, :, None] == unique_x[None, None, :]\n",
    "    t = t * torch.arange(len(unique_x), device=t.device)[None, None, :]\n",
    "    t = t.sum(-1)\n",
    "    ts.append(t)\n",
    "t = torch.cat(ts, dim=0)\n",
    "\n",
    "# torch.Size([4096, 1280]) torch.Size([64, 1280]) torch.Size([4096, 2094])\n",
    "# print(result.shape, t.shape, cnt_x.shape)\n",
    "result_cnt = torch.where(result < 9999999, cnt_x.gather(-1, t), -9999999)\n",
    "\n",
    "'''\n",
    "ensemble_attn_mask_per_layer\n",
    "tensor([[1, 1, 3, 3, 3, 5],\\\n",
    "        [3, 3, 4, 4, 4, 4]])\n",
    "ensemble_cnt_sorted\n",
    "tensor([[       6,        4,        3,        3,        2,        1,        1,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999],\\\n",
    "[       6,        4,        3,        3,        2,        2, -9999999,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
    "-9999999, -9999999, -9999999, -9999999, -9999999, -9999999]])\n",
    "ensemble_sorted\n",
    "tensor([[   10,     6,     3,     8,     1,     5,    11, 32000, 32000, 32000,\n",
    "32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000],\\\n",
    "[    5,     4,     7,     9,     6,     3, 32000, 32000, 32000, 32000,\n",
    "32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000]]))\n",
    "'''\n",
    "# ensemble_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "# ensemble_cnt_sorted : [N*H * TDST//BLOCK_SIZE_Q, mask_k//BLOCK_SIZE_K * ensemble_model_n]\n",
    "ensemble_cnt_sorted, indices = torch.sort(result_cnt, dim=-1, descending=True)\n",
    "ensemble_sorted = result.gather(-1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 12]), torch.Size([10, 12]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cnt_sorted.shape, ensemble_sorted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1,        1,        1, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cnt_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ensemble_cnt_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1,        1,        1, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1,        1, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1,        1, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999],\n",
       "        [       1, -9999999, -9999999, -9999999, -9999999, -9999999, -9999999,\n",
       "         -9999999, -9999999, -9999999, -9999999, -9999999]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129188242076432, 129188242076432)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(ensemble_cnt_sorted), id(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
