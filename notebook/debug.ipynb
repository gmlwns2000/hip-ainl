{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  5,  8, 10, 15])\n",
      "torch.Size([5])\n",
      "tensor([3, 2, 4, 1, 3])\n",
      "torch.Size([5])\n",
      "tensor([[-1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example data\n",
    "BLOCK_BK = 5  # Assuming BLOCK_BK is 5 for this example\n",
    "t_group_size = 4  # Maximum number of group sizes\n",
    "\n",
    "# Example tensors\n",
    "indices = torch.tensor([2, 5, 8, 10, 15])  # Shape (BLOCK_BK,)\n",
    "group_size = torch.tensor([3, 2, 4, 1, 3])  # Shape (BLOCK_BK,)\n",
    "\n",
    "# Step 1: Create a base tensor with garbage values (-1)\n",
    "dupped_indices = torch.full((BLOCK_BK, t_group_size), -1, dtype=torch.int64)\n",
    "\n",
    "print(indices)\n",
    "print(indices.shape)\n",
    "print(group_size)\n",
    "print(group_size.shape)\n",
    "print(dupped_indices)\n",
    "print(dupped_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate ranges for each group in a flat tensor\n",
    "group_indices = torch.arange(t_group_size).unsqueeze(0)  # Shape (1, t_group_size)\n",
    "group_indices = group_indices.expand(BLOCK_BK, t_group_size)  # Shape (BLOCK_BK, t_group_size)\n",
    "\n",
    "print(group_indices)\n",
    "print(group_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4,  5],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [10, 11, 12, 13],\n",
      "        [15, 16, 17, 18]])\n",
      "torch.Size([5, 4])\n",
      "tensor([[ 2,  3,  4, -1],\n",
      "        [ 5,  6, -1, -1],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [10, -1, -1, -1],\n",
      "        [15, 16, 17, -1]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create a tensor where the group sizes define valid ranges for each row\n",
    "group_indices = group_indices + indices.unsqueeze(1)  # Broadcasting addition of indices\n",
    "\n",
    "# Step 4: Scatter values into dupped_indices according to group_size\n",
    "scatter_indices = torch.arange(t_group_size).expand(BLOCK_BK, t_group_size)  # Prepare scatter indices\n",
    "dupped_indices.scatter_(1, scatter_indices, group_indices)\n",
    "\n",
    "# Step 5: Zero out the invalid entries (group_size < t_group_size)\n",
    "valid_ranges = torch.arange(t_group_size).unsqueeze(0) < group_size.unsqueeze(1)\n",
    "dupped_indices[~valid_ranges] = -1  # Fill the invalid positions with -1\n",
    "\n",
    "print(indices)\n",
    "print(indices.shape)\n",
    "print(group_size)\n",
    "print(group_size.shape)\n",
    "print(dupped_indices)\n",
    "print(dupped_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  5,  8, 10, 15])\n",
      "torch.Size([5])\n",
      "tensor([3, 2, 4, 1, 3])\n",
      "torch.Size([5])\n",
      "tensor([[-1, -1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1, -1]])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example data\n",
    "BLOCK_BK = 5  # Assuming BLOCK_BK is 5 for this example\n",
    "t_group_size = 4  # Maximum number of group sizes\n",
    "multi_branch_ratio_per_layer = 3  # Example multi_branch_ratio_per_layer\n",
    "\n",
    "# Derived size based on multi_branch_ratio_per_layer\n",
    "output_size = 2 * multi_branch_ratio_per_layer  # Ensure it's larger or equal to t_group_size\n",
    "\n",
    "# Example tensors\n",
    "indices = torch.tensor([2, 5, 8, 10, 15])  # Shape (BLOCK_BK,)\n",
    "group_size = torch.tensor([3, 2, 4, 1, 3])  # Shape (BLOCK_BK,)\n",
    "\n",
    "# Step 1: Create a base tensor with garbage values (-1)\n",
    "dupped_indices = torch.full((BLOCK_BK, output_size), -1, dtype=torch.int64)\n",
    "\n",
    "print(indices)\n",
    "print(indices.shape)\n",
    "print(group_size)\n",
    "print(group_size.shape)\n",
    "print(dupped_indices)\n",
    "print(dupped_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4, -1, -1, -1],\n",
      "        [ 5,  6, -1, -1, -1, -1],\n",
      "        [ 8,  9, 10, 11, -1, -1],\n",
      "        [10, -1, -1, -1, -1, -1],\n",
      "        [15, 16, 17, -1, -1, -1]])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate ranges for each group up to the max `group_size`\n",
    "range_tensor = torch.arange(output_size).unsqueeze(0).expand(BLOCK_BK, output_size)  # Shape (BLOCK_BK, output_size)\n",
    "\n",
    "# Step 3: Add the base `indices` to the range_tensor\n",
    "group_indices = indices.unsqueeze(1) + range_tensor\n",
    "\n",
    "# Step 4: Ensure we don't add more indices than specified by `group_size`\n",
    "# Create scatter indices for the first `group_size` elements of each row\n",
    "scatter_indices = torch.arange(output_size).expand(BLOCK_BK, output_size)\n",
    "\n",
    "# Step 5: Use scatter_ to add only up to the valid `group_size`\n",
    "valid_mask = scatter_indices < group_size.unsqueeze(1)\n",
    "dupped_indices.scatter_(1, scatter_indices, torch.where(valid_mask, group_indices, dupped_indices))\n",
    "\n",
    "print(dupped_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(indices.dtype).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[                  2,                   3,                   4,\n",
      "         9223372036854775807, 9223372036854775807, 9223372036854775807],\n",
      "        [                  5,                   6, 9223372036854775807,\n",
      "         9223372036854775807, 9223372036854775807, 9223372036854775807],\n",
      "        [                  8,                   9,                  10,\n",
      "                          11, 9223372036854775807, 9223372036854775807],\n",
      "        [                 10, 9223372036854775807, 9223372036854775807,\n",
      "         9223372036854775807, 9223372036854775807, 9223372036854775807],\n",
      "        [                 15,                  16,                  17,\n",
      "         9223372036854775807, 9223372036854775807, 9223372036854775807]])\n"
     ]
    }
   ],
   "source": [
    "BLOCK_BK = 5  # Assuming BLOCK_BK is 5 for this example\n",
    "t_group_size = 4  # Maximum number of group sizes\n",
    "multi_branch_ratio_per_layer = 3  # Example multi_branch_ratio_per_layer\n",
    "\n",
    "# Derived size based on multi_branch_ratio_per_layer\n",
    "\n",
    "# Example tensors\n",
    "indices = torch.tensor([2, 5, 8, 10, 15])  # Shape (BLOCK_BK,)\n",
    "group_sizes = torch.tensor([3, 2, 4, 1, 3])  # Shape (BLOCK_BK,)\n",
    "\n",
    "garbage_value = torch.iinfo(indices.dtype).max\n",
    "M2 = 2 * multi_branch_ratio_per_layer\n",
    "dupped_indices = torch.full((BLOCK_BK, M2), garbage_value).to(indices.device)\n",
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)  # Shape (1, t_group_size)\n",
    "\n",
    "group_indices = group_indices + indices.unsqueeze(1)\n",
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "valid_mask = scatter_indices < group_sizes.unsqueeze(1)\n",
    "dupped_indices.scatter_(1, scatter_indices, torch.where(valid_mask, group_indices, dupped_indices))\n",
    "\n",
    "print(dupped_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_sizes.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "dupped_group_sizes = torch.ones((BLOCK_BK, M2), dtype=group_sizes.dtype)\n",
    "\n",
    "\n",
    "print(dupped_group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4,  5,  6,  7],\n",
      "        [ 5,  6,  7,  8,  9, 10],\n",
      "        [ 8,  9, 10, 11, 12, 13],\n",
      "        [10, 11, 12, 13, 14, 15],\n",
      "        [15, 16, 17, 18, 19, 20]])\n"
     ]
    }
   ],
   "source": [
    "print(group_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4,  1,  1,  1],\n",
      "        [ 5,  6,  1,  1,  1,  1],\n",
      "        [ 8,  9, 10, 11,  1,  1],\n",
      "        [10,  1,  1,  1,  1,  1],\n",
      "        [15, 16, 17,  1,  1,  1]])\n"
     ]
    }
   ],
   "source": [
    "dupped_group_sizes.scatter_(1, scatter_indices, torch.where(valid_mask, dupped_group_sizes, dupped_group_sizes))\n",
    "\n",
    "print(dupped_group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  8, 12, 15, 22, 25, 30, 35], dtype=torch.int32)\n",
      "torch.Size([8])\n",
      "tensor([ 5,  8, 15, 22, 35], dtype=torch.int32)\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have the following variables defined elsewhere in your code\n",
    "BLOCK_BK = 16  # Example value\n",
    "M2 = 8  # Threshold for group sizes\n",
    "multi_branch_ratio_per_layer = 0.75  # Example value\n",
    "\n",
    "# Example tensors for demonstration purposes\n",
    "indices = torch.tensor([5, 8, 12, 15, 22, 25, 30, 35], dtype=torch.int32)\n",
    "group_sizes = torch.tensor([4, 6, 9, 3, 7, 12, 14, 5], dtype=torch.int32)\n",
    "\n",
    "# Define garbage value\n",
    "garbage_value = torch.iinfo(indices.dtype).max\n",
    "\n",
    "# Separate small and large groups\n",
    "small_group_sizes = group_sizes <= M2\n",
    "large_group_sizes = group_sizes > M2\n",
    "\n",
    "# Small group tensors\n",
    "indices_small = indices[small_group_sizes]\n",
    "group_sizes_small = group_sizes[small_group_sizes]\n",
    "\n",
    "\n",
    "print(indices)\n",
    "print(indices.shape)\n",
    "\n",
    "print(indices_small)\n",
    "print(indices_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large group tensors\n",
    "indices_large = indices[large_group_sizes]\n",
    "group_sizes_large = group_sizes[large_group_sizes]\n",
    "\n",
    "# The code operation applied to `indices_small` and `group_sizes_small`\n",
    "dupped_indices = torch.full((BLOCK_BK, M2), garbage_value).to(indices.device)\n",
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)  # Shape (BLOCK_BK, M2)\n",
    "\n",
    "group_indices = group_indices + indices_small.unsqueeze(1)\n",
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "valid_mask = scatter_indices < group_sizes_small.unsqueeze(1)\n",
    "\n",
    "# Update dupped_indices using scatter\n",
    "dupped_indices.scatter_(1, scatter_indices, torch.where(valid_mask, group_indices, dupped_indices))\n",
    "\n",
    "# Create dupped_group_sizes and reshape\n",
    "dupped_group_sizes = torch.ones((BLOCK_BK, M2), dtype=group_sizes_small.dtype)\n",
    "dupped_indices = dupped_indices.view(BLOCK_BK * M2)\n",
    "dupped_group_sizes = dupped_group_sizes.view(BLOCK_BK * M2)\n",
    "\n",
    "# Create mask\n",
    "mask_bk_dup = (dupped_indices < garbage_value)\n",
    "\n",
    "# Store dupped_indices and dupped_group_sizes (for tl.store-like behavior, assume some output tensor)\n",
    "DUPPED_INDICES = torch.empty_like(dupped_indices)\n",
    "DUPPED_GROUP_SIZE = torch.empty_like(dupped_group_sizes)\n",
    "\n",
    "# Mocking `tl.store` behavior (this stores the values)\n",
    "DUPPED_INDICES[mask_bk_dup] = dupped_indices[mask_bk_dup]\n",
    "DUPPED_GROUP_SIZE[mask_bk_dup] = dupped_group_sizes[mask_bk_dup]\n",
    "\n",
    "# Now you have `dupped_indices` and `dupped_group_sizes` ready for further operations\n",
    "print(\"Dupped Indices:\", DUPPED_INDICES)\n",
    "print(\"Dupped Group Sizes:\", DUPPED_GROUP_SIZE)\n",
    "\n",
    "# Handle `indices_large` and `group_sizes_large` with your other operations\n",
    "# (Assume you will apply a different set of operations for large group sizes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  8, 15, 22, 35], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have the following variables defined elsewhere in your code\n",
    "BLOCK_BK = 16  # Example value\n",
    "M2 = 8  # Threshold for group sizes\n",
    "multi_branch_ratio_per_layer = 0.75  # Example value\n",
    "\n",
    "# Example tensors for demonstration purposes\n",
    "indices = torch.tensor([5, 8, 12, 15, 22, 25, 30, 35], dtype=torch.int32)\n",
    "group_sizes = torch.tensor([4, 6, 9, 3, 7, 12, 14, 5], dtype=torch.int32)\n",
    "\n",
    "# Define garbage value\n",
    "garbage_value = torch.iinfo(indices.dtype).max\n",
    "\n",
    "# Separate small and large groups\n",
    "small_group_sizes = group_sizes <= M2\n",
    "large_group_sizes = group_sizes > M2\n",
    "\n",
    "# Small group tensors\n",
    "indices_small = indices[small_group_sizes]\n",
    "group_sizes_small = group_sizes[small_group_sizes]\n",
    "\n",
    "\n",
    "print(indices_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dupped_indices with garbage values\n",
    "dupped_indices = torch.full((BLOCK_BK, len(indices)), garbage_value).to(indices.device)\n",
    "\n",
    "# Create a group_indices tensor and apply the same operation only for small indices\n",
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)  # Shape (BLOCK_BK, M2)\n",
    "group_indices = group_indices + indices_small.unsqueeze(1)  # Operate only on small group sizes\n",
    "\n",
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "# Valid mask for small group sizes\n",
    "valid_mask = scatter_indices < group_sizes_small.unsqueeze(1)\n",
    "\n",
    "# Only scatter into `dupped_indices` for positions corresponding to small group sizes\n",
    "# Use torch.where to select valid indices, or keep the garbage value for invalid ones\n",
    "dupped_indices[:, small_group_sizes] = torch.where(valid_mask, group_indices, dupped_indices[:, small_group_sizes])\n",
    "\n",
    "# Create dupped_group_sizes and reshape it\n",
    "dupped_group_sizes = torch.ones((BLOCK_BK, len(indices)), dtype=group_sizes.dtype).to(indices.device)\n",
    "\n",
    "# Reshape to match expected output dimensions\n",
    "dupped_indices = dupped_indices.view(BLOCK_BK * len(indices))\n",
    "dupped_group_sizes = dupped_group_sizes.view(BLOCK_BK * len(indices))\n",
    "\n",
    "# Create mask\n",
    "mask_bk_dup = (dupped_indices < garbage_value)\n",
    "\n",
    "# Mocking tl.store-like behavior (assuming some output tensors)\n",
    "DUPPED_INDICES = torch.empty_like(dupped_indices)\n",
    "DUPPED_GROUP_SIZE = torch.empty_like(dupped_group_sizes)\n",
    "\n",
    "# Store values in the result tensor\n",
    "DUPPED_INDICES[mask_bk_dup] = dupped_indices[mask_bk_dup]\n",
    "DUPPED_GROUP_SIZE[mask_bk_dup] = dupped_group_sizes[mask_bk_dup]\n",
    "\n",
    "# Now you have `dupped_indices` and `dupped_group_sizes` with the same size as the original tensors,\n",
    "# while only operating on the small group sizes.\n",
    "print(\"Dupped Indices:\", DUPPED_INDICES)\n",
    "print(\"Dupped Group Sizes:\", DUPPED_GROUP_SIZE)\n",
    "\n",
    "# Handle `indices_large` and `group_sizes_large` with your other operations\n",
    "# (You can apply other operations for large group sizes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  5,  8, 10, 15])\n",
      "tensor([3, 2, 4, 1, 3])\n",
      "tensor([[ 2,  3,  4,  5,  6,  7],\n",
      "        [ 5,  6,  7,  8,  9, 10],\n",
      "        [ 8,  9, 10, 11, 12, 13],\n",
      "        [10, 11, 12, 13, 14, 15],\n",
      "        [15, 16, 17, 18, 19, 20]])\n",
      "tensor([[0, 1, 2, 3, 4, 5],\n",
      "        [0, 1, 2, 3, 4, 5],\n",
      "        [0, 1, 2, 3, 4, 5],\n",
      "        [0, 1, 2, 3, 4, 5],\n",
      "        [0, 1, 2, 3, 4, 5]])\n",
      "---------\n",
      "tensor([[ 2,  3,  4, -1, -1, -1],\n",
      "        [ 5,  6, -1, -1, -1, -1],\n",
      "        [ 8,  9, 10, 11, -1, -1],\n",
      "        [10, -1, -1, -1, -1, -1],\n",
      "        [15, 16, 17, -1, -1, -1]])\n"
     ]
    }
   ],
   "source": [
    "BLOCK_BK = 5  # Assuming BLOCK_BK is 5 for this example\n",
    "t_group_size = 4  # Maximum number of group sizes\n",
    "multi_branch_ratio_per_layer = 3  # Example multi_branch_ratio_per_layer\n",
    "\n",
    "# Derived size based on multi_branch_ratio_per_layer\n",
    "\n",
    "# Example tensors\n",
    "indices = torch.tensor([2, 5, 8, 10, 15])  # Shape (BLOCK_BK,)\n",
    "group_sizes = torch.tensor([3, 2, 4, 1, 3])  # Shape (BLOCK_BK,)\n",
    "\n",
    "garbage_value = -1 # torch.iinfo(indices.dtype).max\n",
    "M2 = 2 * multi_branch_ratio_per_layer\n",
    "dupped_indices = torch.full((BLOCK_BK, M2), garbage_value).to(indices.device)\n",
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)  # Shape (1, t_group_size)\n",
    "\n",
    "group_indices = group_indices + indices.unsqueeze(1)\n",
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "valid_mask = scatter_indices < group_sizes.unsqueeze(1)\n",
    "dupped_indices.scatter_(1, scatter_indices, torch.where(valid_mask, group_indices, dupped_indices))\n",
    "\n",
    "print(indices)\n",
    "print(group_sizes)\n",
    "print(group_indices)\n",
    "print(scatter_indices)\n",
    "print('---------')\n",
    "print(dupped_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices tensor([ 2,  5,  8, 10, 15])\n",
      "group_sizes tensor([3, 2, 5, 1, 4])\n",
      "dupped_indices: tensor([[ 2,  3,  4, -1],\n",
      "        [ 5,  6, -1, -1],\n",
      "        [ 8,  8,  8,  8],\n",
      "        [10, -1, -1, -1],\n",
      "        [15, 16, 17, 18]])\n",
      "dupped_group_sizes: tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [5, 5, 5, 5],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n",
      "valid_mask tensor([[ True,  True,  True, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True,  True],\n",
      "        [ True, False, False, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "mask tensor([[ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True]])\n",
      "mask_final tensor([[ True,  True,  True, False],\n",
      "        [ True,  True, False, False],\n",
      "        [False, False, False, False],\n",
      "        [ True, False, False, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example data\n",
    "BLOCK_BK = 5  # Assuming BLOCK_BK is 5 for this example\n",
    "M2 = 4  # Threshold value\n",
    "\n",
    "# Example tensors\n",
    "indices = torch.tensor([2, 5, 8, 10, 15], dtype=torch.int64)  # Shape (BLOCK_BK,)\n",
    "group_sizes = torch.tensor([3, 2, 5, 1, 4], dtype=torch.int64)  # Shape (BLOCK_BK,)\n",
    "\n",
    "# Step 1: Define the garbage value\n",
    "garbage_value = -1 # torch.iinfo(indices.dtype).max\n",
    "\n",
    "# Step 2: Initialize the dupped_indices tensor with garbage values\n",
    "dupped_indices = torch.full((BLOCK_BK, M2), garbage_value).to(indices.device)\n",
    "\n",
    "# Step 3: Create the group_indices tensor\n",
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)\n",
    "group_indices = group_indices + indices.unsqueeze(1)\n",
    "\n",
    "# Step 4: Create scatter indices\n",
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "# Step 5: Create a mask where group_sizes <= M2\n",
    "mask = group_sizes.unsqueeze(1) <= M2\n",
    "\n",
    "# Step 6: For the valid mask, apply the operation using torch.where\n",
    "valid_mask = scatter_indices < group_sizes.unsqueeze(1)\n",
    "# dupped_indices.scatter_(1, scatter_indices, torch.where(valid_mask & mask, group_indices, dupped_indices))\n",
    "dupped_indices = torch.where(valid_mask & mask, group_indices, dupped_indices)\n",
    "\n",
    "# Step 7: Create dupped_group_sizes\n",
    "dupped_group_sizes = torch.where(mask, torch.ones_like(group_sizes).unsqueeze(1).expand(BLOCK_BK, M2),\n",
    "                                 group_sizes.unsqueeze(1).expand(BLOCK_BK, M2))\n",
    "\n",
    "dupped_indices = torch.where(mask, dupped_indices, indices.unsqueeze(1).expand(BLOCK_BK, M2))\n",
    "\n",
    "# Step 8: Reshape the tensors as requested\n",
    "# dupped_indices = dupped_indices.reshape(BLOCK_BK * M2)\n",
    "# dupped_group_sizes = dupped_group_sizes.reshape(BLOCK_BK * M2)\n",
    "\n",
    "# Print the output tensors\n",
    "print('indices', indices)\n",
    "print('group_sizes', group_sizes)\n",
    "print(\"dupped_indices:\", dupped_indices)\n",
    "print(\"dupped_group_sizes:\", dupped_group_sizes)\n",
    "print('valid_mask', valid_mask)\n",
    "print('mask', mask)\n",
    "print('mask_final', mask & valid_mask)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)\n",
    "print(group_indices)\n",
    "print(group_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3],\n",
      "        [0, 1, 2, 3]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "print(scatter_indices)\n",
    "print(scatter_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices tensor([ 2,  5,  8, 10, 15])\n",
      "group_sizes tensor([3, 2, 4, 1, 4])\n",
      "group_indices tensor([[ 2,  3,  4,  5],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [10, 11, 12, 13],\n",
      "        [15, 16, 17, 18]])\n",
      "Dupped Indices: tensor([[ 2,  3,  4, -1],\n",
      "        [ 5,  6, -1, -1],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [10, -1, -1, -1],\n",
      "        [15, 16, 17, 18]])\n",
      "Dupped Group Sizes: tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n",
      "Mask BK Dup tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example values for demonstration\n",
    "BLOCK_BK = 5  # Example BLOCK_BK value\n",
    "M2 = 4  # Example M2 value\n",
    "indices = torch.tensor([2, 5, 8, 10, 15], dtype=torch.int64)\n",
    "group_sizes = torch.tensor([3, 2, 4, 1, 4], dtype=torch.int64)\n",
    "\n",
    "# Step 1: Define the garbage value\n",
    "garbage_value = -1 # torch.iinfo(indices.dtype).max\n",
    "\n",
    "# Step 2: Initialize the dupped_indices tensor with garbage values\n",
    "dupped_indices = torch.full((BLOCK_BK, M2), garbage_value).to(indices.device)\n",
    "\n",
    "# Step 3: Create the group_indices tensor\n",
    "group_indices = torch.arange(M2).unsqueeze(0).expand(BLOCK_BK, M2).to(indices.device)\n",
    "group_indices = group_indices + indices.unsqueeze(1)\n",
    "\n",
    "# Step 4: Create scatter indices\n",
    "scatter_indices = torch.arange(M2).expand(BLOCK_BK, M2).to(indices.device)\n",
    "\n",
    "# Step 5: Create a valid mask\n",
    "valid_mask = scatter_indices < group_sizes.unsqueeze(1)\n",
    "\n",
    "# Step 6: Apply the logic without using scatter_\n",
    "# Instead of scatter_, we will directly assign values where `valid_mask` is True\n",
    "dupped_indices = torch.where(valid_mask, group_indices, dupped_indices)\n",
    "\n",
    "# Step 7: Create dupped_group_sizes\n",
    "dupped_group_sizes = torch.ones((BLOCK_BK, M2), dtype=group_sizes.dtype)\n",
    "\n",
    "# Step 8: Reshape dupped_indices and dupped_group_sizes\n",
    "# dupped_indices = dupped_indices.view(BLOCK_BK * M2)\n",
    "# dupped_group_sizes = dupped_group_sizes.view(BLOCK_BK * M2)\n",
    "\n",
    "# Step 9: Create mask_bk_dup to filter out garbage values\n",
    "mask_bk_dup = dupped_indices < garbage_value\n",
    "\n",
    "# Output the results\n",
    "print('indices', indices)\n",
    "print('group_sizes', group_sizes)\n",
    "print('group_indices', group_indices)\n",
    "print(\"Dupped Indices:\", dupped_indices)\n",
    "print(\"Dupped Group Sizes:\", dupped_group_sizes)\n",
    "print(\"Mask BK Dup\", mask_bk_dup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4, -1],\n",
      "        [ 5,  6, -1, -1],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [10, -1, -1, -1],\n",
      "        [15, 16, 17, 18]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example values for demonstration\n",
    "BLOCK_BK = 5  # Example BLOCK_BK value\n",
    "M2 = 4  # Example M2 value\n",
    "indices = torch.tensor([2, 5, 8, 10, 15], dtype=torch.int64)\n",
    "group_sizes = torch.tensor([3, 2, 4, 1, 4], dtype=torch.int64)\n",
    "\n",
    "# Set constants\n",
    "garbage_value = -1 # MAX_TSRC + 1\n",
    "\n",
    "# Create tensors with appropriate shapes and data types\n",
    "dupped_indices = torch.full((BLOCK_BK, M2), garbage_value, dtype=indices.dtype)\n",
    "group_indices = torch.arange(0, M2).unsqueeze(0).expand(BLOCK_BK, M2)  # Shape (BLOCK_BK, M2)\n",
    "\n",
    "# Add indices to group_indices along a new dimension\n",
    "group_indices = group_indices + indices.unsqueeze(1)\n",
    "\n",
    "# Scatter indices and create the valid mask\n",
    "scatter_indices = torch.arange(0, M2).unsqueeze(0).expand(BLOCK_BK, M2)\n",
    "valid_mask = scatter_indices < group_sizes.unsqueeze(1)\n",
    "\n",
    "# Apply the valid mask using torch.where\n",
    "dupped_indices = torch.where(valid_mask, group_indices, dupped_indices)\n",
    "\n",
    "# Initialize duplicated group sizes with ones\n",
    "dupped_group_sizes = torch.ones((BLOCK_BK, M2), dtype=group_sizes.dtype)\n",
    "\n",
    "# Reshape the indices and group sizes to flatten the first two dimensions\n",
    "# dupped_indices = dupped_indices.reshape(BLOCK_BK * M2)\n",
    "# dupped_group_sizes = dupped_group_sizes.reshape(BLOCK_BK * M2)\n",
    "\n",
    "print(dupped_indices)\n",
    "print(dupped_group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupped Indices:\n",
      "tensor([[ 2,  3,  4,  4],\n",
      "        [ 5,  6,  6,  6],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [10, 10, 10, 10],\n",
      "        [15, 16, 17, 18]])\n",
      "\n",
      "Dupped Group Sizes:\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example values for demonstration\n",
    "BLOCK_BK = 5  # Example BLOCK_BK value\n",
    "M2 = 4  # Example M2 value\n",
    "indices = torch.tensor([2, 5, 8, 10, 15], dtype=torch.int64)\n",
    "group_sizes = torch.tensor([3, 2, 4, 1, 4], dtype=torch.int64)\n",
    "\n",
    "# Create tensors with appropriate shapes and data types\n",
    "# Instead of using the garbage_value, initialize with indices + group_size - 1\n",
    "initial_value = indices.unsqueeze(1) + group_sizes.unsqueeze(1) - 1\n",
    "dupped_indices = initial_value.expand(BLOCK_BK, M2).clone()\n",
    "\n",
    "# Create group_indices\n",
    "group_indices = torch.arange(0, M2).unsqueeze(0).expand(BLOCK_BK, M2)  # Shape (BLOCK_BK, M2)\n",
    "\n",
    "# Add indices to group_indices along a new dimension\n",
    "group_indices = group_indices + indices.unsqueeze(1)\n",
    "\n",
    "# Scatter indices and create the valid mask\n",
    "scatter_indices = torch.arange(0, M2).unsqueeze(0).expand(BLOCK_BK, M2)\n",
    "valid_mask = scatter_indices < group_sizes.unsqueeze(1)\n",
    "\n",
    "# Apply the valid mask using torch.where\n",
    "dupped_indices = torch.where(valid_mask, group_indices, dupped_indices)\n",
    "\n",
    "# Initialize duplicated group sizes with ones\n",
    "dupped_group_sizes = torch.ones((BLOCK_BK, M2), dtype=group_sizes.dtype)\n",
    "\n",
    "# Print the result\n",
    "print(\"Dupped Indices:\")\n",
    "print(dupped_indices)\n",
    "print(\"\\nDupped Group Sizes:\")\n",
    "print(dupped_group_sizes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
