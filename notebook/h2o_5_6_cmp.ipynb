{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442128/936581573.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5.append(torch.load(f'../cache/llama/h2o_5_l3_i{i}.pth', map_location=torch.device('cpu')))\n",
      "/home/jina/anaconda3/envs/hip/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_442128/936581573.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6.append(torch.load(f'../cache/llama/h2o_6_l3_i{i}.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/936581573.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5.append(torch.load(f'../cache/llama/h2o_5_l3_i{i}.pth', map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "d5=[]\n",
    "d6=[]\n",
    "for i in range(5):\n",
    "    d5.append(torch.load(f'../cache/llama/h2o_5_l3_i{i}.pth', map_location=torch.device('cpu')))\n",
    "    d6.append(torch.load(f'../cache/llama/h2o_6_l3_i{i}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'q': tensor([[[[ 1.1094, -0.1309,  0.5000,  ...,  3.8125,  0.8438, -3.3594]],\n",
       "  \n",
       "           [[-0.5391, -0.6836, -0.2754,  ..., -1.9375, -1.4141, -1.4844]],\n",
       "  \n",
       "           [[-1.8672,  0.5977,  0.4141,  ...,  6.5312, -0.0688, -0.0488]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.7617,  0.5625,  0.2080,  ...,  6.1250, -0.6055,  0.5195]],\n",
       "  \n",
       "           [[ 1.0859, -0.8047,  0.5078,  ...,  0.4707, -0.7070,  0.5703]],\n",
       "  \n",
       "           [[-0.2441,  0.1279, -0.5391,  ...,  3.1406, -2.3281, -6.7812]]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
       "             -8.8867e-02,  4.0000e+00],\n",
       "            ...,\n",
       "            [ 1.0703e+00,  1.2109e+00,  1.4375e+00,  ..., -3.1719e+00,\n",
       "              7.3438e-01,  3.3281e+00],\n",
       "            [ 6.5625e-01,  4.5312e-01,  1.1406e+00,  ..., -2.8594e+00,\n",
       "              3.8867e-01,  3.1562e+00],\n",
       "            [ 6.6406e-02,  6.5625e-01,  1.0781e+00,  ..., -2.9844e+00,\n",
       "              3.9844e-01,  3.2500e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
       "              1.7734e+00,  1.3984e+00],\n",
       "            ...,\n",
       "            [ 3.8672e-01, -3.3789e-01,  2.8125e-01,  ...,  1.6094e+00,\n",
       "              1.3359e+00,  1.3672e+00],\n",
       "            [ 4.0625e-01, -3.6328e-01,  1.8945e-01,  ...,  1.9141e+00,\n",
       "              1.4219e+00,  1.2422e+00],\n",
       "            [ 3.6719e-01, -2.8906e-01,  1.6211e-01,  ...,  1.7891e+00,\n",
       "              1.3906e+00,  1.4219e+00]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
       "              7.1875e-01, -4.9219e-01],\n",
       "            ...,\n",
       "            [ 1.3281e-01,  6.4844e-01,  4.3555e-01,  ..., -6.5625e+00,\n",
       "              2.9688e-01, -2.6367e-01],\n",
       "            [ 3.9453e-01,  2.6953e-01,  1.1016e+00,  ..., -6.5000e+00,\n",
       "              6.3672e-01, -6.0547e-01],\n",
       "            [ 1.9531e-01, -2.8906e-01,  1.3203e+00,  ..., -6.6562e+00,\n",
       "              5.9375e-01, -9.8047e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
       "              1.5723e-01,  7.3047e-01],\n",
       "            ...,\n",
       "            [-1.0703e+00,  5.6152e-02,  2.4023e-01,  ..., -3.7812e+00,\n",
       "              2.5977e-01,  9.1016e-01],\n",
       "            [-1.1641e+00,  2.6953e-01,  1.9336e-01,  ..., -3.6875e+00,\n",
       "             -6.7969e-01,  5.5859e-01],\n",
       "            [-1.1250e+00,  2.6562e-01,  2.4023e-01,  ..., -3.8750e+00,\n",
       "             -4.9219e-01,  2.5781e-01]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
       "              7.4219e-01,  1.8457e-01],\n",
       "            ...,\n",
       "            [ 6.5234e-01,  2.1191e-01,  5.7422e-01,  ...,  4.4727e-01,\n",
       "              2.6953e-01, -3.2617e-01],\n",
       "            [ 1.3125e+00,  1.0693e-01,  2.5781e-01,  ..., -5.5078e-01,\n",
       "             -1.1328e+00, -9.9219e-01],\n",
       "            [ 1.2812e+00, -8.1055e-02,  1.3184e-01,  ...,  2.6758e-01,\n",
       "             -2.7930e-01, -8.8281e-01]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
       "              4.0938e+00,  2.5312e+00],\n",
       "            ...,\n",
       "            [ 3.9648e-01, -2.3926e-02,  2.3047e-01,  ..., -4.7812e+00,\n",
       "              4.0938e+00,  1.0469e+00],\n",
       "            [ 2.3828e-01, -9.7656e-02,  3.5938e-01,  ..., -4.2812e+00,\n",
       "              4.3750e+00, -1.2266e+00],\n",
       "            [ 4.7266e-01,  2.5879e-02,  4.8047e-01,  ..., -3.9688e+00,\n",
       "              4.5000e+00, -1.4062e+00]]]], dtype=torch.bfloat16),\n",
       "  'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-9.8145e-02,  1.6797e-01,  2.1973e-02,  ...,  3.9062e-02,\n",
       "              2.6172e-01, -7.9102e-02],\n",
       "            ...,\n",
       "            [-4.8438e-01, -3.7109e-01, -1.6895e-01,  ..., -1.6699e-01,\n",
       "              5.2344e-01,  8.6426e-02],\n",
       "            [-5.3125e-01,  1.0449e-01,  3.2715e-02,  ..., -7.4707e-02,\n",
       "             -5.6885e-02, -1.4062e-01],\n",
       "            [-5.4688e-01,  1.7578e-01,  2.0508e-01,  ..., -1.2012e-01,\n",
       "             -7.7148e-02,  1.9531e-01]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-2.6172e-01, -2.6758e-01, -2.7539e-01,  ...,  1.1670e-01,\n",
       "              2.3633e-01, -1.5723e-01],\n",
       "            ...,\n",
       "            [ 2.8711e-01, -1.4648e-01,  2.1191e-01,  ...,  1.5918e-01,\n",
       "              5.5469e-01, -7.0312e-02],\n",
       "            [ 2.7344e-01, -5.4199e-02,  1.4355e-01,  ...,  8.6914e-02,\n",
       "              1.0840e-01,  1.4648e-01],\n",
       "            [ 3.9844e-01,  1.4099e-02, -3.1738e-02,  ..., -1.3123e-02,\n",
       "             -1.2756e-02,  2.2168e-01]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 1.5039e-01,  2.1777e-01, -1.3855e-02,  ...,  5.7129e-02,\n",
       "              6.7871e-02, -3.6133e-02],\n",
       "            ...,\n",
       "            [-2.0898e-01, -1.8652e-01, -9.6680e-02,  ..., -2.0898e-01,\n",
       "              6.2256e-02,  6.4453e-02],\n",
       "            [ 3.7305e-01, -2.8906e-01,  1.9238e-01,  ..., -1.7773e-01,\n",
       "             -1.0059e-01, -3.7305e-01],\n",
       "            [ 2.8320e-01, -1.0010e-01,  2.1680e-01,  ..., -2.3340e-01,\n",
       "             -9.2773e-02, -3.5938e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [-2.2852e-01, -3.6914e-01,  2.1606e-02,  ...,  1.8652e-01,\n",
       "              4.8096e-02,  2.7734e-01],\n",
       "            ...,\n",
       "            [-6.9531e-01,  9.1797e-02, -1.9531e-01,  ...,  4.6875e-02,\n",
       "              8.3984e-02,  1.3770e-01],\n",
       "            [-1.2665e-03,  4.5654e-02, -2.4121e-01,  ...,  1.0352e-01,\n",
       "             -1.2012e-01, -9.9609e-02],\n",
       "            [-7.4707e-02,  2.8320e-02, -2.1973e-01,  ..., -8.9844e-02,\n",
       "             -6.4453e-02, -3.3984e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [-1.4062e-01,  2.7539e-01,  6.9824e-02,  ..., -1.0010e-01,\n",
       "             -3.2471e-02,  4.3945e-01],\n",
       "            ...,\n",
       "            [-2.2266e-01,  2.5977e-01,  3.3789e-01,  ..., -4.5166e-02,\n",
       "             -1.5625e-01,  3.5938e-01],\n",
       "            [-3.3203e-02,  9.0332e-02, -2.0898e-01,  ..., -2.7930e-01,\n",
       "             -4.4678e-02, -3.9307e-02],\n",
       "            [-4.4189e-02,  2.8711e-01, -2.2559e-01,  ..., -3.2227e-01,\n",
       "              4.5166e-02, -1.7773e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 9.5703e-02,  2.2949e-02,  4.5166e-03,  ..., -6.0303e-02,\n",
       "             -1.6895e-01, -7.3242e-02],\n",
       "            ...,\n",
       "            [ 1.8848e-01,  2.7539e-01, -1.8848e-01,  ...,  5.8105e-02,\n",
       "             -2.1484e-01, -4.9561e-02],\n",
       "            [ 1.4258e-01, -6.1768e-02, -2.9883e-01,  ...,  5.2979e-02,\n",
       "             -9.6680e-02,  1.9434e-01],\n",
       "            [ 1.1865e-01, -1.2305e-01, -2.6611e-02,  ...,  2.5757e-02,\n",
       "             -1.4941e-01,  1.8164e-01]]]], dtype=torch.bfloat16),\n",
       "  'kv_seq_len': 513,\n",
       "  'past_key_value': DynamicCache(),\n",
       "  'past_key_values_length': 513,\n",
       "  'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0.]]]], dtype=torch.bfloat16),\n",
       "  'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "              1.6689e-05,  1.4424e-05],\n",
       "            [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "              3.3379e-05,  2.8849e-05],\n",
       "            ...,\n",
       "            [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "              1.6968e-02,  1.4709e-02],\n",
       "            [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02],\n",
       "            [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "   'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            ...,\n",
       "            [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "          dtype=torch.bfloat16),\n",
       "   'cache_position': tensor([   0,    1,    2,  ..., 1021, 1022, 1023])},\n",
       "  'attn_weights': None,\n",
       "  'kv_hh': (False, DynamicCache()),\n",
       "  'attn_output': tensor([[[ 0.0103, -0.0184,  0.0082,  ..., -0.0004, -0.0255,  0.0020]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'hh_score': tensor([[[2.5100e+02, 2.1400e+02, 1.0449e-01,  ..., 2.0630e-02,\n",
       "            6.4453e-02, 5.0537e-02],\n",
       "           [2.5200e+02, 2.2300e+02, 1.1377e-01,  ..., 5.7678e-03,\n",
       "            1.1902e-03, 6.2180e-04],\n",
       "           [2.4000e+02, 2.1600e+02, 5.3955e-02,  ..., 1.5625e-01,\n",
       "            1.4355e-01, 3.9795e-02],\n",
       "           ...,\n",
       "           [2.6600e+02, 2.1700e+02, 4.7119e-02,  ..., 6.3477e-03,\n",
       "            5.8899e-03, 1.5259e-03],\n",
       "           [2.5400e+02, 2.1000e+02, 4.8584e-02,  ..., 2.6123e-02,\n",
       "            7.2754e-02, 1.9653e-02],\n",
       "           [2.0700e+02, 1.5400e+02, 6.0059e-02,  ..., 1.3611e-02,\n",
       "            5.3711e-03, 4.2419e-03]]], dtype=torch.bfloat16)},\n",
       " {'q': tensor([[[[ 0.9766, -0.2256,  0.4961,  ...,  3.6719,  1.1406, -3.2344]],\n",
       "  \n",
       "           [[-0.4453, -0.6875, -0.2012,  ..., -1.8594, -1.4141, -1.4844]],\n",
       "  \n",
       "           [[-1.8281,  0.2832,  0.0352,  ...,  6.3438,  0.0354, -0.1797]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.9102,  0.5312,  0.3066,  ...,  5.8750, -0.3867,  0.3906]],\n",
       "  \n",
       "           [[ 1.1562, -0.9219,  0.6211,  ...,  0.4902, -0.4316,  0.6016]],\n",
       "  \n",
       "           [[-0.5273,  0.0830, -0.6641,  ...,  3.1875, -1.8594, -6.5312]]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
       "             -8.8867e-02,  4.0000e+00],\n",
       "            ...,\n",
       "            [ 6.5625e-01,  4.5312e-01,  1.1406e+00,  ..., -2.8594e+00,\n",
       "              3.8867e-01,  3.1562e+00],\n",
       "            [ 6.6406e-02,  6.5625e-01,  1.0781e+00,  ..., -2.9844e+00,\n",
       "              3.9844e-01,  3.2500e+00],\n",
       "            [-4.8438e-01,  7.2266e-01,  8.0469e-01,  ..., -2.9688e+00,\n",
       "              1.9336e-01,  3.1719e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
       "              1.7734e+00,  1.3984e+00],\n",
       "            ...,\n",
       "            [ 4.0625e-01, -3.6328e-01,  1.8945e-01,  ...,  1.9141e+00,\n",
       "              1.4219e+00,  1.2422e+00],\n",
       "            [ 3.6719e-01, -2.8906e-01,  1.6211e-01,  ...,  1.7891e+00,\n",
       "              1.3906e+00,  1.4219e+00],\n",
       "            [ 2.4707e-01, -2.0312e-01,  1.2695e-01,  ...,  1.5391e+00,\n",
       "              1.3672e+00,  1.5234e+00]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
       "              7.1875e-01, -4.9219e-01],\n",
       "            ...,\n",
       "            [ 3.9453e-01,  2.6953e-01,  1.1016e+00,  ..., -6.5000e+00,\n",
       "              6.3672e-01, -6.0547e-01],\n",
       "            [ 1.9531e-01, -2.8906e-01,  1.3203e+00,  ..., -6.6562e+00,\n",
       "              5.9375e-01, -9.8047e-01],\n",
       "            [-1.7383e-01, -5.8594e-01,  1.5547e+00,  ..., -6.4688e+00,\n",
       "              4.4336e-01, -1.1875e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
       "              1.5723e-01,  7.3047e-01],\n",
       "            ...,\n",
       "            [-1.1641e+00,  2.6953e-01,  1.9336e-01,  ..., -3.6875e+00,\n",
       "             -6.7969e-01,  5.5859e-01],\n",
       "            [-1.1250e+00,  2.6562e-01,  2.4023e-01,  ..., -3.8750e+00,\n",
       "             -4.9219e-01,  2.5781e-01],\n",
       "            [-1.0469e+00,  2.0117e-01,  2.3633e-01,  ..., -3.8281e+00,\n",
       "             -5.0391e-01,  9.2285e-02]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
       "              7.4219e-01,  1.8457e-01],\n",
       "            ...,\n",
       "            [ 1.3125e+00,  1.0693e-01,  2.5781e-01,  ..., -5.5078e-01,\n",
       "             -1.1328e+00, -9.9219e-01],\n",
       "            [ 1.2812e+00, -8.1055e-02,  1.3184e-01,  ...,  2.6758e-01,\n",
       "             -2.7930e-01, -8.8281e-01],\n",
       "            [ 1.0469e+00, -2.2363e-01,  6.2500e-02,  ...,  8.2031e-01,\n",
       "              4.5508e-01, -8.6719e-01]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
       "              4.0938e+00,  2.5312e+00],\n",
       "            ...,\n",
       "            [ 2.3828e-01, -9.7656e-02,  3.5938e-01,  ..., -4.2812e+00,\n",
       "              4.3750e+00, -1.2266e+00],\n",
       "            [ 4.7266e-01,  2.5879e-02,  4.8047e-01,  ..., -3.9688e+00,\n",
       "              4.5000e+00, -1.4062e+00],\n",
       "            [ 6.1719e-01,  6.3477e-02,  5.4688e-01,  ..., -3.6250e+00,\n",
       "              4.5625e+00, -1.3750e+00]]]], dtype=torch.bfloat16),\n",
       "  'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-9.8145e-02,  1.6797e-01,  2.1973e-02,  ...,  3.9062e-02,\n",
       "              2.6172e-01, -7.9102e-02],\n",
       "            ...,\n",
       "            [-5.3125e-01,  1.0449e-01,  3.2715e-02,  ..., -7.4707e-02,\n",
       "             -5.6885e-02, -1.4062e-01],\n",
       "            [-5.4688e-01,  1.7578e-01,  2.0508e-01,  ..., -1.2012e-01,\n",
       "             -7.7148e-02,  1.9531e-01],\n",
       "            [-5.5469e-01,  1.7188e-01,  3.7109e-01,  ..., -9.5703e-02,\n",
       "             -4.6875e-02,  3.3789e-01]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-2.6172e-01, -2.6758e-01, -2.7539e-01,  ...,  1.1670e-01,\n",
       "              2.3633e-01, -1.5723e-01],\n",
       "            ...,\n",
       "            [ 2.7344e-01, -5.4199e-02,  1.4355e-01,  ...,  8.6914e-02,\n",
       "              1.0840e-01,  1.4648e-01],\n",
       "            [ 3.9844e-01,  1.4099e-02, -3.1738e-02,  ..., -1.3123e-02,\n",
       "             -1.2756e-02,  2.2168e-01],\n",
       "            [ 4.4727e-01,  1.0986e-01, -2.0703e-01,  ..., -7.1289e-02,\n",
       "             -2.5879e-02,  3.1641e-01]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 1.5039e-01,  2.1777e-01, -1.3855e-02,  ...,  5.7129e-02,\n",
       "              6.7871e-02, -3.6133e-02],\n",
       "            ...,\n",
       "            [ 3.7305e-01, -2.8906e-01,  1.9238e-01,  ..., -1.7773e-01,\n",
       "             -1.0059e-01, -3.7305e-01],\n",
       "            [ 2.8320e-01, -1.0010e-01,  2.1680e-01,  ..., -2.3340e-01,\n",
       "             -9.2773e-02, -3.5938e-01],\n",
       "            [ 1.4453e-01,  6.1279e-02,  2.2461e-01,  ..., -2.5000e-01,\n",
       "             -5.3711e-02, -3.1445e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [-2.2852e-01, -3.6914e-01,  2.1606e-02,  ...,  1.8652e-01,\n",
       "              4.8096e-02,  2.7734e-01],\n",
       "            ...,\n",
       "            [-1.2665e-03,  4.5654e-02, -2.4121e-01,  ...,  1.0352e-01,\n",
       "             -1.2012e-01, -9.9609e-02],\n",
       "            [-7.4707e-02,  2.8320e-02, -2.1973e-01,  ..., -8.9844e-02,\n",
       "             -6.4453e-02, -3.3984e-01],\n",
       "            [-8.2520e-02, -2.6245e-02, -1.6895e-01,  ..., -2.2461e-01,\n",
       "             -3.2471e-02, -5.1562e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [-1.4062e-01,  2.7539e-01,  6.9824e-02,  ..., -1.0010e-01,\n",
       "             -3.2471e-02,  4.3945e-01],\n",
       "            ...,\n",
       "            [-3.3203e-02,  9.0332e-02, -2.0898e-01,  ..., -2.7930e-01,\n",
       "             -4.4678e-02, -3.9307e-02],\n",
       "            [-4.4189e-02,  2.8711e-01, -2.2559e-01,  ..., -3.2227e-01,\n",
       "              4.5166e-02, -1.7773e-01],\n",
       "            [-1.1673e-03,  3.4961e-01, -2.4219e-01,  ..., -2.7344e-01,\n",
       "              1.8750e-01, -2.5195e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 9.5703e-02,  2.2949e-02,  4.5166e-03,  ..., -6.0303e-02,\n",
       "             -1.6895e-01, -7.3242e-02],\n",
       "            ...,\n",
       "            [ 1.4258e-01, -6.1768e-02, -2.9883e-01,  ...,  5.2979e-02,\n",
       "             -9.6680e-02,  1.9434e-01],\n",
       "            [ 1.1865e-01, -1.2305e-01, -2.6611e-02,  ...,  2.5757e-02,\n",
       "             -1.4941e-01,  1.8164e-01],\n",
       "            [ 1.0938e-01, -1.5527e-01,  1.5625e-01,  ..., -1.3306e-02,\n",
       "             -1.3672e-01,  1.6113e-01]]]], dtype=torch.bfloat16),\n",
       "  'kv_seq_len': 514,\n",
       "  'past_key_value': DynamicCache(),\n",
       "  'past_key_values_length': 514,\n",
       "  'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=torch.bfloat16),\n",
       "  'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "              1.6689e-05,  1.4424e-05],\n",
       "            [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "              3.3379e-05,  2.8849e-05],\n",
       "            ...,\n",
       "            [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "              1.6968e-02,  1.4709e-02],\n",
       "            [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02],\n",
       "            [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "   'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            ...,\n",
       "            [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "          dtype=torch.bfloat16),\n",
       "   'cache_position': tensor([   0,    1,    2,  ..., 1021, 1022, 1023])},\n",
       "  'attn_weights': None,\n",
       "  'kv_hh': (False, DynamicCache()),\n",
       "  'attn_output': tensor([[[ 0.0178, -0.0123,  0.0017,  ...,  0.0192, -0.0393,  0.0132]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'hh_score': tensor([[[2.5100e+02, 2.1400e+02, 1.0449e-01,  ..., 1.1621e-01,\n",
       "            1.1621e-01, 7.8613e-02],\n",
       "           [2.5300e+02, 2.2300e+02, 1.1377e-01,  ..., 2.0599e-03,\n",
       "            1.4191e-03, 8.6975e-04],\n",
       "           [2.4000e+02, 2.1600e+02, 5.3955e-02,  ..., 2.4609e-01,\n",
       "            1.0156e-01, 4.2480e-02],\n",
       "           ...,\n",
       "           [2.6600e+02, 2.1700e+02, 4.7119e-02,  ..., 1.0132e-02,\n",
       "            3.7231e-03, 1.5106e-03],\n",
       "           [2.5400e+02, 2.1000e+02, 4.8584e-02,  ..., 1.2207e-01,\n",
       "            4.3945e-02, 1.4526e-02],\n",
       "           [2.0700e+02, 1.5400e+02, 6.0059e-02,  ..., 7.9956e-03,\n",
       "            1.1108e-02, 9.0942e-03]]], dtype=torch.bfloat16)},\n",
       " {'q': tensor([[[[ 0.1592,  0.5000,  0.6016,  ...,  3.5156, -0.9453, -3.0938]],\n",
       "  \n",
       "           [[-0.0105, -0.4609, -0.1709,  ..., -1.4141, -0.9453, -1.2422]],\n",
       "  \n",
       "           [[-2.0781,  1.3750,  0.7188,  ...,  6.4375,  0.4414,  0.6133]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.8984,  0.4805,  0.0143,  ...,  5.9375,  0.5078,  0.7969]],\n",
       "  \n",
       "           [[ 0.9922, -0.5430,  0.3906,  ...,  0.1094,  0.3828,  0.5352]],\n",
       "  \n",
       "           [[-0.4453,  0.4609,  0.4805,  ...,  2.6875, -3.2344, -5.3438]]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
       "             -8.8867e-02,  4.0000e+00],\n",
       "            ...,\n",
       "            [ 6.6406e-02,  6.5625e-01,  1.0781e+00,  ..., -2.9844e+00,\n",
       "              3.9844e-01,  3.2500e+00],\n",
       "            [-4.8438e-01,  7.2266e-01,  8.0469e-01,  ..., -2.9688e+00,\n",
       "              1.9336e-01,  3.1719e+00],\n",
       "            [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "              6.5625e-01,  3.1719e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
       "              1.7734e+00,  1.3984e+00],\n",
       "            ...,\n",
       "            [ 3.6719e-01, -2.8906e-01,  1.6211e-01,  ...,  1.7891e+00,\n",
       "              1.3906e+00,  1.4219e+00],\n",
       "            [ 2.4707e-01, -2.0312e-01,  1.2695e-01,  ...,  1.5391e+00,\n",
       "              1.3672e+00,  1.5234e+00],\n",
       "            [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "              1.1641e+00,  1.2969e+00]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
       "              7.1875e-01, -4.9219e-01],\n",
       "            ...,\n",
       "            [ 1.9531e-01, -2.8906e-01,  1.3203e+00,  ..., -6.6562e+00,\n",
       "              5.9375e-01, -9.8047e-01],\n",
       "            [-1.7383e-01, -5.8594e-01,  1.5547e+00,  ..., -6.4688e+00,\n",
       "              4.4336e-01, -1.1875e+00],\n",
       "            [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "              5.3101e-03, -4.0039e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
       "              1.5723e-01,  7.3047e-01],\n",
       "            ...,\n",
       "            [-1.1250e+00,  2.6562e-01,  2.4023e-01,  ..., -3.8750e+00,\n",
       "             -4.9219e-01,  2.5781e-01],\n",
       "            [-1.0469e+00,  2.0117e-01,  2.3633e-01,  ..., -3.8281e+00,\n",
       "             -5.0391e-01,  9.2285e-02],\n",
       "            [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "             -9.8828e-01,  5.5078e-01]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
       "              7.4219e-01,  1.8457e-01],\n",
       "            ...,\n",
       "            [ 1.2812e+00, -8.1055e-02,  1.3184e-01,  ...,  2.6758e-01,\n",
       "             -2.7930e-01, -8.8281e-01],\n",
       "            [ 1.0469e+00, -2.2363e-01,  6.2500e-02,  ...,  8.2031e-01,\n",
       "              4.5508e-01, -8.6719e-01],\n",
       "            [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "              1.3984e+00,  1.0156e+00]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
       "              4.0938e+00,  2.5312e+00],\n",
       "            ...,\n",
       "            [ 4.7266e-01,  2.5879e-02,  4.8047e-01,  ..., -3.9688e+00,\n",
       "              4.5000e+00, -1.4062e+00],\n",
       "            [ 6.1719e-01,  6.3477e-02,  5.4688e-01,  ..., -3.6250e+00,\n",
       "              4.5625e+00, -1.3750e+00],\n",
       "            [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "              3.5625e+00,  2.7539e-01]]]], dtype=torch.bfloat16),\n",
       "  'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-9.8145e-02,  1.6797e-01,  2.1973e-02,  ...,  3.9062e-02,\n",
       "              2.6172e-01, -7.9102e-02],\n",
       "            ...,\n",
       "            [-5.4688e-01,  1.7578e-01,  2.0508e-01,  ..., -1.2012e-01,\n",
       "             -7.7148e-02,  1.9531e-01],\n",
       "            [-5.5469e-01,  1.7188e-01,  3.7109e-01,  ..., -9.5703e-02,\n",
       "             -4.6875e-02,  3.3789e-01],\n",
       "            [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "              3.8281e-01,  1.8555e-01]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-2.6172e-01, -2.6758e-01, -2.7539e-01,  ...,  1.1670e-01,\n",
       "              2.3633e-01, -1.5723e-01],\n",
       "            ...,\n",
       "            [ 3.9844e-01,  1.4099e-02, -3.1738e-02,  ..., -1.3123e-02,\n",
       "             -1.2756e-02,  2.2168e-01],\n",
       "            [ 4.4727e-01,  1.0986e-01, -2.0703e-01,  ..., -7.1289e-02,\n",
       "             -2.5879e-02,  3.1641e-01],\n",
       "            [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "              2.6172e-01,  4.5166e-03]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 1.5039e-01,  2.1777e-01, -1.3855e-02,  ...,  5.7129e-02,\n",
       "              6.7871e-02, -3.6133e-02],\n",
       "            ...,\n",
       "            [ 2.8320e-01, -1.0010e-01,  2.1680e-01,  ..., -2.3340e-01,\n",
       "             -9.2773e-02, -3.5938e-01],\n",
       "            [ 1.4453e-01,  6.1279e-02,  2.2461e-01,  ..., -2.5000e-01,\n",
       "             -5.3711e-02, -3.1445e-01],\n",
       "            [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "             -1.9141e-01,  5.2734e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [-2.2852e-01, -3.6914e-01,  2.1606e-02,  ...,  1.8652e-01,\n",
       "              4.8096e-02,  2.7734e-01],\n",
       "            ...,\n",
       "            [-7.4707e-02,  2.8320e-02, -2.1973e-01,  ..., -8.9844e-02,\n",
       "             -6.4453e-02, -3.3984e-01],\n",
       "            [-8.2520e-02, -2.6245e-02, -1.6895e-01,  ..., -2.2461e-01,\n",
       "             -3.2471e-02, -5.1562e-01],\n",
       "            [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "             -3.3203e-02, -2.7344e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [-1.4062e-01,  2.7539e-01,  6.9824e-02,  ..., -1.0010e-01,\n",
       "             -3.2471e-02,  4.3945e-01],\n",
       "            ...,\n",
       "            [-4.4189e-02,  2.8711e-01, -2.2559e-01,  ..., -3.2227e-01,\n",
       "              4.5166e-02, -1.7773e-01],\n",
       "            [-1.1673e-03,  3.4961e-01, -2.4219e-01,  ..., -2.7344e-01,\n",
       "              1.8750e-01, -2.5195e-01],\n",
       "            [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "             -2.6367e-01,  1.0107e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 9.5703e-02,  2.2949e-02,  4.5166e-03,  ..., -6.0303e-02,\n",
       "             -1.6895e-01, -7.3242e-02],\n",
       "            ...,\n",
       "            [ 1.1865e-01, -1.2305e-01, -2.6611e-02,  ...,  2.5757e-02,\n",
       "             -1.4941e-01,  1.8164e-01],\n",
       "            [ 1.0938e-01, -1.5527e-01,  1.5625e-01,  ..., -1.3306e-02,\n",
       "             -1.3672e-01,  1.6113e-01],\n",
       "            [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "              1.6309e-01,  7.3242e-03]]]], dtype=torch.bfloat16),\n",
       "  'kv_seq_len': 515,\n",
       "  'past_key_value': DynamicCache(),\n",
       "  'past_key_values_length': 515,\n",
       "  'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=torch.bfloat16),\n",
       "  'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "              1.6689e-05,  1.4424e-05],\n",
       "            [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "              3.3379e-05,  2.8849e-05],\n",
       "            ...,\n",
       "            [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "              1.6968e-02,  1.4709e-02],\n",
       "            [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02],\n",
       "            [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "   'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            ...,\n",
       "            [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "          dtype=torch.bfloat16),\n",
       "   'cache_position': tensor([   0,    1,    2,  ..., 1021, 1022, 1023])},\n",
       "  'attn_weights': None,\n",
       "  'kv_hh': (False, DynamicCache()),\n",
       "  'attn_output': tensor([[[-0.0160, -0.0371, -0.0039,  ..., -0.0035,  0.0027,  0.0145]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'hh_score': tensor([[[2.5100e+02, 2.1400e+02, 1.0449e-01,  ..., 1.2207e-01,\n",
       "            8.3496e-02, 1.7395e-03],\n",
       "           [2.5400e+02, 2.2300e+02, 1.1377e-01,  ..., 2.6550e-03,\n",
       "            2.2278e-03, 1.5869e-03],\n",
       "           [2.4000e+02, 2.1600e+02, 5.3955e-02,  ..., 1.2256e-01,\n",
       "            7.4707e-02, 3.5889e-02],\n",
       "           ...,\n",
       "           [2.6600e+02, 2.1700e+02, 4.7119e-02,  ..., 5.2490e-03,\n",
       "            2.5940e-03, 1.5945e-03],\n",
       "           [2.5400e+02, 2.1000e+02, 4.8584e-02,  ..., 6.0791e-02,\n",
       "            2.5146e-02, 6.1951e-03],\n",
       "           [2.0700e+02, 1.5400e+02, 6.0303e-02,  ..., 1.1353e-02,\n",
       "            9.3994e-03, 1.5442e-02]]], dtype=torch.bfloat16)},\n",
       " {'q': tensor([[[[-0.2402,  0.7266,  0.2100,  ...,  3.6875, -0.6680, -3.2812]],\n",
       "  \n",
       "           [[ 0.2402, -0.7656, -0.2080,  ..., -1.6953, -1.3125, -1.1641]],\n",
       "  \n",
       "           [[-2.6719, -0.2246,  0.9102,  ...,  6.3438,  0.3633,  1.3516]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.5703,  0.1426, -0.0156,  ...,  6.1562,  0.3691,  0.0413]],\n",
       "  \n",
       "           [[ 0.6016, -0.3301,  0.1641,  ..., -0.0806,  0.2119,  0.1416]],\n",
       "  \n",
       "           [[-0.3730,  0.4453,  0.5820,  ...,  3.3125, -2.4375, -2.5469]]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
       "             -8.8867e-02,  4.0000e+00],\n",
       "            ...,\n",
       "            [-4.8438e-01,  7.2266e-01,  8.0469e-01,  ..., -2.9688e+00,\n",
       "              1.9336e-01,  3.1719e+00],\n",
       "            [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "              6.5625e-01,  3.1719e+00],\n",
       "            [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "             -8.4375e-01,  3.4531e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
       "              1.7734e+00,  1.3984e+00],\n",
       "            ...,\n",
       "            [ 2.4707e-01, -2.0312e-01,  1.2695e-01,  ...,  1.5391e+00,\n",
       "              1.3672e+00,  1.5234e+00],\n",
       "            [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "              1.1641e+00,  1.2969e+00],\n",
       "            [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "              1.6016e+00,  9.7656e-01]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
       "              7.1875e-01, -4.9219e-01],\n",
       "            ...,\n",
       "            [-1.7383e-01, -5.8594e-01,  1.5547e+00,  ..., -6.4688e+00,\n",
       "              4.4336e-01, -1.1875e+00],\n",
       "            [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "              5.3101e-03, -4.0039e-01],\n",
       "            [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "              2.0020e-02, -8.6719e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
       "              1.5723e-01,  7.3047e-01],\n",
       "            ...,\n",
       "            [-1.0469e+00,  2.0117e-01,  2.3633e-01,  ..., -3.8281e+00,\n",
       "             -5.0391e-01,  9.2285e-02],\n",
       "            [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "             -9.8828e-01,  5.5078e-01],\n",
       "            [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "              7.0312e-02, -3.8867e-01]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
       "              7.4219e-01,  1.8457e-01],\n",
       "            ...,\n",
       "            [ 1.0469e+00, -2.2363e-01,  6.2500e-02,  ...,  8.2031e-01,\n",
       "              4.5508e-01, -8.6719e-01],\n",
       "            [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "              1.3984e+00,  1.0156e+00],\n",
       "            [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "              2.3906e+00,  1.8066e-01]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
       "              4.0938e+00,  2.5312e+00],\n",
       "            ...,\n",
       "            [ 6.1719e-01,  6.3477e-02,  5.4688e-01,  ..., -3.6250e+00,\n",
       "              4.5625e+00, -1.3750e+00],\n",
       "            [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "              3.5625e+00,  2.7539e-01],\n",
       "            [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "              5.0625e+00,  3.1562e+00]]]], dtype=torch.bfloat16),\n",
       "  'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-9.8145e-02,  1.6797e-01,  2.1973e-02,  ...,  3.9062e-02,\n",
       "              2.6172e-01, -7.9102e-02],\n",
       "            ...,\n",
       "            [-5.5469e-01,  1.7188e-01,  3.7109e-01,  ..., -9.5703e-02,\n",
       "             -4.6875e-02,  3.3789e-01],\n",
       "            [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "              3.8281e-01,  1.8555e-01],\n",
       "            [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "              2.3535e-01, -2.9297e-02]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-2.6172e-01, -2.6758e-01, -2.7539e-01,  ...,  1.1670e-01,\n",
       "              2.3633e-01, -1.5723e-01],\n",
       "            ...,\n",
       "            [ 4.4727e-01,  1.0986e-01, -2.0703e-01,  ..., -7.1289e-02,\n",
       "             -2.5879e-02,  3.1641e-01],\n",
       "            [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "              2.6172e-01,  4.5166e-03],\n",
       "            [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "              2.8906e-01,  1.6016e-01]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 1.5039e-01,  2.1777e-01, -1.3855e-02,  ...,  5.7129e-02,\n",
       "              6.7871e-02, -3.6133e-02],\n",
       "            ...,\n",
       "            [ 1.4453e-01,  6.1279e-02,  2.2461e-01,  ..., -2.5000e-01,\n",
       "             -5.3711e-02, -3.1445e-01],\n",
       "            [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "             -1.9141e-01,  5.2734e-01],\n",
       "            [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "             -4.3457e-02,  1.1328e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [-2.2852e-01, -3.6914e-01,  2.1606e-02,  ...,  1.8652e-01,\n",
       "              4.8096e-02,  2.7734e-01],\n",
       "            ...,\n",
       "            [-8.2520e-02, -2.6245e-02, -1.6895e-01,  ..., -2.2461e-01,\n",
       "             -3.2471e-02, -5.1562e-01],\n",
       "            [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "             -3.3203e-02, -2.7344e-01],\n",
       "            [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "             -2.0996e-01, -3.8281e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [-1.4062e-01,  2.7539e-01,  6.9824e-02,  ..., -1.0010e-01,\n",
       "             -3.2471e-02,  4.3945e-01],\n",
       "            ...,\n",
       "            [-1.1673e-03,  3.4961e-01, -2.4219e-01,  ..., -2.7344e-01,\n",
       "              1.8750e-01, -2.5195e-01],\n",
       "            [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "             -2.6367e-01,  1.0107e-01],\n",
       "            [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "             -2.3804e-02, -4.7656e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 9.5703e-02,  2.2949e-02,  4.5166e-03,  ..., -6.0303e-02,\n",
       "             -1.6895e-01, -7.3242e-02],\n",
       "            ...,\n",
       "            [ 1.0938e-01, -1.5527e-01,  1.5625e-01,  ..., -1.3306e-02,\n",
       "             -1.3672e-01,  1.6113e-01],\n",
       "            [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "              1.6309e-01,  7.3242e-03],\n",
       "            [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "              1.6895e-01,  9.0820e-02]]]], dtype=torch.bfloat16),\n",
       "  'kv_seq_len': 516,\n",
       "  'past_key_value': DynamicCache(),\n",
       "  'past_key_values_length': 516,\n",
       "  'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=torch.bfloat16),\n",
       "  'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "              1.6689e-05,  1.4424e-05],\n",
       "            [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "              3.3379e-05,  2.8849e-05],\n",
       "            ...,\n",
       "            [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "              1.6968e-02,  1.4709e-02],\n",
       "            [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02],\n",
       "            [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "   'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            ...,\n",
       "            [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "          dtype=torch.bfloat16),\n",
       "   'cache_position': tensor([   0,    1,    2,  ..., 1021, 1022, 1023])},\n",
       "  'attn_weights': None,\n",
       "  'kv_hh': (False, DynamicCache()),\n",
       "  'attn_output': tensor([[[-0.0008, -0.0229,  0.0139,  ..., -0.0151,  0.0198, -0.0009]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'hh_score': tensor([[[2.5100e+02, 2.1400e+02, 1.0449e-01,  ..., 8.4961e-02,\n",
       "            2.5482e-03, 8.2397e-03],\n",
       "           [2.5500e+02, 2.2300e+02, 1.1377e-01,  ..., 2.5024e-03,\n",
       "            1.9455e-03, 1.0681e-04],\n",
       "           [2.4000e+02, 2.1600e+02, 5.3955e-02,  ..., 1.0889e-01,\n",
       "            1.0254e-01, 3.2227e-02],\n",
       "           ...,\n",
       "           [2.6600e+02, 2.1700e+02, 4.7119e-02,  ..., 3.3569e-03,\n",
       "            2.6245e-03, 1.4114e-03],\n",
       "           [2.5400e+02, 2.1000e+02, 4.8584e-02,  ..., 3.0273e-02,\n",
       "            9.1553e-03, 2.9602e-03],\n",
       "           [2.0700e+02, 1.5400e+02, 6.0303e-02,  ..., 9.4604e-03,\n",
       "            1.5991e-02, 1.0742e-02]]], dtype=torch.bfloat16)},\n",
       " {'q': tensor([[[[ 0.3945,  0.8281,  0.6562,  ...,  3.8438, -0.9609, -3.3906]],\n",
       "  \n",
       "           [[ 0.1396, -0.6016, -0.2422,  ..., -1.8125, -1.4219, -1.1094]],\n",
       "  \n",
       "           [[-2.8750,  0.1016,  0.2324,  ...,  6.3750, -0.7891,  0.9688]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.4727, -0.0547,  0.1934,  ...,  6.2500, -0.3555,  0.8008]],\n",
       "  \n",
       "           [[ 0.5820, -0.4043,  0.2715,  ...,  0.0591, -0.3457,  0.5117]],\n",
       "  \n",
       "           [[-0.1445,  0.2598,  0.2344,  ...,  2.3750, -5.3750, -6.0000]]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
       "             -8.8867e-02,  4.0000e+00],\n",
       "            ...,\n",
       "            [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "              6.5625e-01,  3.1719e+00],\n",
       "            [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "             -8.4375e-01,  3.4531e+00],\n",
       "            [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
       "             -8.7891e-01,  3.4062e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
       "              1.7734e+00,  1.3984e+00],\n",
       "            ...,\n",
       "            [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "              1.1641e+00,  1.2969e+00],\n",
       "            [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "              1.6016e+00,  9.7656e-01],\n",
       "            [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
       "              1.2734e+00,  8.8281e-01]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
       "              7.1875e-01, -4.9219e-01],\n",
       "            ...,\n",
       "            [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "              5.3101e-03, -4.0039e-01],\n",
       "            [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "              2.0020e-02, -8.6719e-01],\n",
       "            [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
       "             -5.9766e-01, -4.4727e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
       "              1.5723e-01,  7.3047e-01],\n",
       "            ...,\n",
       "            [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "             -9.8828e-01,  5.5078e-01],\n",
       "            [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "              7.0312e-02, -3.8867e-01],\n",
       "            [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
       "              3.9648e-01,  6.1279e-02]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
       "              7.4219e-01,  1.8457e-01],\n",
       "            ...,\n",
       "            [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "              1.3984e+00,  1.0156e+00],\n",
       "            [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "              2.3906e+00,  1.8066e-01],\n",
       "            [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
       "              1.7422e+00,  6.2891e-01]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
       "              4.0938e+00,  2.5312e+00],\n",
       "            ...,\n",
       "            [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "              3.5625e+00,  2.7539e-01],\n",
       "            [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "              5.0625e+00,  3.1562e+00],\n",
       "            [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
       "              2.3750e+00,  4.7656e-01]]]], dtype=torch.bfloat16),\n",
       "  'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-9.8145e-02,  1.6797e-01,  2.1973e-02,  ...,  3.9062e-02,\n",
       "              2.6172e-01, -7.9102e-02],\n",
       "            ...,\n",
       "            [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "              3.8281e-01,  1.8555e-01],\n",
       "            [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "              2.3535e-01, -2.9297e-02],\n",
       "            [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "             -1.8848e-01,  1.3477e-01]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-2.6172e-01, -2.6758e-01, -2.7539e-01,  ...,  1.1670e-01,\n",
       "              2.3633e-01, -1.5723e-01],\n",
       "            ...,\n",
       "            [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "              2.6172e-01,  4.5166e-03],\n",
       "            [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "              2.8906e-01,  1.6016e-01],\n",
       "            [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "              2.9688e-01,  1.3580e-03]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 1.5039e-01,  2.1777e-01, -1.3855e-02,  ...,  5.7129e-02,\n",
       "              6.7871e-02, -3.6133e-02],\n",
       "            ...,\n",
       "            [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "             -1.9141e-01,  5.2734e-01],\n",
       "            [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "             -4.3457e-02,  1.1328e-01],\n",
       "            [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "              3.6621e-02,  3.8086e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [-2.2852e-01, -3.6914e-01,  2.1606e-02,  ...,  1.8652e-01,\n",
       "              4.8096e-02,  2.7734e-01],\n",
       "            ...,\n",
       "            [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "             -3.3203e-02, -2.7344e-01],\n",
       "            [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "             -2.0996e-01, -3.8281e-01],\n",
       "            [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "              2.0703e-01, -1.0254e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [-1.4062e-01,  2.7539e-01,  6.9824e-02,  ..., -1.0010e-01,\n",
       "             -3.2471e-02,  4.3945e-01],\n",
       "            ...,\n",
       "            [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "             -2.6367e-01,  1.0107e-01],\n",
       "            [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "             -2.3804e-02, -4.7656e-01],\n",
       "            [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "             -2.2656e-01, -9.6094e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 9.5703e-02,  2.2949e-02,  4.5166e-03,  ..., -6.0303e-02,\n",
       "             -1.6895e-01, -7.3242e-02],\n",
       "            ...,\n",
       "            [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "              1.6309e-01,  7.3242e-03],\n",
       "            [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "              1.6895e-01,  9.0820e-02],\n",
       "            [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "              9.9609e-02,  1.3867e-01]]]], dtype=torch.bfloat16),\n",
       "  'kv_seq_len': 517,\n",
       "  'past_key_value': DynamicCache(),\n",
       "  'past_key_values_length': 516,\n",
       "  'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "              1.6689e-05,  1.4424e-05],\n",
       "            [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "              3.3379e-05,  2.8849e-05],\n",
       "            ...,\n",
       "            [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "              1.6968e-02,  1.4709e-02],\n",
       "            [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02],\n",
       "            [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "              1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "   'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            ...,\n",
       "            [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "            [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "          dtype=torch.bfloat16),\n",
       "   'cache_position': tensor([   0,    1,    2,  ..., 1021, 1022, 1023])},\n",
       "  'attn_weights': None,\n",
       "  'kv_hh': (True,\n",
       "   tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "               5.3223e-02, -4.8633e-01],\n",
       "             [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "               5.1758e-02, -4.3555e-01],\n",
       "             [-2.5586e-01,  5.6641e-01, -6.9531e-01,  ..., -1.9453e+00,\n",
       "              -1.0625e+00,  2.1875e+00],\n",
       "             ...,\n",
       "             [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "               6.5625e-01,  3.1719e+00],\n",
       "             [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "              -8.4375e-01,  3.4531e+00],\n",
       "             [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
       "              -8.7891e-01,  3.4062e+00]],\n",
       "   \n",
       "            [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "              -4.2969e-01, -3.4570e-01],\n",
       "             [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "              -2.5586e-01, -1.9238e-01],\n",
       "             [ 3.3203e-02, -3.5645e-02, -3.3203e-02,  ...,  5.7812e-01,\n",
       "               7.8125e-01,  6.2500e-01],\n",
       "             ...,\n",
       "             [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "               1.1641e+00,  1.2969e+00],\n",
       "             [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "               1.6016e+00,  9.7656e-01],\n",
       "             [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
       "               1.2734e+00,  8.8281e-01]],\n",
       "   \n",
       "            [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "              -1.1621e-01,  1.7969e-01],\n",
       "             [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "              -1.1963e-01,  2.3438e-01],\n",
       "             [-9.4922e-01,  1.4141e+00,  3.3984e-01,  ..., -4.6562e+00,\n",
       "               1.3906e+00, -9.5703e-01],\n",
       "             ...,\n",
       "             [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "               5.3101e-03, -4.0039e-01],\n",
       "             [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "               2.0020e-02, -8.6719e-01],\n",
       "             [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
       "              -5.9766e-01, -4.4727e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "              -8.1055e-02,  5.9082e-02],\n",
       "             [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "              -8.3008e-02,  3.7598e-02],\n",
       "             [ 4.1602e-01, -1.3086e-01,  3.0664e-01,  ..., -2.3594e+00,\n",
       "              -1.4453e+00,  3.3789e-01],\n",
       "             ...,\n",
       "             [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "              -9.8828e-01,  5.5078e-01],\n",
       "             [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "               7.0312e-02, -3.8867e-01],\n",
       "             [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
       "               3.9648e-01,  6.1279e-02]],\n",
       "   \n",
       "            [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "              -8.5449e-02, -1.1902e-03],\n",
       "             [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "              -7.9590e-02, -7.2937e-03],\n",
       "             [ 5.2246e-02, -8.5547e-01,  4.6094e-01,  ..., -1.5312e+00,\n",
       "              -1.4688e+00, -1.6172e+00],\n",
       "             ...,\n",
       "             [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "               1.3984e+00,  1.0156e+00],\n",
       "             [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "               2.3906e+00,  1.8066e-01],\n",
       "             [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
       "               1.7422e+00,  6.2891e-01]],\n",
       "   \n",
       "            [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "              -6.0547e-01, -4.7656e-01],\n",
       "             [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "              -5.3125e-01, -4.3945e-01],\n",
       "             [-1.7090e-01, -2.9492e-01,  3.8867e-01,  ..., -3.5469e+00,\n",
       "               3.2031e+00, -1.2734e+00],\n",
       "             ...,\n",
       "             [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "               3.5625e+00,  2.7539e-01],\n",
       "             [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "               5.0625e+00,  3.1562e+00],\n",
       "             [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
       "               2.3750e+00,  4.7656e-01]]]], dtype=torch.bfloat16),\n",
       "   tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "              -2.0313e-04,  9.9487e-03],\n",
       "             [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "              -3.4943e-03,  6.3705e-04],\n",
       "             [-2.1606e-02,  3.9258e-01,  2.6562e-01,  ...,  3.6328e-01,\n",
       "               7.7148e-02, -6.0938e-01],\n",
       "             ...,\n",
       "             [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "               3.8281e-01,  1.8555e-01],\n",
       "             [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "               2.3535e-01, -2.9297e-02],\n",
       "             [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "              -1.8848e-01,  1.3477e-01]],\n",
       "   \n",
       "            [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "               2.8992e-03, -1.0986e-03],\n",
       "             [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "               4.2319e-06,  2.3193e-03],\n",
       "             [-4.0039e-02,  4.1016e-02, -1.6113e-01,  ...,  8.5938e-02,\n",
       "               2.8125e-01,  1.2598e-01],\n",
       "             ...,\n",
       "             [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "               2.6172e-01,  4.5166e-03],\n",
       "             [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "               2.8906e-01,  1.6016e-01],\n",
       "             [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "               2.9688e-01,  1.3580e-03]],\n",
       "   \n",
       "            [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "               8.0490e-04,  3.6011e-03],\n",
       "             [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "               4.7913e-03,  9.0332e-03],\n",
       "             [ 4.0625e-01,  1.2817e-02,  3.2227e-01,  ..., -1.4038e-02,\n",
       "               7.3730e-02, -3.2031e-01],\n",
       "             ...,\n",
       "             [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "              -1.9141e-01,  5.2734e-01],\n",
       "             [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "              -4.3457e-02,  1.1328e-01],\n",
       "             [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "               3.6621e-02,  3.8086e-02]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "              -1.1475e-02, -2.6093e-03],\n",
       "             [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "               1.5259e-03,  1.0529e-03],\n",
       "             [ 4.7070e-01,  3.5352e-01, -2.5781e-01,  ...,  4.0625e-01,\n",
       "              -3.5547e-01, -2.5195e-01],\n",
       "             ...,\n",
       "             [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "              -3.3203e-02, -2.7344e-01],\n",
       "             [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "              -2.0996e-01, -3.8281e-01],\n",
       "             [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "               2.0703e-01, -1.0254e-01]],\n",
       "   \n",
       "            [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "              -3.6926e-03, -1.8539e-03],\n",
       "             [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "               3.5095e-03, -4.6387e-03],\n",
       "             [ 1.8555e-01, -1.9629e-01, -2.7930e-01,  ..., -2.9053e-02,\n",
       "               5.8984e-01, -1.5430e-01],\n",
       "             ...,\n",
       "             [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "              -2.6367e-01,  1.0107e-01],\n",
       "             [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "              -2.3804e-02, -4.7656e-01],\n",
       "             [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "              -2.2656e-01, -9.6094e-01]],\n",
       "   \n",
       "            [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "               5.3101e-03,  4.3030e-03],\n",
       "             [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "              -4.6387e-03,  2.1667e-03],\n",
       "             [ 2.1973e-01,  1.2500e-01, -3.9453e-01,  ...,  2.0410e-01,\n",
       "              -1.8457e-01,  1.4709e-02],\n",
       "             ...,\n",
       "             [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "               1.6309e-01,  7.3242e-03],\n",
       "             [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "               1.6895e-01,  9.0820e-02],\n",
       "             [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "               9.9609e-02,  1.3867e-01]]]], dtype=torch.bfloat16)),\n",
       "  'attn_output': tensor([[[ 0.0054, -0.0162,  0.0083,  ..., -0.0330,  0.0061, -0.0008]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'hh_score': tensor([[[2.5200e+02, 2.1400e+02, 4.2500e+00,  ..., 3.3569e-03,\n",
       "            1.1841e-02, 3.6469e-03],\n",
       "           [2.5600e+02, 2.2300e+02, 1.0391e+00,  ..., 2.2888e-03,\n",
       "            2.0313e-04, 9.3460e-05],\n",
       "           [2.4000e+02, 2.1600e+02, 4.4531e-01,  ..., 1.6504e-01,\n",
       "            6.5918e-02, 4.3701e-02],\n",
       "           ...,\n",
       "           [2.6600e+02, 2.1700e+02, 1.2734e+00,  ..., 3.6316e-03,\n",
       "            2.3346e-03, 5.9509e-04],\n",
       "           [2.5400e+02, 2.1000e+02, 6.5625e-01,  ..., 1.2634e-02,\n",
       "            5.6152e-03, 3.8910e-03],\n",
       "           [2.0700e+02, 1.5400e+02, 3.9844e+00,  ..., 1.6113e-02,\n",
       "            1.0742e-02, 8.3618e-03]]], dtype=torch.bfloat16)}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q', 'k', 'v', 'kv_seq_len', 'past_key_value', 'past_key_values_length', 'attention_mask', 'cache_kwargs', 'attn_weights', 'kv_hh', 'attn_output', 'hh_score'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.1094, -0.1309,  0.5000,  ...,  3.8125,  0.8438, -3.3594]],\n",
       "\n",
       "         [[-0.5391, -0.6836, -0.2754,  ..., -1.9375, -1.4141, -1.4844]],\n",
       "\n",
       "         [[-1.8672,  0.5977,  0.4141,  ...,  6.5312, -0.0688, -0.0488]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.7617,  0.5625,  0.2080,  ...,  6.1250, -0.6055,  0.5195]],\n",
       "\n",
       "         [[ 1.0859, -0.8047,  0.5078,  ...,  0.4707, -0.7070,  0.5703]],\n",
       "\n",
       "         [[-0.2441,  0.1279, -0.5391,  ...,  3.1406, -2.3281, -6.7812]]]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[0]['q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(d5_i, d6_i):\n",
    "    keys = d5_i.keys()\n",
    "    for k in keys:\n",
    "        print('key ', k)\n",
    "        print(d5_i[k] == d6_i[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> i 0\n",
      "--------\n",
      "key  q\n",
      "tensor([[[[True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True]]]])\n",
      "--------\n",
      "key  k\n",
      "tensor([[[[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]]]])\n",
      "--------\n",
      "key  v\n",
      "tensor([[[[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]]]])\n",
      "--------\n",
      "key  kv_seq_len\n",
      "True\n",
      "--------\n",
      "key  past_key_value\n",
      "False\n",
      "--------\n",
      "key  past_key_values_length\n",
      "False\n",
      "--------\n",
      "key  attention_mask\n",
      "tensor([[[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True]]]])\n",
      "--------\n",
      "key  cache_kwargs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(d5)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>> i\u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43md5\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md6\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mcompare\u001b[0;34m(d5_i, d6_i)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey \u001b[39m\u001b[38;5;124m'\u001b[39m, k)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43md5_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md6_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "for i in range(len(d5)):\n",
    "    print('>> i', i)\n",
    "    compare(d5[i], d6[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': tensor([[[[ 0.3945,  0.8281,  0.6562,  ...,  3.8438, -0.9609, -3.3906]],\n",
       " \n",
       "          [[ 0.1396, -0.6016, -0.2422,  ..., -1.8125, -1.4219, -1.1094]],\n",
       " \n",
       "          [[-2.8750,  0.1016,  0.2324,  ...,  6.3750, -0.7891,  0.9688]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4727, -0.0547,  0.1934,  ...,  6.2500, -0.3555,  0.8008]],\n",
       " \n",
       "          [[ 0.5820, -0.4043,  0.2715,  ...,  0.0591, -0.3457,  0.5117]],\n",
       " \n",
       "          [[-0.1445,  0.2598,  0.2344,  ...,  2.3750, -5.3750, -6.0000]]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "             5.3223e-02, -4.8633e-01],\n",
       "           [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "             5.1758e-02, -4.3555e-01],\n",
       "           [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
       "            -8.8867e-02,  4.0000e+00],\n",
       "           ...,\n",
       "           [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "             6.5625e-01,  3.1719e+00],\n",
       "           [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "            -8.4375e-01,  3.4531e+00],\n",
       "           [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
       "            -8.7891e-01,  3.4062e+00]],\n",
       " \n",
       "          [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "            -4.2969e-01, -3.4570e-01],\n",
       "           [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "            -2.5586e-01, -1.9238e-01],\n",
       "           [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
       "             1.7734e+00,  1.3984e+00],\n",
       "           ...,\n",
       "           [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "             1.1641e+00,  1.2969e+00],\n",
       "           [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "             1.6016e+00,  9.7656e-01],\n",
       "           [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
       "             1.2734e+00,  8.8281e-01]],\n",
       " \n",
       "          [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "            -1.1621e-01,  1.7969e-01],\n",
       "           [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "            -1.1963e-01,  2.3438e-01],\n",
       "           [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
       "             7.1875e-01, -4.9219e-01],\n",
       "           ...,\n",
       "           [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "             5.3101e-03, -4.0039e-01],\n",
       "           [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "             2.0020e-02, -8.6719e-01],\n",
       "           [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
       "            -5.9766e-01, -4.4727e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "            -8.1055e-02,  5.9082e-02],\n",
       "           [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "            -8.3008e-02,  3.7598e-02],\n",
       "           [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
       "             1.5723e-01,  7.3047e-01],\n",
       "           ...,\n",
       "           [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "            -9.8828e-01,  5.5078e-01],\n",
       "           [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "             7.0312e-02, -3.8867e-01],\n",
       "           [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
       "             3.9648e-01,  6.1279e-02]],\n",
       " \n",
       "          [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "            -8.5449e-02, -1.1902e-03],\n",
       "           [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "            -7.9590e-02, -7.2937e-03],\n",
       "           [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
       "             7.4219e-01,  1.8457e-01],\n",
       "           ...,\n",
       "           [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "             1.3984e+00,  1.0156e+00],\n",
       "           [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "             2.3906e+00,  1.8066e-01],\n",
       "           [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
       "             1.7422e+00,  6.2891e-01]],\n",
       " \n",
       "          [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "            -6.0547e-01, -4.7656e-01],\n",
       "           [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "            -5.3125e-01, -4.3945e-01],\n",
       "           [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
       "             4.0938e+00,  2.5312e+00],\n",
       "           ...,\n",
       "           [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "             3.5625e+00,  2.7539e-01],\n",
       "           [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "             5.0625e+00,  3.1562e+00],\n",
       "           [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
       "             2.3750e+00,  4.7656e-01]]]], dtype=torch.bfloat16),\n",
       " 'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "            -2.0313e-04,  9.9487e-03],\n",
       "           [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "            -3.4943e-03,  6.3705e-04],\n",
       "           [-9.8145e-02,  1.6797e-01,  2.1973e-02,  ...,  3.9062e-02,\n",
       "             2.6172e-01, -7.9102e-02],\n",
       "           ...,\n",
       "           [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "             3.8281e-01,  1.8555e-01],\n",
       "           [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "             2.3535e-01, -2.9297e-02],\n",
       "           [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "            -1.8848e-01,  1.3477e-01]],\n",
       " \n",
       "          [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "             2.8992e-03, -1.0986e-03],\n",
       "           [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "             4.2319e-06,  2.3193e-03],\n",
       "           [-2.6172e-01, -2.6758e-01, -2.7539e-01,  ...,  1.1670e-01,\n",
       "             2.3633e-01, -1.5723e-01],\n",
       "           ...,\n",
       "           [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "             2.6172e-01,  4.5166e-03],\n",
       "           [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "             2.8906e-01,  1.6016e-01],\n",
       "           [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "             2.9688e-01,  1.3580e-03]],\n",
       " \n",
       "          [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "             8.0490e-04,  3.6011e-03],\n",
       "           [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "             4.7913e-03,  9.0332e-03],\n",
       "           [ 1.5039e-01,  2.1777e-01, -1.3855e-02,  ...,  5.7129e-02,\n",
       "             6.7871e-02, -3.6133e-02],\n",
       "           ...,\n",
       "           [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "            -1.9141e-01,  5.2734e-01],\n",
       "           [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "            -4.3457e-02,  1.1328e-01],\n",
       "           [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "             3.6621e-02,  3.8086e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "            -1.1475e-02, -2.6093e-03],\n",
       "           [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "             1.5259e-03,  1.0529e-03],\n",
       "           [-2.2852e-01, -3.6914e-01,  2.1606e-02,  ...,  1.8652e-01,\n",
       "             4.8096e-02,  2.7734e-01],\n",
       "           ...,\n",
       "           [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "            -3.3203e-02, -2.7344e-01],\n",
       "           [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "            -2.0996e-01, -3.8281e-01],\n",
       "           [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "             2.0703e-01, -1.0254e-01]],\n",
       " \n",
       "          [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "            -3.6926e-03, -1.8539e-03],\n",
       "           [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "             3.5095e-03, -4.6387e-03],\n",
       "           [-1.4062e-01,  2.7539e-01,  6.9824e-02,  ..., -1.0010e-01,\n",
       "            -3.2471e-02,  4.3945e-01],\n",
       "           ...,\n",
       "           [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "            -2.6367e-01,  1.0107e-01],\n",
       "           [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "            -2.3804e-02, -4.7656e-01],\n",
       "           [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "            -2.2656e-01, -9.6094e-01]],\n",
       " \n",
       "          [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "             5.3101e-03,  4.3030e-03],\n",
       "           [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "            -4.6387e-03,  2.1667e-03],\n",
       "           [ 9.5703e-02,  2.2949e-02,  4.5166e-03,  ..., -6.0303e-02,\n",
       "            -1.6895e-01, -7.3242e-02],\n",
       "           ...,\n",
       "           [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "             1.6309e-01,  7.3242e-03],\n",
       "           [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "             1.6895e-01,  9.0820e-02],\n",
       "           [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "             9.9609e-02,  1.3867e-01]]]], dtype=torch.bfloat16),\n",
       " 'kv_seq_len': 517,\n",
       " 'past_key_value': DynamicCache(),\n",
       " 'past_key_values_length': 516,\n",
       " 'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "             1.6689e-05,  1.4424e-05],\n",
       "           [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "             3.3379e-05,  2.8849e-05],\n",
       "           ...,\n",
       "           [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "             1.6968e-02,  1.4709e-02],\n",
       "           [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "             1.7090e-02,  1.4771e-02],\n",
       "           [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "             1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "  'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'cache_position': tensor([   0,    1,    2,  ..., 1021, 1022, 1023])},\n",
       " 'attn_weights': None,\n",
       " 'kv_hh': (True,\n",
       "  tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-2.5586e-01,  5.6641e-01, -6.9531e-01,  ..., -1.9453e+00,\n",
       "             -1.0625e+00,  2.1875e+00],\n",
       "            ...,\n",
       "            [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "              6.5625e-01,  3.1719e+00],\n",
       "            [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "             -8.4375e-01,  3.4531e+00],\n",
       "            [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
       "             -8.7891e-01,  3.4062e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [ 3.3203e-02, -3.5645e-02, -3.3203e-02,  ...,  5.7812e-01,\n",
       "              7.8125e-01,  6.2500e-01],\n",
       "            ...,\n",
       "            [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "              1.1641e+00,  1.2969e+00],\n",
       "            [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "              1.6016e+00,  9.7656e-01],\n",
       "            [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
       "              1.2734e+00,  8.8281e-01]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-9.4922e-01,  1.4141e+00,  3.3984e-01,  ..., -4.6562e+00,\n",
       "              1.3906e+00, -9.5703e-01],\n",
       "            ...,\n",
       "            [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "              5.3101e-03, -4.0039e-01],\n",
       "            [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "              2.0020e-02, -8.6719e-01],\n",
       "            [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
       "             -5.9766e-01, -4.4727e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 4.1602e-01, -1.3086e-01,  3.0664e-01,  ..., -2.3594e+00,\n",
       "             -1.4453e+00,  3.3789e-01],\n",
       "            ...,\n",
       "            [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "             -9.8828e-01,  5.5078e-01],\n",
       "            [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "              7.0312e-02, -3.8867e-01],\n",
       "            [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
       "              3.9648e-01,  6.1279e-02]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [ 5.2246e-02, -8.5547e-01,  4.6094e-01,  ..., -1.5312e+00,\n",
       "             -1.4688e+00, -1.6172e+00],\n",
       "            ...,\n",
       "            [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "              1.3984e+00,  1.0156e+00],\n",
       "            [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "              2.3906e+00,  1.8066e-01],\n",
       "            [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
       "              1.7422e+00,  6.2891e-01]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.7090e-01, -2.9492e-01,  3.8867e-01,  ..., -3.5469e+00,\n",
       "              3.2031e+00, -1.2734e+00],\n",
       "            ...,\n",
       "            [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "              3.5625e+00,  2.7539e-01],\n",
       "            [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "              5.0625e+00,  3.1562e+00],\n",
       "            [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
       "              2.3750e+00,  4.7656e-01]]]], dtype=torch.bfloat16),\n",
       "  tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-2.1606e-02,  3.9258e-01,  2.6562e-01,  ...,  3.6328e-01,\n",
       "              7.7148e-02, -6.0938e-01],\n",
       "            ...,\n",
       "            [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "              3.8281e-01,  1.8555e-01],\n",
       "            [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "              2.3535e-01, -2.9297e-02],\n",
       "            [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "             -1.8848e-01,  1.3477e-01]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-4.0039e-02,  4.1016e-02, -1.6113e-01,  ...,  8.5938e-02,\n",
       "              2.8125e-01,  1.2598e-01],\n",
       "            ...,\n",
       "            [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "              2.6172e-01,  4.5166e-03],\n",
       "            [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "              2.8906e-01,  1.6016e-01],\n",
       "            [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "              2.9688e-01,  1.3580e-03]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 4.0625e-01,  1.2817e-02,  3.2227e-01,  ..., -1.4038e-02,\n",
       "              7.3730e-02, -3.2031e-01],\n",
       "            ...,\n",
       "            [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "             -1.9141e-01,  5.2734e-01],\n",
       "            [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "             -4.3457e-02,  1.1328e-01],\n",
       "            [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "              3.6621e-02,  3.8086e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [ 4.7070e-01,  3.5352e-01, -2.5781e-01,  ...,  4.0625e-01,\n",
       "             -3.5547e-01, -2.5195e-01],\n",
       "            ...,\n",
       "            [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "             -3.3203e-02, -2.7344e-01],\n",
       "            [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "             -2.0996e-01, -3.8281e-01],\n",
       "            [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "              2.0703e-01, -1.0254e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [ 1.8555e-01, -1.9629e-01, -2.7930e-01,  ..., -2.9053e-02,\n",
       "              5.8984e-01, -1.5430e-01],\n",
       "            ...,\n",
       "            [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "             -2.6367e-01,  1.0107e-01],\n",
       "            [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "             -2.3804e-02, -4.7656e-01],\n",
       "            [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "             -2.2656e-01, -9.6094e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 2.1973e-01,  1.2500e-01, -3.9453e-01,  ...,  2.0410e-01,\n",
       "             -1.8457e-01,  1.4709e-02],\n",
       "            ...,\n",
       "            [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "              1.6309e-01,  7.3242e-03],\n",
       "            [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "              1.6895e-01,  9.0820e-02],\n",
       "            [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "              9.9609e-02,  1.3867e-01]]]], dtype=torch.bfloat16)),\n",
       " 'attn_output': tensor([[[ 0.0054, -0.0162,  0.0083,  ..., -0.0330,  0.0061, -0.0008]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'hh_score': tensor([[[2.5200e+02, 2.1400e+02, 4.2500e+00,  ..., 3.3569e-03,\n",
       "           1.1841e-02, 3.6469e-03],\n",
       "          [2.5600e+02, 2.2300e+02, 1.0391e+00,  ..., 2.2888e-03,\n",
       "           2.0313e-04, 9.3460e-05],\n",
       "          [2.4000e+02, 2.1600e+02, 4.4531e-01,  ..., 1.6504e-01,\n",
       "           6.5918e-02, 4.3701e-02],\n",
       "          ...,\n",
       "          [2.6600e+02, 2.1700e+02, 1.2734e+00,  ..., 3.6316e-03,\n",
       "           2.3346e-03, 5.9509e-04],\n",
       "          [2.5400e+02, 2.1000e+02, 6.5625e-01,  ..., 1.2634e-02,\n",
       "           5.6152e-03, 3.8910e-03],\n",
       "          [2.0700e+02, 1.5400e+02, 3.9844e+00,  ..., 1.6113e-02,\n",
       "           1.0742e-02, 8.3618e-03]]], dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q', 'k', 'v', 'kv_seq_len', 'past_key_value', 'past_key_values_length', 'attention_mask', 'cache_kwargs', 'attn_weights', 'kv_hh', 'attn_output', 'hh_score'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[4].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[4]['q'] != d6[4]['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2098969)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[4]['k'] != d6[4]['k'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2106113)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[4]['v'] != d6[4]['v'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 517, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[4]['v'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 517, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d6[4]['v'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[3]['q'] != d6[3]['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[3]['v'] != d6[3]['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': tensor([[[[ 0.3945,  0.8281,  0.6562,  ...,  3.8438, -0.9609, -3.3906]],\n",
       " \n",
       "          [[ 0.1396, -0.6016, -0.2422,  ..., -1.8125, -1.4219, -1.1094]],\n",
       " \n",
       "          [[-2.8750,  0.1016,  0.2324,  ...,  6.3750, -0.7891,  0.9688]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4727, -0.0547,  0.1934,  ...,  6.2500, -0.3555,  0.8008]],\n",
       " \n",
       "          [[ 0.5820, -0.4043,  0.2715,  ...,  0.0591, -0.3457,  0.5117]],\n",
       " \n",
       "          [[-0.1445,  0.2598,  0.2344,  ...,  2.3750, -5.3750, -6.0000]]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'k': tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "             5.3223e-02, -4.8633e-01],\n",
       "           [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "             5.1758e-02, -4.3555e-01],\n",
       "           [-2.5586e-01,  5.6641e-01, -6.9531e-01,  ..., -1.9453e+00,\n",
       "            -1.0625e+00,  2.1875e+00],\n",
       "           ...,\n",
       "           [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "            -8.4375e-01,  3.4531e+00],\n",
       "           [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
       "            -8.7891e-01,  3.4062e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "            -4.2969e-01, -3.4570e-01],\n",
       "           [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "            -2.5586e-01, -1.9238e-01],\n",
       "           [ 3.3203e-02, -3.5645e-02, -3.3203e-02,  ...,  5.7812e-01,\n",
       "             7.8125e-01,  6.2500e-01],\n",
       "           ...,\n",
       "           [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "             1.6016e+00,  9.7656e-01],\n",
       "           [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
       "             1.2734e+00,  8.8281e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "            -1.1621e-01,  1.7969e-01],\n",
       "           [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "            -1.1963e-01,  2.3438e-01],\n",
       "           [-9.4922e-01,  1.4141e+00,  3.3984e-01,  ..., -4.6562e+00,\n",
       "             1.3906e+00, -9.5703e-01],\n",
       "           ...,\n",
       "           [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "             2.0020e-02, -8.6719e-01],\n",
       "           [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
       "            -5.9766e-01, -4.4727e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "            -8.1055e-02,  5.9082e-02],\n",
       "           [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "            -8.3008e-02,  3.7598e-02],\n",
       "           [ 4.1602e-01, -1.3086e-01,  3.0664e-01,  ..., -2.3594e+00,\n",
       "            -1.4453e+00,  3.3789e-01],\n",
       "           ...,\n",
       "           [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "             7.0312e-02, -3.8867e-01],\n",
       "           [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
       "             3.9648e-01,  6.1279e-02],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "            -8.5449e-02, -1.1902e-03],\n",
       "           [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "            -7.9590e-02, -7.2937e-03],\n",
       "           [ 5.2246e-02, -8.5547e-01,  4.6094e-01,  ..., -1.5312e+00,\n",
       "            -1.4688e+00, -1.6172e+00],\n",
       "           ...,\n",
       "           [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "             2.3906e+00,  1.8066e-01],\n",
       "           [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
       "             1.7422e+00,  6.2891e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "            -6.0547e-01, -4.7656e-01],\n",
       "           [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "            -5.3125e-01, -4.3945e-01],\n",
       "           [-1.7090e-01, -2.9492e-01,  3.8867e-01,  ..., -3.5469e+00,\n",
       "             3.2031e+00, -1.2734e+00],\n",
       "           ...,\n",
       "           [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "             5.0625e+00,  3.1562e+00],\n",
       "           [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
       "             2.3750e+00,  4.7656e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]]], dtype=torch.bfloat16),\n",
       " 'v': tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "            -2.0313e-04,  9.9487e-03],\n",
       "           [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "            -3.4943e-03,  6.3705e-04],\n",
       "           [-2.1606e-02,  3.9258e-01,  2.6562e-01,  ...,  3.6328e-01,\n",
       "             7.7148e-02, -6.0938e-01],\n",
       "           ...,\n",
       "           [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "             2.3535e-01, -2.9297e-02],\n",
       "           [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "            -1.8848e-01,  1.3477e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "             2.8992e-03, -1.0986e-03],\n",
       "           [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "             4.2319e-06,  2.3193e-03],\n",
       "           [-4.0039e-02,  4.1016e-02, -1.6113e-01,  ...,  8.5938e-02,\n",
       "             2.8125e-01,  1.2598e-01],\n",
       "           ...,\n",
       "           [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "             2.8906e-01,  1.6016e-01],\n",
       "           [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "             2.9688e-01,  1.3580e-03],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "             8.0490e-04,  3.6011e-03],\n",
       "           [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "             4.7913e-03,  9.0332e-03],\n",
       "           [ 4.0625e-01,  1.2817e-02,  3.2227e-01,  ..., -1.4038e-02,\n",
       "             7.3730e-02, -3.2031e-01],\n",
       "           ...,\n",
       "           [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "            -4.3457e-02,  1.1328e-01],\n",
       "           [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "             3.6621e-02,  3.8086e-02],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "            -1.1475e-02, -2.6093e-03],\n",
       "           [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "             1.5259e-03,  1.0529e-03],\n",
       "           [ 4.7070e-01,  3.5352e-01, -2.5781e-01,  ...,  4.0625e-01,\n",
       "            -3.5547e-01, -2.5195e-01],\n",
       "           ...,\n",
       "           [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "            -2.0996e-01, -3.8281e-01],\n",
       "           [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "             2.0703e-01, -1.0254e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "            -3.6926e-03, -1.8539e-03],\n",
       "           [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "             3.5095e-03, -4.6387e-03],\n",
       "           [ 1.8555e-01, -1.9629e-01, -2.7930e-01,  ..., -2.9053e-02,\n",
       "             5.8984e-01, -1.5430e-01],\n",
       "           ...,\n",
       "           [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "            -2.3804e-02, -4.7656e-01],\n",
       "           [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "            -2.2656e-01, -9.6094e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "          [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "             5.3101e-03,  4.3030e-03],\n",
       "           [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "            -4.6387e-03,  2.1667e-03],\n",
       "           [ 2.1973e-01,  1.2500e-01, -3.9453e-01,  ...,  2.0410e-01,\n",
       "            -1.8457e-01,  1.4709e-02],\n",
       "           ...,\n",
       "           [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "             1.6895e-01,  9.0820e-02],\n",
       "           [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "             9.9609e-02,  1.3867e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]]], dtype=torch.bfloat16),\n",
       " 'kv_seq_len': 517,\n",
       " 'past_key_value': StaticCache(),\n",
       " 'past_key_values_length': 516,\n",
       " 'attention_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'cache_kwargs': {'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 1.2451e-01,  1.0791e-01,  9.3750e-02,  ...,  1.9193e-05,\n",
       "             1.6689e-05,  1.4424e-05],\n",
       "           [ 2.4707e-01,  2.1484e-01,  1.8652e-01,  ...,  3.8385e-05,\n",
       "             3.3379e-05,  2.8849e-05],\n",
       "           ...,\n",
       "           [ 9.2578e-01, -5.3516e-01,  9.9219e-01,  ...,  1.9653e-02,\n",
       "             1.6968e-02,  1.4709e-02],\n",
       "           [ 8.7109e-01, -6.2109e-01,  1.0000e+00,  ...,  1.9653e-02,\n",
       "             1.7090e-02,  1.4771e-02],\n",
       "           [ 8.0078e-01, -7.0312e-01,  9.9609e-01,  ...,  1.9653e-02,\n",
       "             1.7090e-02,  1.4771e-02]]], dtype=torch.bfloat16),\n",
       "  'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9922,  0.9961,  0.9961,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9688,  0.9766,  0.9844,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [-0.3809, -0.8438,  0.1133,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [-0.4922, -0.7812,  0.0197,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [-0.5977, -0.7109, -0.0742,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "         dtype=torch.bfloat16),\n",
       "  'cache_position': tensor([516])},\n",
       " 'attn_weights': None,\n",
       " 'kv_hh': (True,\n",
       "  tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
       "              5.3223e-02, -4.8633e-01],\n",
       "            [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
       "              5.1758e-02, -4.3555e-01],\n",
       "            [-2.5586e-01,  5.6641e-01, -6.9531e-01,  ..., -1.9453e+00,\n",
       "             -1.0625e+00,  2.1875e+00],\n",
       "            ...,\n",
       "            [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
       "              6.5625e-01,  3.1719e+00],\n",
       "            [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
       "             -8.4375e-01,  3.4531e+00],\n",
       "            [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
       "             -8.7891e-01,  3.4062e+00]],\n",
       "  \n",
       "           [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
       "             -4.2969e-01, -3.4570e-01],\n",
       "            [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
       "             -2.5586e-01, -1.9238e-01],\n",
       "            [ 3.3203e-02, -3.5645e-02, -3.3203e-02,  ...,  5.7812e-01,\n",
       "              7.8125e-01,  6.2500e-01],\n",
       "            ...,\n",
       "            [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
       "              1.1641e+00,  1.2969e+00],\n",
       "            [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
       "              1.6016e+00,  9.7656e-01],\n",
       "            [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
       "              1.2734e+00,  8.8281e-01]],\n",
       "  \n",
       "           [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
       "             -1.1621e-01,  1.7969e-01],\n",
       "            [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
       "             -1.1963e-01,  2.3438e-01],\n",
       "            [-9.4922e-01,  1.4141e+00,  3.3984e-01,  ..., -4.6562e+00,\n",
       "              1.3906e+00, -9.5703e-01],\n",
       "            ...,\n",
       "            [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
       "              5.3101e-03, -4.0039e-01],\n",
       "            [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
       "              2.0020e-02, -8.6719e-01],\n",
       "            [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
       "             -5.9766e-01, -4.4727e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
       "             -8.1055e-02,  5.9082e-02],\n",
       "            [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
       "             -8.3008e-02,  3.7598e-02],\n",
       "            [ 4.1602e-01, -1.3086e-01,  3.0664e-01,  ..., -2.3594e+00,\n",
       "             -1.4453e+00,  3.3789e-01],\n",
       "            ...,\n",
       "            [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
       "             -9.8828e-01,  5.5078e-01],\n",
       "            [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
       "              7.0312e-02, -3.8867e-01],\n",
       "            [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
       "              3.9648e-01,  6.1279e-02]],\n",
       "  \n",
       "           [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
       "             -8.5449e-02, -1.1902e-03],\n",
       "            [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
       "             -7.9590e-02, -7.2937e-03],\n",
       "            [ 5.2246e-02, -8.5547e-01,  4.6094e-01,  ..., -1.5312e+00,\n",
       "             -1.4688e+00, -1.6172e+00],\n",
       "            ...,\n",
       "            [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
       "              1.3984e+00,  1.0156e+00],\n",
       "            [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
       "              2.3906e+00,  1.8066e-01],\n",
       "            [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
       "              1.7422e+00,  6.2891e-01]],\n",
       "  \n",
       "           [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
       "             -6.0547e-01, -4.7656e-01],\n",
       "            [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
       "             -5.3125e-01, -4.3945e-01],\n",
       "            [-1.7090e-01, -2.9492e-01,  3.8867e-01,  ..., -3.5469e+00,\n",
       "              3.2031e+00, -1.2734e+00],\n",
       "            ...,\n",
       "            [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
       "              3.5625e+00,  2.7539e-01],\n",
       "            [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
       "              5.0625e+00,  3.1562e+00],\n",
       "            [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
       "              2.3750e+00,  4.7656e-01]]]], dtype=torch.bfloat16),\n",
       "  tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "             -2.0313e-04,  9.9487e-03],\n",
       "            [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "             -3.4943e-03,  6.3705e-04],\n",
       "            [-2.1606e-02,  3.9258e-01,  2.6562e-01,  ...,  3.6328e-01,\n",
       "              7.7148e-02, -6.0938e-01],\n",
       "            ...,\n",
       "            [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "              3.8281e-01,  1.8555e-01],\n",
       "            [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "              2.3535e-01, -2.9297e-02],\n",
       "            [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "             -1.8848e-01,  1.3477e-01]],\n",
       "  \n",
       "           [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "              2.8992e-03, -1.0986e-03],\n",
       "            [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "              4.2319e-06,  2.3193e-03],\n",
       "            [-4.0039e-02,  4.1016e-02, -1.6113e-01,  ...,  8.5938e-02,\n",
       "              2.8125e-01,  1.2598e-01],\n",
       "            ...,\n",
       "            [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "              2.6172e-01,  4.5166e-03],\n",
       "            [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "              2.8906e-01,  1.6016e-01],\n",
       "            [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "              2.9688e-01,  1.3580e-03]],\n",
       "  \n",
       "           [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "              8.0490e-04,  3.6011e-03],\n",
       "            [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "              4.7913e-03,  9.0332e-03],\n",
       "            [ 4.0625e-01,  1.2817e-02,  3.2227e-01,  ..., -1.4038e-02,\n",
       "              7.3730e-02, -3.2031e-01],\n",
       "            ...,\n",
       "            [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "             -1.9141e-01,  5.2734e-01],\n",
       "            [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "             -4.3457e-02,  1.1328e-01],\n",
       "            [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "              3.6621e-02,  3.8086e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "             -1.1475e-02, -2.6093e-03],\n",
       "            [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "              1.5259e-03,  1.0529e-03],\n",
       "            [ 4.7070e-01,  3.5352e-01, -2.5781e-01,  ...,  4.0625e-01,\n",
       "             -3.5547e-01, -2.5195e-01],\n",
       "            ...,\n",
       "            [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "             -3.3203e-02, -2.7344e-01],\n",
       "            [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "             -2.0996e-01, -3.8281e-01],\n",
       "            [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "              2.0703e-01, -1.0254e-01]],\n",
       "  \n",
       "           [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "             -3.6926e-03, -1.8539e-03],\n",
       "            [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "              3.5095e-03, -4.6387e-03],\n",
       "            [ 1.8555e-01, -1.9629e-01, -2.7930e-01,  ..., -2.9053e-02,\n",
       "              5.8984e-01, -1.5430e-01],\n",
       "            ...,\n",
       "            [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "             -2.6367e-01,  1.0107e-01],\n",
       "            [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "             -2.3804e-02, -4.7656e-01],\n",
       "            [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "             -2.2656e-01, -9.6094e-01]],\n",
       "  \n",
       "           [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "              5.3101e-03,  4.3030e-03],\n",
       "            [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "             -4.6387e-03,  2.1667e-03],\n",
       "            [ 2.1973e-01,  1.2500e-01, -3.9453e-01,  ...,  2.0410e-01,\n",
       "             -1.8457e-01,  1.4709e-02],\n",
       "            ...,\n",
       "            [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "              1.6309e-01,  7.3242e-03],\n",
       "            [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "              1.6895e-01,  9.0820e-02],\n",
       "            [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "              9.9609e-02,  1.3867e-01]]]], dtype=torch.bfloat16)),\n",
       " 'attn_output': tensor([[[ 0.0093, -0.0258,  0.0129,  ..., -0.0250,  0.0026,  0.0156]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'hh_score': tensor([[[2.5200e+02, 2.1400e+02, 4.2500e+00,  ..., 3.3569e-03,\n",
       "           1.1841e-02, 3.6469e-03],\n",
       "          [2.5600e+02, 2.2300e+02, 1.0391e+00,  ..., 2.2888e-03,\n",
       "           2.0313e-04, 9.3460e-05],\n",
       "          [2.4000e+02, 2.1600e+02, 4.4531e-01,  ..., 1.6504e-01,\n",
       "           6.5918e-02, 4.3701e-02],\n",
       "          ...,\n",
       "          [2.6600e+02, 2.1700e+02, 1.2734e+00,  ..., 3.6316e-03,\n",
       "           2.3346e-03, 5.9509e-04],\n",
       "          [2.5400e+02, 2.1000e+02, 6.5625e-01,  ..., 1.2634e-02,\n",
       "           5.6152e-03, 3.8910e-03],\n",
       "          [2.0700e+02, 1.5400e+02, 3.9844e+00,  ..., 1.6113e-02,\n",
       "           1.0742e-02, 8.3618e-03]]], dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d6[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442128/3484282968.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_rope.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_rope.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_rope.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_rope.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_pkv.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_pkv.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_pkv.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_pkv.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_repeat.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_repeat.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_repeat.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_repeat.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}.pth', map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442128/3484282968.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_kvhh.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_kvhh.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_pkw_update.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/3484282968.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_pkw_update.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "d5_rope=[]\n",
    "d6_rope=[]\n",
    "d5_pkv=[]\n",
    "d6_pkv=[]\n",
    "d5_repeat=[]\n",
    "d6_repeat=[]\n",
    "d5_kvhh=[]\n",
    "d6_kvhh=[]\n",
    "d5_pkw_update=[]\n",
    "d6_pkw_update=[]\n",
    "d5=[]\n",
    "d6=[]\n",
    "for i in range(5):\n",
    "    d5_rope.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_rope.pth', map_location=torch.device('cpu')))\n",
    "    d6_rope.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_rope.pth', map_location=torch.device('cpu')))\n",
    "    d5_pkv.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_pkv.pth', map_location=torch.device('cpu')))\n",
    "    d6_pkv.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_pkv.pth', map_location=torch.device('cpu')))\n",
    "    d5_repeat.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_repeat.pth', map_location=torch.device('cpu')))\n",
    "    d6_repeat.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_repeat.pth', map_location=torch.device('cpu')))\n",
    "    d5.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}.pth', map_location=torch.device('cpu')))\n",
    "    d6.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}.pth', map_location=torch.device('cpu')))\n",
    "    d5_kvhh.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
    "    d6_kvhh.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
    "    d5_pkw_update.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n",
    "    d6_pkw_update.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_pkw_update[4]['k']!=d6_pkw_update[4]['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum(): argument 'input' (position 1) must be Tensor, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43md5\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattn_weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43md6\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattn_weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not bool"
     ]
    }
   ],
   "source": [
    "torch.sum(d5[4]['attention_mask']!=d6[4]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5[4]['attn_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_pkv[4]['k']!=d6_pkv[4]['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_repeat[4]['k']!=d6_repeat[4]['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_repeat[4]['v']!=d6_repeat[4]['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2098969)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[4]['k']!=d6[4]['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2106113)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[4]['v']!=d6[4]['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5[4]['kv_hh'][2]!=d6[4]['kv_hh'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.3869e-04,  1.5793e-03, -1.7853e-03,  ..., -7.7515e-03,\n",
       "           -2.0313e-04,  9.9487e-03],\n",
       "          [ 9.5367e-04,  6.4697e-03, -3.6011e-03,  ..., -6.9580e-03,\n",
       "           -3.4943e-03,  6.3705e-04],\n",
       "          [-2.1606e-02,  3.9258e-01,  2.6562e-01,  ...,  3.6328e-01,\n",
       "            7.7148e-02, -6.0938e-01],\n",
       "          ...,\n",
       "          [-1.1279e-01, -4.7913e-03,  3.0664e-01,  ...,  2.2754e-01,\n",
       "            3.8281e-01,  1.8555e-01],\n",
       "          [-1.6797e-01, -1.7188e-01,  1.4160e-01,  ...,  2.8516e-01,\n",
       "            2.3535e-01, -2.9297e-02],\n",
       "          [-1.4062e-01, -8.0566e-03,  4.4141e-01,  ...,  1.6309e-01,\n",
       "           -1.8848e-01,  1.3477e-01]],\n",
       "\n",
       "         [[ 4.6387e-03,  6.8970e-03, -1.0498e-02,  ..., -3.8147e-03,\n",
       "            2.8992e-03, -1.0986e-03],\n",
       "          [ 9.3937e-05,  2.7008e-03, -1.1536e-02,  ...,  1.0132e-02,\n",
       "            4.2319e-06,  2.3193e-03],\n",
       "          [-4.0039e-02,  4.1016e-02, -1.6113e-01,  ...,  8.5938e-02,\n",
       "            2.8125e-01,  1.2598e-01],\n",
       "          ...,\n",
       "          [ 2.6172e-01,  1.1865e-01, -5.6396e-02,  ...,  1.4844e-01,\n",
       "            2.6172e-01,  4.5166e-03],\n",
       "          [-2.3535e-01,  2.7734e-01, -2.6367e-02,  ...,  9.0820e-02,\n",
       "            2.8906e-01,  1.6016e-01],\n",
       "          [-1.1377e-01,  1.0986e-01, -2.3315e-02,  ...,  2.5781e-01,\n",
       "            2.9688e-01,  1.3580e-03]],\n",
       "\n",
       "         [[ 6.6833e-03,  1.5320e-02, -8.7280e-03,  ...,  1.0803e-02,\n",
       "            8.0490e-04,  3.6011e-03],\n",
       "          [ 6.2256e-03,  7.2632e-03, -9.3994e-03,  ...,  1.0620e-02,\n",
       "            4.7913e-03,  9.0332e-03],\n",
       "          [ 4.0625e-01,  1.2817e-02,  3.2227e-01,  ..., -1.4038e-02,\n",
       "            7.3730e-02, -3.2031e-01],\n",
       "          ...,\n",
       "          [-3.2812e-01,  2.3633e-01,  2.1191e-01,  ...,  1.6895e-01,\n",
       "           -1.9141e-01,  5.2734e-01],\n",
       "          [-4.6875e-01,  7.9102e-02,  1.7188e-01,  ...,  9.6191e-02,\n",
       "           -4.3457e-02,  1.1328e-01],\n",
       "          [-3.0273e-01,  6.4062e-01, -5.7422e-01,  ...,  1.7383e-01,\n",
       "            3.6621e-02,  3.8086e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7014e-03,  1.0681e-02,  1.1475e-02,  ..., -1.6937e-03,\n",
       "           -1.1475e-02, -2.6093e-03],\n",
       "          [ 3.6621e-03, -1.1826e-03,  1.1063e-03,  ...,  6.5918e-03,\n",
       "            1.5259e-03,  1.0529e-03],\n",
       "          [ 4.7070e-01,  3.5352e-01, -2.5781e-01,  ...,  4.0625e-01,\n",
       "           -3.5547e-01, -2.5195e-01],\n",
       "          ...,\n",
       "          [-3.5938e-01, -2.3145e-01,  5.3955e-02,  ...,  2.4658e-02,\n",
       "           -3.3203e-02, -2.7344e-01],\n",
       "          [-5.8594e-01, -1.4062e-01, -1.5503e-02,  ...,  2.4512e-01,\n",
       "           -2.0996e-01, -3.8281e-01],\n",
       "          [-5.0000e-01, -8.4229e-03,  2.8906e-01,  ...,  2.2656e-01,\n",
       "            2.0703e-01, -1.0254e-01]],\n",
       "\n",
       "         [[ 6.1951e-03, -1.5747e-02, -3.3264e-03,  ..., -1.3245e-02,\n",
       "           -3.6926e-03, -1.8539e-03],\n",
       "          [ 1.2817e-02, -6.9275e-03,  4.1199e-03,  ..., -1.8677e-02,\n",
       "            3.5095e-03, -4.6387e-03],\n",
       "          [ 1.8555e-01, -1.9629e-01, -2.7930e-01,  ..., -2.9053e-02,\n",
       "            5.8984e-01, -1.5430e-01],\n",
       "          ...,\n",
       "          [-3.4180e-01,  3.3398e-01,  1.3574e-01,  ..., -2.2168e-01,\n",
       "           -2.6367e-01,  1.0107e-01],\n",
       "          [-1.8677e-02,  4.6680e-01, -7.3242e-02,  ...,  2.5781e-01,\n",
       "           -2.3804e-02, -4.7656e-01],\n",
       "          [-1.9043e-02,  5.3516e-01,  2.6562e-01,  ..., -2.2461e-01,\n",
       "           -2.2656e-01, -9.6094e-01]],\n",
       "\n",
       "         [[ 4.7913e-03,  1.1536e-02, -3.9978e-03,  ..., -9.3460e-05,\n",
       "            5.3101e-03,  4.3030e-03],\n",
       "          [ 6.8359e-03,  1.2024e-02, -7.1106e-03,  ...,  2.5635e-03,\n",
       "           -4.6387e-03,  2.1667e-03],\n",
       "          [ 2.1973e-01,  1.2500e-01, -3.9453e-01,  ...,  2.0410e-01,\n",
       "           -1.8457e-01,  1.4709e-02],\n",
       "          ...,\n",
       "          [-1.9141e-01,  1.8066e-01,  3.6133e-02,  ..., -1.5039e-01,\n",
       "            1.6309e-01,  7.3242e-03],\n",
       "          [-1.1621e-01,  1.8457e-01,  7.5195e-02,  ..., -9.8145e-02,\n",
       "            1.6895e-01,  9.0820e-02],\n",
       "          [-2.3651e-03,  1.5039e-01, -1.0376e-02,  ..., -1.0889e-01,\n",
       "            9.9609e-02,  1.3867e-01]]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[4]['kv_hh'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
      "            5.3223e-02, -4.8633e-01],\n",
      "          [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
      "            5.1758e-02, -4.3555e-01],\n",
      "          [-1.3916e-02,  6.7969e-01, -1.0234e+00,  ..., -3.8281e+00,\n",
      "           -8.8867e-02,  4.0000e+00],\n",
      "          ...,\n",
      "          [ 7.3047e-01,  9.1406e-01,  1.0156e+00,  ..., -3.0000e+00,\n",
      "            6.5625e-01,  3.1719e+00],\n",
      "          [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
      "           -8.4375e-01,  3.4531e+00],\n",
      "          [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
      "           -8.7891e-01,  3.4062e+00]],\n",
      "\n",
      "         [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
      "           -4.2969e-01, -3.4570e-01],\n",
      "          [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
      "           -2.5586e-01, -1.9238e-01],\n",
      "          [-8.0078e-02, -4.5312e-01, -2.4219e-01,  ...,  8.2812e-01,\n",
      "            1.7734e+00,  1.3984e+00],\n",
      "          ...,\n",
      "          [ 9.4238e-02, -4.8047e-01,  2.0605e-01,  ...,  1.1484e+00,\n",
      "            1.1641e+00,  1.2969e+00],\n",
      "          [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
      "            1.6016e+00,  9.7656e-01],\n",
      "          [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
      "            1.2734e+00,  8.8281e-01]],\n",
      "\n",
      "         [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
      "           -1.1621e-01,  1.7969e-01],\n",
      "          [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
      "           -1.1963e-01,  2.3438e-01],\n",
      "          [-7.5781e-01,  1.1914e-01, -7.5684e-02,  ..., -6.9688e+00,\n",
      "            7.1875e-01, -4.9219e-01],\n",
      "          ...,\n",
      "          [-7.7734e-01,  1.2344e+00,  1.1562e+00,  ..., -6.5000e+00,\n",
      "            5.3101e-03, -4.0039e-01],\n",
      "          [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
      "            2.0020e-02, -8.6719e-01],\n",
      "          [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
      "           -5.9766e-01, -4.4727e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
      "           -8.1055e-02,  5.9082e-02],\n",
      "          [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
      "           -8.3008e-02,  3.7598e-02],\n",
      "          [ 5.8984e-01,  2.3828e-01,  1.3867e-01,  ..., -4.4375e+00,\n",
      "            1.5723e-01,  7.3047e-01],\n",
      "          ...,\n",
      "          [-7.8125e-01,  1.4844e-01,  1.9922e-01,  ..., -3.7031e+00,\n",
      "           -9.8828e-01,  5.5078e-01],\n",
      "          [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
      "            7.0312e-02, -3.8867e-01],\n",
      "          [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
      "            3.9648e-01,  6.1279e-02]],\n",
      "\n",
      "         [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
      "           -8.5449e-02, -1.1902e-03],\n",
      "          [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
      "           -7.9590e-02, -7.2937e-03],\n",
      "          [-8.7402e-02, -2.7734e-01,  2.1777e-01,  ..., -1.8359e-01,\n",
      "            7.4219e-01,  1.8457e-01],\n",
      "          ...,\n",
      "          [ 9.2188e-01, -6.4062e-01,  5.0391e-01,  ...,  4.5898e-01,\n",
      "            1.3984e+00,  1.0156e+00],\n",
      "          [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
      "            2.3906e+00,  1.8066e-01],\n",
      "          [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
      "            1.7422e+00,  6.2891e-01]],\n",
      "\n",
      "         [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
      "           -6.0547e-01, -4.7656e-01],\n",
      "          [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
      "           -5.3125e-01, -4.3945e-01],\n",
      "          [-1.3867e-01,  1.6309e-01,  5.3125e-01,  ..., -4.4375e+00,\n",
      "            4.0938e+00,  2.5312e+00],\n",
      "          ...,\n",
      "          [ 1.6406e-01, -3.0859e-01, -3.3984e-01,  ..., -3.6250e+00,\n",
      "            3.5625e+00,  2.7539e-01],\n",
      "          [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
      "            5.0625e+00,  3.1562e+00],\n",
      "          [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
      "            2.3750e+00,  4.7656e-01]]]], dtype=torch.bfloat16)\n",
      "torch.Size([1, 32, 517, 128])\n"
     ]
    }
   ],
   "source": [
    "print(d5[4]['k'])\n",
    "print(d5[4]['k'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-3.8818e-02, -3.5400e-02,  1.4038e-02,  ...,  4.9219e-01,\n",
      "            5.3223e-02, -4.8633e-01],\n",
      "          [-5.9326e-02, -4.0039e-02, -2.1057e-03,  ...,  4.4141e-01,\n",
      "            5.1758e-02, -4.3555e-01],\n",
      "          [-2.5586e-01,  5.6641e-01, -6.9531e-01,  ..., -1.9453e+00,\n",
      "           -1.0625e+00,  2.1875e+00],\n",
      "          ...,\n",
      "          [ 3.3008e-01,  8.0078e-01,  5.0781e-01,  ..., -3.3438e+00,\n",
      "           -8.4375e-01,  3.4531e+00],\n",
      "          [ 3.0859e-01,  1.4688e+00,  8.4375e-01,  ..., -3.3281e+00,\n",
      "           -8.7891e-01,  3.4062e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 6.1951e-03,  2.2949e-02, -2.7588e-02,  ..., -4.2383e-01,\n",
      "           -4.2969e-01, -3.4570e-01],\n",
      "          [ 1.9531e-02, -5.6763e-03, -3.6133e-02,  ..., -3.8281e-01,\n",
      "           -2.5586e-01, -1.9238e-01],\n",
      "          [ 3.3203e-02, -3.5645e-02, -3.3203e-02,  ...,  5.7812e-01,\n",
      "            7.8125e-01,  6.2500e-01],\n",
      "          ...,\n",
      "          [ 4.7461e-01, -4.1016e-01,  2.5781e-01,  ...,  1.9531e+00,\n",
      "            1.6016e+00,  9.7656e-01],\n",
      "          [ 5.6641e-01, -3.1250e-01,  2.0410e-01,  ...,  1.8750e+00,\n",
      "            1.2734e+00,  8.8281e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4453e-01, -5.9814e-02,  2.1851e-02,  ...,  1.0781e+00,\n",
      "           -1.1621e-01,  1.7969e-01],\n",
      "          [-2.0996e-01, -2.9053e-02,  3.6133e-02,  ...,  1.0234e+00,\n",
      "           -1.1963e-01,  2.3438e-01],\n",
      "          [-9.4922e-01,  1.4141e+00,  3.3984e-01,  ..., -4.6562e+00,\n",
      "            1.3906e+00, -9.5703e-01],\n",
      "          ...,\n",
      "          [-1.0625e+00,  1.7812e+00,  4.4531e-01,  ..., -7.0312e+00,\n",
      "            2.0020e-02, -8.6719e-01],\n",
      "          [-1.0312e+00,  1.1406e+00,  5.7031e-01,  ..., -7.0938e+00,\n",
      "           -5.9766e-01, -4.4727e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7637e-02,  2.7832e-02,  9.7046e-03,  ...,  7.3438e-01,\n",
      "           -8.1055e-02,  5.9082e-02],\n",
      "          [ 3.9307e-02,  3.6133e-02,  8.4229e-03,  ...,  6.6016e-01,\n",
      "           -8.3008e-02,  3.7598e-02],\n",
      "          [ 4.1602e-01, -1.3086e-01,  3.0664e-01,  ..., -2.3594e+00,\n",
      "           -1.4453e+00,  3.3789e-01],\n",
      "          ...,\n",
      "          [-5.4297e-01,  4.7070e-01,  9.7656e-03,  ..., -4.0312e+00,\n",
      "            7.0312e-02, -3.8867e-01],\n",
      "          [-4.9609e-01,  5.6641e-01, -8.8867e-02,  ..., -4.1250e+00,\n",
      "            3.9648e-01,  6.1279e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-2.9907e-02,  1.6724e-02,  1.1673e-03,  ...,  8.6914e-02,\n",
      "           -8.5449e-02, -1.1902e-03],\n",
      "          [-5.0781e-02, -6.8970e-03,  4.5654e-02,  ...,  7.8125e-02,\n",
      "           -7.9590e-02, -7.2937e-03],\n",
      "          [ 5.2246e-02, -8.5547e-01,  4.6094e-01,  ..., -1.5312e+00,\n",
      "           -1.4688e+00, -1.6172e+00],\n",
      "          ...,\n",
      "          [ 1.0703e+00, -7.3047e-01,  1.7578e-01,  ...,  8.0078e-01,\n",
      "            2.3906e+00,  1.8066e-01],\n",
      "          [ 1.0078e+00, -1.0234e+00,  3.8867e-01,  ...,  8.0859e-01,\n",
      "            1.7422e+00,  6.2891e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.8330e-02,  6.5002e-03, -5.7068e-03,  ...,  6.0547e-01,\n",
      "           -6.0547e-01, -4.7656e-01],\n",
      "          [ 7.5073e-03,  6.0425e-03,  2.3193e-02,  ...,  5.5469e-01,\n",
      "           -5.3125e-01, -4.3945e-01],\n",
      "          [-1.7090e-01, -2.9492e-01,  3.8867e-01,  ..., -3.5469e+00,\n",
      "            3.2031e+00, -1.2734e+00],\n",
      "          ...,\n",
      "          [ 2.4121e-01, -1.9531e-01, -4.8438e-01,  ..., -3.4531e+00,\n",
      "            5.0625e+00,  3.1562e+00],\n",
      "          [ 8.4473e-02, -1.3574e-01, -2.0703e-01,  ..., -5.2188e+00,\n",
      "            2.3750e+00,  4.7656e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], dtype=torch.bfloat16)\n",
      "torch.Size([1, 32, 517, 128])\n"
     ]
    }
   ],
   "source": [
    "print(d6[4]['k'])\n",
    "print(d6[4]['k'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2559,  0.5664, -0.6953,  ..., -1.9453, -1.0625,  2.1875],\n",
       "         [ 0.0332, -0.0356, -0.0332,  ...,  0.5781,  0.7812,  0.6250],\n",
       "         [-0.9492,  1.4141,  0.3398,  ..., -4.6562,  1.3906, -0.9570],\n",
       "         ...,\n",
       "         [ 0.4160, -0.1309,  0.3066,  ..., -2.3594, -1.4453,  0.3379],\n",
       "         [ 0.0522, -0.8555,  0.4609,  ..., -1.5312, -1.4688, -1.6172],\n",
       "         [-0.1709, -0.2949,  0.3887,  ..., -3.5469,  3.2031, -1.2734]]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[4]['k'][:, :, 3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2559,  0.5664, -0.6953,  ..., -1.9453, -1.0625,  2.1875],\n",
       "         [ 0.0332, -0.0356, -0.0332,  ...,  0.5781,  0.7812,  0.6250],\n",
       "         [-0.9492,  1.4141,  0.3398,  ..., -4.6562,  1.3906, -0.9570],\n",
       "         ...,\n",
       "         [ 0.4160, -0.1309,  0.3066,  ..., -2.3594, -1.4453,  0.3379],\n",
       "         [ 0.0522, -0.8555,  0.4609,  ..., -1.5312, -1.4688, -1.6172],\n",
       "         [-0.1709, -0.2949,  0.3887,  ..., -3.5469,  3.2031, -1.2734]]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d6[4]['k'][:, :, 2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442128/73442226.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_kvhh.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/73442226.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_kvhh.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/73442226.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_pkw_update.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_442128/73442226.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_pkw_update.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "d5_kvhh=[]\n",
    "d6_kvhh=[]\n",
    "d5_pkw_update=[]\n",
    "d6_pkw_update=[]\n",
    "\n",
    "for i in range(5):\n",
    "    d5_kvhh.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
    "    d6_kvhh.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_kvhh.pth', map_location=torch.device('cpu')))\n",
    "    d5_pkw_update.append(torch.load(f'../cache/llama/h2o_5/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n",
    "    d6_pkw_update.append(torch.load(f'../cache/llama/h2o_6/l3_i{i}_pkw_update.pth', map_location=torch.device('cpu')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_kvhh[4]['k']!=d6_kvhh[4]['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2098969)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_pkw_update[4]['k']!=d6_pkw_update[4]['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442128/1437630781.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_final = torch.load(f'../cache/llama/h2o_5/l3_final.pth', map_location=torch.device('cpu'))\n",
      "/tmp/ipykernel_442128/1437630781.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_final = torch.load(f'../cache/llama/h2o_6/l3_final.pth', map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "d5_final = torch.load(f'../cache/llama/h2o_5/l3_final.pth', map_location=torch.device('cpu'))\n",
    "d6_final = torch.load(f'../cache/llama/h2o_6/l3_final.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_final['attn_output']!=d6_final['attn_output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d5_final['past_key_value'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d5_final['past_key_value'][3][0]!=d6_final['past_key_value'].key_cache[3][:, :, :516, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum(): argument 'input' (position 1) must be Tensor, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43md5_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpast_key_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43md6_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpast_key_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not bool"
     ]
    }
   ],
   "source": [
    "torch.sum(d5_final['past_key_value']!=d6_final['past_key_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442128/1783226647.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d5_final[i] = torch.load(f'../cache/llama/h2o_5/l{i}_final.pth', map_location=torch.device('cpu'))\n",
      "/tmp/ipykernel_442128/1783226647.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d6_final[i] = torch.load(f'../cache/llama/h2o_6/l{i}_final.pth', map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "d5_final={}\n",
    "d6_final={}\n",
    "\n",
    "for i in range(3, 32):\n",
    "    d5_final[i] = torch.load(f'../cache/llama/h2o_5/l{i}_final.pth', map_location=torch.device('cpu'))\n",
    "    d6_final[i] = torch.load(f'../cache/llama/h2o_6/l{i}_final.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 3\n",
      "tensor(0)\n",
      ">> 4\n",
      "tensor(0)\n",
      ">> 5\n",
      "tensor(0)\n",
      ">> 6\n",
      "tensor(0)\n",
      ">> 7\n",
      "tensor(0)\n",
      ">> 8\n",
      "tensor(0)\n",
      ">> 9\n",
      "tensor(0)\n",
      ">> 10\n",
      "tensor(0)\n",
      ">> 11\n",
      "tensor(0)\n",
      ">> 12\n",
      "tensor(0)\n",
      ">> 13\n",
      "tensor(0)\n",
      ">> 14\n",
      "tensor(0)\n",
      ">> 15\n",
      "tensor(0)\n",
      ">> 16\n",
      "tensor(0)\n",
      ">> 17\n",
      "tensor(0)\n",
      ">> 18\n",
      "tensor(0)\n",
      ">> 19\n",
      "tensor(0)\n",
      ">> 20\n",
      "tensor(0)\n",
      ">> 21\n",
      "tensor(0)\n",
      ">> 22\n",
      "tensor(0)\n",
      ">> 23\n",
      "tensor(0)\n",
      ">> 24\n",
      "tensor(0)\n",
      ">> 25\n",
      "tensor(0)\n",
      ">> 26\n",
      "tensor(0)\n",
      ">> 27\n",
      "tensor(0)\n",
      ">> 28\n",
      "tensor(0)\n",
      ">> 29\n",
      "tensor(0)\n",
      ">> 30\n",
      "tensor(0)\n",
      ">> 31\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 32):\n",
    "    print(f'>> {i}')\n",
    "    print(torch.sum(d5_final[i]['attn_output']!=d6_final[i]['attn_output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[0]['cache_kwargs']['cos'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 1021, 1022, 1023])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5[0]['cache_kwargs']['cache_position']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
